{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from pytorch_lightning.loggers import WandbLogger, CSVLogger\n",
    "\n",
    "from estimator import LagGPTEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CombinedDatasetIterator:\n",
    "    def __init__(self, datasets, seed, weights):\n",
    "        self._datasets = [iter(el) for el in datasets]\n",
    "        self._weights = weights\n",
    "        self._rng = random.Random(seed)\n",
    "\n",
    "    def __next__(self):\n",
    "        (dataset,) = self._rng.choices(self._datasets, weights=self._weights, k=1)\n",
    "        return next(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CombinedDataset:\n",
    "    def __init__(self, datasets, seed=None, weights=None):\n",
    "        self._seed = seed\n",
    "        self._datasets = datasets\n",
    "        self._weights = weights\n",
    "        n_datasets = len(datasets)\n",
    "        if weights is None:\n",
    "            self._weights = [1 / n_datasets] * n_datasets\n",
    "\n",
    "    def __iter__(self):\n",
    "        return CombinedDatasetIterator(self._datasets, self._seed, self._weights)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return sum([len(ds) for ds in self._datasets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gluonts_ds = [\n",
    "        get_dataset(\"airpassengers\").train,\n",
    "        get_dataset(\"australian_electricity_demand\").train,\n",
    "        get_dataset(\"car_parts_without_missing\").train,\n",
    "        get_dataset(\"cif_2016\").train,\n",
    "        get_dataset(\"covid_deaths\").train,\n",
    "        get_dataset(\"electricity\").train,\n",
    "        get_dataset(\"electricity_weekly\").train,\n",
    "        get_dataset(\"exchange_rate\").train,\n",
    "        get_dataset(\"fred_md\").train,\n",
    "        get_dataset(\"hospital\").train,\n",
    "        get_dataset(\"kaggle_web_traffic_weekly\").train,\n",
    "        get_dataset(\"kdd_cup_2018_without_missing\").train,\n",
    "        get_dataset(\"london_smart_meters_without_missing\").train,\n",
    "        get_dataset(\"nn5_daily_with_missing\").train,\n",
    "        get_dataset(\"nn5_weekly\").train,\n",
    "        get_dataset(\"pedestrian_counts\").train,\n",
    "        get_dataset(\"rideshare_without_missing\").train,\n",
    "        get_dataset(\"saugeenday\").train,\n",
    "        get_dataset(\"solar-energy\").train,\n",
    "        get_dataset(\"solar_10_minutes\").train,\n",
    "        get_dataset(\"solar_weekly\").train,\n",
    "        get_dataset(\"taxi_30min\").train,\n",
    "        get_dataset(\"temperature_rain_without_missing\").train,\n",
    "        get_dataset(\"tourism_monthly\").train,\n",
    "        get_dataset(\"uber_tlc_daily\").train,\n",
    "        get_dataset(\"uber_tlc_hourly\").train,\n",
    "        get_dataset(\"vehicle_trips_without_missing\").train,\n",
    "        get_dataset(\"weather\").train,\n",
    "        get_dataset(\"wiki-rolling_nips\").train,\n",
    "        get_dataset(\"m4_daily\").train,\n",
    "        get_dataset(\"m4_hourly\").train,\n",
    "        get_dataset(\"m4_monthly\").train,\n",
    "        get_dataset(\"m4_quarterly\").train,\n",
    "        get_dataset(\"m4_yearly\").train,\n",
    "        get_dataset(\"wind_farms_without_missing\").train,\n",
    "]\n",
    "dataset = CombinedDataset(gluonts_ds, weights=[sum([len(x[\"target\"]) for x in d]) for d in gluonts_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataset = get_dataset(\"m4_weekly\").test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta = get_dataset(\"m4_weekly\").metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set more seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "logger = CSVLogger(\"logs\", name=\"Lag-gpt-large-\"+str(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unset LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator = LagGPTEstimator(\n",
    "    prediction_length=meta.prediction_length,\n",
    "    context_length=1024, # block_size: int = 1024, 2048 \n",
    "    batch_size=4, # 4, 8, 16, 32\n",
    "    n_layer=8,\n",
    "    n_head=4,\n",
    "    n_embd=32, # 32,64,128,256,512,1024,2048,4096\n",
    "    scaling=\"std\",\n",
    "    \n",
    "    # set aug prob\n",
    "    aug_prob=1.0,\n",
    "    aug_rate=0.1,\n",
    "    \n",
    "    num_batches_per_epoch=100,\n",
    "    trainer_kwargs=dict(max_epochs=300, accelerator=\"gpu\", precision=\"32\", logger=logger),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = estimator.train(\n",
    "    training_data=dataset, \n",
    "    validation_data=val_dataset,\n",
    "    shuffle_buffer_length=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = get_dataset(\"traffic\").test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=test_dataset, predictor=predictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecasts = list(forecast_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tss = list(ts_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# num_workers is limited to 10 if cpu has more cores\n",
    "num_workers = min(multiprocessing.cpu_count(), 10)\n",
    "\n",
    "evaluator = Evaluator(num_workers=num_workers)\n",
    "agg_metrics, ts_metrics = evaluator(\n",
    "    iter(tss), iter(forecasts), num_series=len(test_dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_type = []\n",
    "error = []\n",
    "for state in agg_metrics:\n",
    "    metric_type.append(state)\n",
    "for value in agg_metrics.values():\n",
    "    error.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame( error, metric_type).reset_index().rename(columns = {'index': 'error',0:'metric_type'}).T\n",
    "df.columns = df.iloc[0,:]\n",
    "df = df.iloc[1:, :]\n",
    "df['#parameters']=411000000#102000000#411000000#6800000\n",
    "df['seed'] = seed\n",
    "# df.to_csv('error100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dff = pd.read_csv('error100.csv')#.drop('Unnamed: 0', axis=1)\n",
    "# dff.columns\n",
    "dff = dff.append(df)\n",
    "dff.to_csv('error100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ts_metrics.plot(x=\"MSIS\", y=\"MAPE\", kind=\"scatter\")\n",
    "plt.grid(which=\"both\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "for idx, (forecast, ts) in islice(enumerate(zip(forecasts, tss)), 9):\n",
    "    ax = plt.subplot(3, 3, idx+1)\n",
    "    forecast.plot(color='g')\n",
    "    ts[-3 * 24:][0].plot(label=\"target\")\n",
    "    plt.xticks(rotation=60)\n",
    "    ax.set_title(forecast.item_id)\n",
    "\n",
    "plt.gcf().tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('error100.csv')\n",
    "df = df.drop_duplicates(subset=['#parameters','seed'], keep='last')\n",
    "temp = df.groupby(['#parameters'])['RMSE'].mean().reset_index().dropna()\n",
    "std_temp = df.groupby(['#parameters'])['RMSE'].std().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "std_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = plt.subplots(figsize =(5, 3))# large\n",
    "\n",
    "# plt.bar(temp['model'],temp['crps'],width = 0.2)\n",
    "plt.plot(temp['#parameters'],temp['RMSE'],'bo-')\n",
    "for x,y in zip(np.log10(temp['#parameters']),[0,0.1,0.5]):\n",
    "\n",
    "    label = f\"p={y}\"\n",
    "\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (x,y), # these are the coordinates to position the label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,10), # distance from text to points (x,y)\n",
    "                 ha='center') \n",
    "plt.title('Test RMSE vs params')\n",
    "plt.xlabel('number of parameters')\n",
    "plt.ylabel('RMSE on test set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "clrs = sns.color_palette(\"husl\", 5)\n",
    "with sns.axes_style(\"darkgrid\"):\n",
    "    ax.plot(temp['#parameters'], temp['RMSE'])\n",
    "    ax.fill_between(temp['#parameters'], temp['RMSE']-std_temp['RMSE'], temp['RMSE']+std_temp['RMSE'] ,alpha=0.3)\n",
    "    ax.legend()\n",
    "plt.title('RMSE vs params')\n",
    "plt.xlabel('number of parameters')\n",
    "plt.ylabel('RMSE on test set')\n",
    "plt.show()\n",
    "    # ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"logs/\"\n",
    "dir_list = os.listdir(path)\n",
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dff = pd.DataFrame()\n",
    "for i in dir_list:\n",
    "    \n",
    "    df = pd.read_csv('logs/'+i+'/version_0/metrics.csv').drop(['train_loss'], axis=1).dropna()\n",
    "    df['seed']=int(i.split(\"-\")[-1])\n",
    "    if i.split(\"-\")[-2]=='medium':\n",
    "        df['parameters']=102000000\n",
    "    if i.split(\"-\")[-2]=='small':\n",
    "        print(i)\n",
    "        df['parameters']=6800000\n",
    "    if i.split(\"-\")[-2]=='large':\n",
    "        df['parameters']=411000000\n",
    "    dff = dff.append(df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dff['parameters'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = dff.groupby(['parameters','epoch'])['val_loss'].mean().reset_index().dropna()\n",
    "std_temp = dff.groupby(['parameters','epoch'])['val_loss'].std().reset_index().dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "clrs = sns.color_palette(\"husl\", 5)\n",
    "with sns.axes_style(\"darkgrid\"):\n",
    "    for i in dff['parameters'].unique().tolist():\n",
    "        ax.plot(temp[temp['parameters']==i]['epoch'], temp[temp['parameters']==i]['val_loss'], label=i)\n",
    "        ax.fill_between(temp[temp['parameters']==i]['epoch'], temp[temp['parameters']==i]['val_loss']-std_temp[std_temp['parameters']==i]['val_loss'], temp[temp['parameters']==i]['val_loss']+std_temp[std_temp['parameters']==i]['val_loss'] ,alpha=0.3)\n",
    "        ax.legend()\n",
    "plt.title('validation loss vs epochs')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('nll')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
