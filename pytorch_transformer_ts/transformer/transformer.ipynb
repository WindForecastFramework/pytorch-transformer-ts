{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Iterable, Dict, Any\n",
    "from itertools import islice\n",
    "from functools import lru_cache, partial\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import tqdm.auto as tqdm\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from datasets import load_dataset, interleave_datasets\n",
    "from datasets.iterable_dataset import RandomlyCyclingMultiSourcesExamplesIterable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from gluonts.core.component import validated\n",
    "from gluonts.dataset.common import Dataset, ListDataset, DatasetCollection, ProcessDataEntry\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.itertools import Cyclic, PseudoShuffled, IterableSlice\n",
    "from gluonts.time_feature import (\n",
    "    time_features_from_frequency_str,\n",
    "    TimeFeature,\n",
    "    MinuteOfHour,\n",
    "    HourOfDay,\n",
    "    DayOfWeek,\n",
    "    DayOfMonth,\n",
    "    DayOfYear,\n",
    ")\n",
    "from gluonts.torch.modules.loss import DistributionLoss, NegativeLogLikelihood\n",
    "from gluonts.transform import (\n",
    "    Transformation,\n",
    "    Chain,\n",
    "    RemoveFields,\n",
    "    SetField,\n",
    "    AsNumpyArray,\n",
    "    AddObservedValuesIndicator,\n",
    "    AddTimeFeatures,\n",
    "    AddAgeFeature,\n",
    "    VstackFeatures,\n",
    "    InstanceSplitter,\n",
    "    ValidationSplitSampler,\n",
    "    TestSplitSampler,\n",
    "    ExpectedNumInstanceSampler,\n",
    "    SelectFields,\n",
    "    InstanceSampler,\n",
    ")\n",
    "from gluonts.torch.util import (\n",
    "    IterableDataset,\n",
    ")\n",
    "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
    "from gluonts.torch.model.estimator import PyTorchLightningEstimator\n",
    "from gluonts.torch.model.predictor import PyTorchPredictor\n",
    "from gluonts.torch.distributions import (\n",
    "    DistributionOutput,\n",
    "    StudentTOutput,\n",
    ")\n",
    "from gluonts.torch.util import weighted_average\n",
    "from gluonts.torch.modules.scaler import MeanScaler, NOPScaler\n",
    "from gluonts.torch.modules.feature import FeatureEmbedder\n",
    "from gluonts.time_feature import get_lags_for_frequency\n",
    "from gluonts.dataset.repository.datasets import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features=[\n",
    "        MinuteOfHour(),\n",
    "        HourOfDay(),\n",
    "        DayOfWeek(),\n",
    "        DayOfMonth(),\n",
    "        DayOfYear(),\n",
    "    ]\n",
    "\n",
    "def add_time_feature(data, freq):\n",
    "    length = len(data[FieldName.TARGET])\n",
    "    start = pd.Period(data[FieldName.START], freq)\n",
    "    index = pd.period_range(start, periods=length, freq=freq)\n",
    "\n",
    "    data[FieldName.FEAT_TIME] = np.vstack(\n",
    "        [feat(index) for feat in time_features]\n",
    "    ).astype(np.float32)\n",
    "    \n",
    "    age = np.log10(2.0 + np.arange(length, dtype=np.float32))\n",
    "    data[FieldName.FEAT_AGE] = age.reshape((1, length))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(10_000)\n",
    "def _as_period(val, freq):\n",
    "    return pd.Period(val, freq)\n",
    "\n",
    "@dataclass\n",
    "class HFDataset(Dataset):\n",
    "    def __init__(self, dataset, freq, shuffle=False):\n",
    "        super().__init__()\n",
    "        transform = partial(add_time_feature, freq=freq)\n",
    "        self.dataset = dataset.with_format(\"np\").map(\n",
    "            transform,  num_proc=8, keep_in_memory=False,\n",
    "        )\n",
    "        if shuffle:\n",
    "            self.dataset = self.dataset.shuffle()\n",
    "        self.freq = to_offset(freq)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for data in self.dataset:\n",
    "            yield {\n",
    "                FieldName.START: _as_period(data[FieldName.START], self.freq),\n",
    "                FieldName.TARGET: data[FieldName.TARGET],\n",
    "                FieldName.ITEM_ID: data[FieldName.ITEM_ID],\n",
    "                FieldName.FEAT_TIME: np.stack(data[FieldName.FEAT_TIME],0),\n",
    "                FieldName.FEAT_AGE: np.stack(data[FieldName.FEAT_AGE],0),\n",
    "            }\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = load_dataset(\"monash_tsf\", \"traffic_hourly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = load_dataset(\"monash_tsf\", \"weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_3 = load_dataset(\"monash_tsf\", \"tourism_monthly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_4 = load_dataset(\"monash_tsf\", \"london_smart_meters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_1[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_2[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_3[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_4[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_1 = HFDataset(dataset_1[\"train\"], freq=\"1H\", shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_2 = HFDataset(dataset_2[\"train\"], freq=\"1D\", shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_3 = HFDataset(dataset_3[\"train\"], freq=\"1M\", shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_4 = HFDataset(dataset_4[\"train\"], freq=\"30T\", shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds_1 = HFDataset(dataset_1[\"validation\"], freq=\"1H\",  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds_2 = HFDataset(dataset_2[\"validation\"], freq=\"1D\",  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds_3 = HFDataset(dataset_3[\"validation\"], freq=\"1M\",  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds_4 = HFDataset(dataset_4[\"validation\"], freq=\"30T\",  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_1 = HFDataset(dataset_1[\"test\"], freq=\"1H\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_2 = HFDataset(dataset_2[\"test\"], freq=\"1D\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_3 = HFDataset(dataset_3[\"test\"], freq=\"1M\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_4 = HFDataset(dataset_4[\"test\"], freq=\"30T\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_list = [train_ds_1, train_ds_2, train_ds_3, train_ds_4]\n",
    "train_ds_size = np.array([len(ds) for ds in train_ds_list])\n",
    "raw_weights = 1/train_ds_size\n",
    "normalization_factor = 1/sum(raw_weights)\n",
    "probablities = raw_weights * normalization_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = RandomlyCyclingMultiSourcesExamplesIterable(\n",
    "    train_ds_list, \n",
    "    generator=np.random.default_rng(), \n",
    "    probabilities=probablities,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = DatasetCollection(datasets=[val_ds_1, val_ds_2, val_ds_3], interleave=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    @validated()\n",
    "    def __init__(\n",
    "        self,\n",
    "        context_length: int,\n",
    "        prediction_length: int,\n",
    "        num_feat_dynamic_real: int,\n",
    "        num_feat_static_real: int,\n",
    "        num_feat_static_cat: int,\n",
    "        cardinality: List[int],\n",
    "        \n",
    "        # transformer arguments\n",
    "        nhead: int,\n",
    "        num_encoder_layers: int,\n",
    "        num_decoder_layers: int,\n",
    "        dim_feedforward: int,\n",
    "        activation: str = \"gelu\",\n",
    "        dropout: float = 0.1,\n",
    "\n",
    "        # univariate input\n",
    "        input_size: int = 1,\n",
    "        embedding_dimension: Optional[List[int]] = None,\n",
    "        distr_output: DistributionOutput = StudentTOutput(),\n",
    "        freq: Optional[str] = None,\n",
    "        lags_seq: Optional[List[int]] = None,\n",
    "        scaling: bool = True,\n",
    "        num_parallel_samples: int = 100,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        assert (freq is not None) or (lags_seq is not None), \"either freq or lags_seq must be given\"\n",
    "        \n",
    "        self.input_size = input_size\n",
    "       \n",
    "        self.target_shape = distr_output.event_shape\n",
    "        self.num_feat_dynamic_real = num_feat_dynamic_real\n",
    "        self.num_feat_static_cat = num_feat_static_cat\n",
    "        self.num_feat_static_real = num_feat_static_real\n",
    "        self.embedding_dimension = (\n",
    "            embedding_dimension\n",
    "            if embedding_dimension is not None or cardinality is None\n",
    "            else [min(50, (cat + 1) // 2) for cat in cardinality]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.lags_seq = lags_seq or get_lags_for_frequency(freq_str=freq)\n",
    "        \n",
    "        self.num_parallel_samples = num_parallel_samples\n",
    "        self.history_length = context_length + max(self.lags_seq)\n",
    "        self.embedder = FeatureEmbedder(\n",
    "            cardinalities=cardinality,\n",
    "            embedding_dims=self.embedding_dimension,\n",
    "        )\n",
    "        if scaling:\n",
    "            self.scaler = MeanScaler(dim=1, keepdim=True)\n",
    "        else:\n",
    "            self.scaler = NOPScaler(dim=1, keepdim=True)\n",
    "        \n",
    "        # total feature size\n",
    "        d_model = self.input_size * len(self.lags_seq) + self._number_of_features\n",
    "        \n",
    "        self.context_length = context_length\n",
    "        self.prediction_length = prediction_length\n",
    "        self.distr_output = distr_output\n",
    "        self.param_proj = distr_output.get_args_proj(d_model)\n",
    "            \n",
    "        # transformer enc-decoder and mask initializer\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation=activation,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        \n",
    "        # causal decoder tgt mask\n",
    "        self.register_buffer(\n",
    "            \"tgt_mask\",\n",
    "            self.transformer.generate_square_subsequent_mask(prediction_length),\n",
    "        )\n",
    "        \n",
    "    @property\n",
    "    def _number_of_features(self) -> int:\n",
    "        return (\n",
    "            sum(self.embedding_dimension)\n",
    "            + self.num_feat_dynamic_real\n",
    "            + self.num_feat_static_real\n",
    "            + self.input_size  # the log(scale)\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def _past_length(self) -> int:\n",
    "        return self.context_length + max(self.lags_seq)\n",
    "    \n",
    "    def get_lagged_subsequences(\n",
    "        self,\n",
    "        sequence: torch.Tensor,\n",
    "        subsequences_length: int,\n",
    "        shift: int = 0\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns lagged subsequences of a given sequence.\n",
    "        Parameters\n",
    "        ----------\n",
    "        sequence : Tensor\n",
    "            the sequence from which lagged subsequences should be extracted.\n",
    "            Shape: (N, T, C).\n",
    "        subsequences_length : int\n",
    "            length of the subsequences to be extracted.\n",
    "        shift: int\n",
    "            shift the lags by this amount back.\n",
    "        Returns\n",
    "        --------\n",
    "        lagged : Tensor\n",
    "            a tensor of shape (N, S, C, I), where S = subsequences_length and\n",
    "            I = len(indices), containing lagged subsequences. Specifically,\n",
    "            lagged[i, j, :, k] = sequence[i, -indices[k]-S+j, :].\n",
    "        \"\"\"\n",
    "        sequence_length = sequence.shape[1]\n",
    "        indices = [l - shift for l in self.lags_seq]\n",
    "\n",
    "        assert max(indices) + subsequences_length <= sequence_length, (\n",
    "            f\"lags cannot go further than history length, found lag {max(indices)} \"\n",
    "            f\"while history length is only {sequence_length}\"\n",
    "        )\n",
    "\n",
    "        lagged_values = []\n",
    "        for lag_index in indices:\n",
    "            begin_index = -lag_index - subsequences_length\n",
    "            end_index = -lag_index if lag_index > 0 else None\n",
    "            lagged_values.append(sequence[:, begin_index:end_index, ...])\n",
    "        return torch.stack(lagged_values, dim=-1)\n",
    "\n",
    "    def _check_shapes(\n",
    "        self,\n",
    "        prior_input: torch.Tensor,\n",
    "        inputs: torch.Tensor,\n",
    "        features: Optional[torch.Tensor],\n",
    "    ) -> None:\n",
    "        assert len(prior_input.shape) == len(inputs.shape)\n",
    "        assert (\n",
    "            len(prior_input.shape) == 2 and self.input_size == 1\n",
    "        ) or prior_input.shape[2] == self.input_size\n",
    "        assert (len(inputs.shape) == 2 and self.input_size == 1) or inputs.shape[\n",
    "            -1\n",
    "        ] == self.input_size\n",
    "        assert (\n",
    "            features is None or features.shape[2] == self._number_of_features\n",
    "        ), f\"{features.shape[2]}, expected {self._number_of_features}\"\n",
    "    \n",
    "    \n",
    "    def create_network_inputs(\n",
    "        self, \n",
    "        feat_static_cat: torch.Tensor, \n",
    "        feat_static_real: torch.Tensor,\n",
    "        past_time_feat: torch.Tensor,\n",
    "        past_target: torch.Tensor,\n",
    "        past_observed_values: torch.Tensor,\n",
    "        future_time_feat: Optional[torch.Tensor] = None,\n",
    "        future_target: Optional[torch.Tensor] = None,\n",
    "    ):        \n",
    "        # time feature\n",
    "        time_feat = (\n",
    "            torch.cat(\n",
    "                (\n",
    "                    past_time_feat[:, self._past_length - self.context_length :, ...],\n",
    "                    future_time_feat,\n",
    "                ),\n",
    "                dim=1,\n",
    "            )\n",
    "            if future_target is not None\n",
    "            else past_time_feat[:, self._past_length - self.context_length :, ...]\n",
    "        )\n",
    "\n",
    "        # target\n",
    "        context = past_target[:, -self.context_length :]\n",
    "        observed_context = past_observed_values[:, -self.context_length :]\n",
    "        _, scale = self.scaler(context, observed_context)\n",
    "\n",
    "        inputs = (\n",
    "            torch.cat((past_target, future_target), dim=1) / scale\n",
    "            if future_target is not None\n",
    "            else past_target / scale\n",
    "        )\n",
    "\n",
    "        inputs_length = (\n",
    "            self._past_length + self.prediction_length\n",
    "            if future_target is not None\n",
    "            else self._past_length\n",
    "        )\n",
    "        assert inputs.shape[1] == inputs_length\n",
    "        \n",
    "        subsequences_length = (\n",
    "            self.context_length + self.prediction_length\n",
    "            if future_target is not None\n",
    "            else self.context_length\n",
    "        )\n",
    "        \n",
    "        # embeddings\n",
    "        embedded_cat = self.embedder(feat_static_cat)\n",
    "        log_scale = scale.log() if self.input_size == 1 else scale.squeeze(1).log()\n",
    "        static_feat = torch.cat(\n",
    "            (embedded_cat, feat_static_real, log_scale),\n",
    "            dim=1,\n",
    "        )\n",
    "        expanded_static_feat = static_feat.unsqueeze(1).expand(\n",
    "            -1, time_feat.shape[1], -1\n",
    "        )\n",
    "        \n",
    "        \n",
    "        features = torch.cat((expanded_static_feat, time_feat), dim=-1)\n",
    "        \n",
    "        \n",
    "        #self._check_shapes(prior_input, inputs, features)\n",
    "\n",
    "        #sequence = torch.cat((prior_input, inputs), dim=1)\n",
    "        lagged_sequence = self.get_lagged_subsequences(\n",
    "            sequence=inputs,\n",
    "            subsequences_length=subsequences_length,\n",
    "        )\n",
    "\n",
    "        lags_shape = lagged_sequence.shape\n",
    "        reshaped_lagged_sequence = lagged_sequence.reshape(\n",
    "            lags_shape[0], lags_shape[1], -1\n",
    "        )\n",
    "\n",
    "\n",
    "        transformer_inputs = torch.cat((reshaped_lagged_sequence, features), dim=-1)\n",
    "        \n",
    "        return transformer_inputs, scale, static_feat\n",
    "    \n",
    "    def output_params(self, transformer_inputs):\n",
    "        enc_input = transformer_inputs[:, :self.context_length, ...]\n",
    "        dec_input = transformer_inputs[:, self.context_length:, ...]\n",
    "        \n",
    "        enc_out = self.transformer.encoder(\n",
    "            enc_input\n",
    "        )\n",
    "        dec_output = self.transformer.decoder(\n",
    "            dec_input,\n",
    "            enc_out,\n",
    "            tgt_mask=self.tgt_mask\n",
    "        )\n",
    "        \n",
    "        return self.param_proj(dec_output)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def output_distribution(\n",
    "        self, params, scale=None, trailing_n=None\n",
    "    ) -> torch.distributions.Distribution:\n",
    "        sliced_params = params\n",
    "        if trailing_n is not None:\n",
    "            sliced_params = [p[:, -trailing_n:] for p in params]\n",
    "        return self.distr_output.distribution(sliced_params, scale=scale)\n",
    "    \n",
    "    # for prediction\n",
    "    def forward(\n",
    "        self,\n",
    "        feat_static_cat: torch.Tensor,\n",
    "        feat_static_real: torch.Tensor,\n",
    "        past_time_feat: torch.Tensor,\n",
    "        past_target: torch.Tensor,\n",
    "        past_observed_values: torch.Tensor,\n",
    "        future_time_feat: torch.Tensor,\n",
    "        num_parallel_samples: Optional[int] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        \n",
    "        if num_parallel_samples is None:\n",
    "            num_parallel_samples = self.num_parallel_samples\n",
    "            \n",
    "        encoder_inputs, scale, static_feat = self.create_network_inputs(\n",
    "            feat_static_cat,\n",
    "            feat_static_real,\n",
    "            past_time_feat,\n",
    "            past_target,\n",
    "            past_observed_values,\n",
    "        )\n",
    "        \n",
    "        enc_out = self.transformer.encoder(encoder_inputs)\n",
    "        \n",
    "        repeated_scale = scale.repeat_interleave(\n",
    "            repeats=self.num_parallel_samples, dim=0\n",
    "        )\n",
    "\n",
    "        repeated_past_target = (\n",
    "            past_target.repeat_interleave(\n",
    "                repeats=self.num_parallel_samples, dim=0\n",
    "            )\n",
    "            / repeated_scale\n",
    "        )\n",
    "        \n",
    "        expanded_static_feat = static_feat.unsqueeze(1).expand(\n",
    "            -1, future_time_feat.shape[1], -1\n",
    "        )\n",
    "        features = torch.cat((expanded_static_feat, future_time_feat), dim=-1)\n",
    "        repeated_features = features.repeat_interleave(\n",
    "            repeats=self.num_parallel_samples, dim=0\n",
    "        )\n",
    "       \n",
    "        repeated_enc_out = enc_out.repeat_interleave(\n",
    "            repeats=self.num_parallel_samples, dim=0\n",
    "        )\n",
    "\n",
    "        future_samples = []\n",
    "        \n",
    "        # greedy decoding\n",
    "        for k in range(self.prediction_length):            \n",
    "            #self._check_shapes(repeated_past_target, next_sample, next_features)\n",
    "            #sequence = torch.cat((repeated_past_target, next_sample), dim=1)\n",
    "            \n",
    "            lagged_sequence = self.get_lagged_subsequences(\n",
    "                sequence=repeated_past_target,\n",
    "                subsequences_length=1+k,\n",
    "                shift=1, \n",
    "            )\n",
    "\n",
    "            lags_shape = lagged_sequence.shape\n",
    "            reshaped_lagged_sequence = lagged_sequence.reshape(\n",
    "                lags_shape[0], lags_shape[1], -1\n",
    "            )\n",
    "            \n",
    "            decoder_input = torch.cat((reshaped_lagged_sequence, repeated_features[:, : k+1]), dim=-1)\n",
    "\n",
    "            output = self.transformer.decoder(decoder_input, repeated_enc_out)\n",
    "            \n",
    "            params = self.param_proj(output[:,-1:])\n",
    "            distr = self.output_distribution(params, scale=repeated_scale)\n",
    "            next_sample = distr.sample()\n",
    "            \n",
    "            repeated_past_target = torch.cat(\n",
    "                (repeated_past_target, next_sample / repeated_scale), dim=1\n",
    "            )\n",
    "            future_samples.append(next_sample)\n",
    "\n",
    "        concat_future_samples = torch.cat(future_samples, dim=1)\n",
    "        return concat_future_samples.reshape(\n",
    "            (-1, self.num_parallel_samples, self.prediction_length)\n",
    "            + self.target_shape,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerLightningModule(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: TransformerModel,\n",
    "        loss: DistributionLoss = NegativeLogLikelihood(),\n",
    "        lr: float = 1e-3,\n",
    "        weight_decay: float = 1e-8,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "    def training_step(self, batch, batch_idx: int):\n",
    "        \"\"\"Execute training step\"\"\"\n",
    "        train_loss = self(batch)\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            train_loss,\n",
    "            on_epoch=True,\n",
    "            on_step=False,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx: int):\n",
    "        \"\"\"Execute validation step\"\"\"\n",
    "        with torch.inference_mode():\n",
    "            val_loss = self(batch)\n",
    "        self.log(\n",
    "            \"val_loss\", val_loss, on_epoch=True, on_step=False, prog_bar=True\n",
    "        )\n",
    "        return val_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Returns the optimizer to use\"\"\"\n",
    "        return torch.optim.Adam(\n",
    "            self.model.parameters(),\n",
    "            lr=self.lr,\n",
    "            weight_decay=self.weight_decay,\n",
    "            capturable=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        feat_static_cat = batch[\"feat_static_cat\"]\n",
    "        feat_static_real = batch[\"feat_static_real\"]\n",
    "        past_time_feat = batch[\"past_time_feat\"]\n",
    "        past_target = batch[\"past_target\"]\n",
    "        future_time_feat = batch[\"future_time_feat\"]\n",
    "        future_target = batch[\"future_target\"]\n",
    "        past_observed_values = batch[\"past_observed_values\"]\n",
    "        future_observed_values = batch[\"future_observed_values\"]\n",
    "        \n",
    "        transformer_inputs, scale, _ = self.model.create_network_inputs(\n",
    "            feat_static_cat,\n",
    "            feat_static_real,\n",
    "            past_time_feat,\n",
    "            past_target,\n",
    "            past_observed_values,\n",
    "            future_time_feat,\n",
    "            future_target,\n",
    "        )\n",
    "        params = self.model.output_params(transformer_inputs)\n",
    "        distr = self.model.output_distribution(params, scale)\n",
    "\n",
    "        loss_values = self.loss(distr, future_target)\n",
    "    \n",
    "        if len(self.model.target_shape) == 0:\n",
    "            loss_weights = future_observed_values\n",
    "        else:\n",
    "            loss_weights, _ = future_observed_values.min(dim=-1, keepdim=False)\n",
    "\n",
    "        return weighted_average(loss_values, weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_INPUT_NAMES = [\n",
    "    \"feat_static_cat\",\n",
    "    \"feat_static_real\",\n",
    "    \"past_time_feat\",\n",
    "    \"past_target\",\n",
    "    \"past_observed_values\",\n",
    "    \"future_time_feat\",\n",
    "]\n",
    "\n",
    "TRAINING_INPUT_NAMES = PREDICTION_INPUT_NAMES + [\n",
    "    \"future_target\",\n",
    "    \"future_observed_values\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEstimator(PyTorchLightningEstimator):\n",
    "    @validated()\n",
    "    def __init__(\n",
    "        self,\n",
    "        prediction_length: int,\n",
    "        \n",
    "        # Transformer arguments\n",
    "        nhead: int,\n",
    "        num_encoder_layers: int,\n",
    "        num_decoder_layers: int,\n",
    "        dim_feedforward: int,\n",
    "        input_size: int = 1,\n",
    "        activation: str = \"gelu\",\n",
    "        dropout: float = 0.1,\n",
    "\n",
    "        context_length: Optional[int] = None,\n",
    "\n",
    "        num_feat_dynamic_real: int = 0,\n",
    "        num_feat_static_cat: int = 0,\n",
    "        num_feat_static_real: int = 0,\n",
    "        cardinality: Optional[List[int]] = None,\n",
    "        embedding_dimension: Optional[List[int]] = None,\n",
    "        distr_output: DistributionOutput = StudentTOutput(),\n",
    "        loss: DistributionLoss = NegativeLogLikelihood(),\n",
    "        scaling: bool = True,\n",
    "        freq: Optional[str] = None,\n",
    "        lags_seq: Optional[List[int]] = None,\n",
    "        time_features: Optional[List[TimeFeature]] = None,\n",
    "        num_parallel_samples: int = 100,\n",
    "        batch_size: int = 32,\n",
    "        num_batches_per_epoch: int = 50,\n",
    "        trainer_kwargs: Optional[Dict[str, Any]] = dict(),\n",
    "        train_sampler: Optional[InstanceSampler] = None,\n",
    "        validation_sampler: Optional[InstanceSampler] = None,\n",
    "    ) -> None:\n",
    "        trainer_kwargs = {\n",
    "            \"max_epochs\": 100,\n",
    "            **trainer_kwargs,\n",
    "        }\n",
    "        super().__init__(trainer_kwargs=trainer_kwargs)\n",
    "        \n",
    "        self.freq = freq\n",
    "        self.context_length = (\n",
    "            context_length if context_length is not None else prediction_length\n",
    "        )\n",
    "        self.prediction_length = prediction_length\n",
    "        self.distr_output = distr_output\n",
    "        self.loss = loss\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.nhead = nhead\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        self.num_decoder_layers = num_decoder_layers\n",
    "        self.activation = activation\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.num_feat_dynamic_real = num_feat_dynamic_real\n",
    "        self.num_feat_static_cat = num_feat_static_cat\n",
    "        self.num_feat_static_real = num_feat_static_real\n",
    "        self.cardinality = (\n",
    "            cardinality if cardinality and num_feat_static_cat > 0 else [1]\n",
    "        )\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.scaling = scaling\n",
    "        self.lags_seq = lags_seq\n",
    "        self.time_features = (\n",
    "            time_features\n",
    "            if time_features is not None\n",
    "            else time_features_from_frequency_str(self.freq)\n",
    "        )\n",
    "\n",
    "        self.num_parallel_samples = num_parallel_samples\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches_per_epoch = num_batches_per_epoch\n",
    "\n",
    "        self.train_sampler = train_sampler or ExpectedNumInstanceSampler(\n",
    "            num_instances=1.0, min_future=prediction_length\n",
    "        )\n",
    "        self.validation_sampler = validation_sampler or ValidationSplitSampler(\n",
    "            min_future=prediction_length\n",
    "        )\n",
    "        \n",
    "    def create_transformation(self) -> Transformation:\n",
    "        remove_field_names = []\n",
    "        if self.num_feat_static_real == 0:\n",
    "            remove_field_names.append(FieldName.FEAT_STATIC_REAL)\n",
    "        if self.num_feat_dynamic_real == 0:\n",
    "            remove_field_names.append(FieldName.FEAT_DYNAMIC_REAL)\n",
    "\n",
    "        return Chain(\n",
    "            [RemoveFields(field_names=remove_field_names)]\n",
    "            + (\n",
    "                [SetField(output_field=FieldName.FEAT_STATIC_CAT, value=[0])]\n",
    "                if not self.num_feat_static_cat > 0\n",
    "                else []\n",
    "            )\n",
    "            + (\n",
    "                [\n",
    "                    SetField(\n",
    "                        output_field=FieldName.FEAT_STATIC_REAL, value=[0.0]\n",
    "                    )\n",
    "                ]\n",
    "                if not self.num_feat_static_real > 0\n",
    "                else []\n",
    "            )\n",
    "            + [\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.FEAT_STATIC_CAT,\n",
    "                    expected_ndim=1,\n",
    "                    dtype=int,\n",
    "                ),\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.FEAT_STATIC_REAL,\n",
    "                    expected_ndim=1,\n",
    "                ),\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.TARGET,\n",
    "                    # in the following line, we add 1 for the time dimension\n",
    "                    expected_ndim=1 + len(self.distr_output.event_shape),\n",
    "                ),\n",
    "                AddObservedValuesIndicator(\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    output_field=FieldName.OBSERVED_VALUES,\n",
    "                ),\n",
    "#                 AddTimeFeatures(\n",
    "#                     start_field=FieldName.START,\n",
    "#                     target_field=FieldName.TARGET,\n",
    "#                     output_field=FieldName.FEAT_TIME,\n",
    "#                     time_features=self.time_features,\n",
    "#                     pred_length=self.prediction_length,\n",
    "#                 ),\n",
    "#                 AddAgeFeature(\n",
    "#                     target_field=FieldName.TARGET,\n",
    "#                     output_field=FieldName.FEAT_AGE,\n",
    "#                     pred_length=self.prediction_length,\n",
    "#                     log_scale=True,\n",
    "#                 ),\n",
    "                VstackFeatures(\n",
    "                    output_field=FieldName.FEAT_TIME,\n",
    "                    input_fields=[FieldName.FEAT_TIME, FieldName.FEAT_AGE]\n",
    "                    + (\n",
    "                        [FieldName.FEAT_DYNAMIC_REAL]\n",
    "                        if self.num_feat_dynamic_real > 0\n",
    "                        else []\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def _create_instance_splitter(\n",
    "        self, module: TransformerLightningModule, mode: str\n",
    "    ):\n",
    "        assert mode in [\"training\", \"validation\", \"test\"]\n",
    "\n",
    "        instance_sampler = {\n",
    "            \"training\": self.train_sampler,\n",
    "            \"validation\": self.validation_sampler,\n",
    "            \"test\": TestSplitSampler(),\n",
    "        }[mode]\n",
    "\n",
    "        return InstanceSplitter(\n",
    "            target_field=FieldName.TARGET,\n",
    "            is_pad_field=FieldName.IS_PAD,\n",
    "            start_field=FieldName.START,\n",
    "            forecast_start_field=FieldName.FORECAST_START,\n",
    "            instance_sampler=instance_sampler,\n",
    "            past_length=module.model._past_length,\n",
    "            future_length=self.prediction_length,\n",
    "            time_series_fields=[\n",
    "                FieldName.FEAT_TIME,\n",
    "                FieldName.OBSERVED_VALUES,\n",
    "            ],\n",
    "            dummy_value=self.distr_output.value_in_support,\n",
    "        )\n",
    "\n",
    "    def create_training_data_loader(\n",
    "        self,\n",
    "        data: Dataset,\n",
    "        module: TransformerLightningModule,\n",
    "        shuffle_buffer_length: Optional[int] = None,\n",
    "        **kwargs,\n",
    "    ) -> Iterable:\n",
    "        transformation = self._create_instance_splitter(\n",
    "            module, \"training\"\n",
    "        ) + SelectFields(TRAINING_INPUT_NAMES)\n",
    "\n",
    "        training_instances = transformation.apply(\n",
    "            Cyclic(data)\n",
    "            if shuffle_buffer_length is None\n",
    "            else PseudoShuffled(\n",
    "                Cyclic(data), shuffle_buffer_length=shuffle_buffer_length\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return IterableSlice(\n",
    "            iter(\n",
    "                DataLoader(\n",
    "                    IterableDataset(training_instances),\n",
    "                    batch_size=self.batch_size,\n",
    "                    pin_memory=True,\n",
    "                    persistent_workers=kwargs.get(\"num_workers\", 0) > 0,\n",
    "                    **kwargs,\n",
    "                )\n",
    "            ),\n",
    "            self.num_batches_per_epoch,\n",
    "        )\n",
    "\n",
    "    def create_validation_data_loader(\n",
    "        self,\n",
    "        data: Dataset,\n",
    "        module: TransformerLightningModule,\n",
    "        **kwargs,\n",
    "    ) -> Iterable:\n",
    "        transformation = self._create_instance_splitter(\n",
    "            module, \"validation\"\n",
    "        ) + SelectFields(TRAINING_INPUT_NAMES)\n",
    "\n",
    "        validation_instances = transformation.apply(data)\n",
    "        \n",
    "        return DataLoader(\n",
    "            IterableDataset(validation_instances),\n",
    "            batch_size=self.batch_size,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=kwargs.get(\"num_workers\", 0) > 0,\n",
    "            **kwargs,\n",
    "        )\n",
    "    \n",
    "    def create_predictor(\n",
    "        self,\n",
    "        transformation: Transformation,\n",
    "        module: TransformerLightningModule,\n",
    "    ) -> PyTorchPredictor:\n",
    "        prediction_splitter = self._create_instance_splitter(module, \"test\")\n",
    "\n",
    "        return PyTorchPredictor(\n",
    "            input_transform=transformation + prediction_splitter,\n",
    "            input_names=PREDICTION_INPUT_NAMES,\n",
    "            prediction_net=module.model,\n",
    "            batch_size=self.batch_size,\n",
    "            prediction_length=self.prediction_length,\n",
    "            device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "        )\n",
    "\n",
    "    def create_lightning_module(self) -> TransformerLightningModule:\n",
    "        model = TransformerModel(\n",
    "            freq=self.freq,\n",
    "            context_length=self.context_length,\n",
    "            prediction_length=self.prediction_length,\n",
    "            num_feat_dynamic_real=1 + self.num_feat_dynamic_real + len(self.time_features),\n",
    "            num_feat_static_real=max(1, self.num_feat_static_real),\n",
    "            num_feat_static_cat=max(1, self.num_feat_static_cat),\n",
    "            cardinality=self.cardinality,\n",
    "            embedding_dimension=self.embedding_dimension,\n",
    "\n",
    "            # transformer arguments\n",
    "            nhead=self.nhead,\n",
    "            num_encoder_layers=self.num_encoder_layers,\n",
    "            num_decoder_layers=self.num_decoder_layers,\n",
    "            activation=self.activation,\n",
    "            dropout=self.dropout,\n",
    "            dim_feedforward=self.dim_feedforward,\n",
    "\n",
    "            # univariate input\n",
    "            input_size=self.input_size,\n",
    "            distr_output=self.distr_output,\n",
    "            lags_seq=self.lags_seq,\n",
    "            scaling=self.scaling,\n",
    "            num_parallel_samples=self.num_parallel_samples,\n",
    "        )\n",
    "        \n",
    "        return TransformerLightningModule(model=model, loss=self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TransformerEstimator(\n",
    "    prediction_length=24,\n",
    "    context_length=24*10,\n",
    "    lags_seq=[1,2,3,4,5,6,7,24,30],\n",
    "    time_features=[\n",
    "        MinuteOfHour(),\n",
    "        HourOfDay(),\n",
    "        DayOfWeek(),\n",
    "        DayOfMonth(),\n",
    "        DayOfYear(),\n",
    "    ],\n",
    "\n",
    "    nhead=2,\n",
    "    num_encoder_layers=6,\n",
    "    num_decoder_layers=2,\n",
    "    dim_feedforward=32,\n",
    "    activation=\"gelu\",\n",
    "\n",
    "    scaling=True,\n",
    "  \n",
    "    batch_size=256,\n",
    "    num_batches_per_epoch=100,\n",
    "    trainer_kwargs=dict(max_epochs=150, accelerator='gpu',),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.train(\n",
    "    training_data=train_ds,\n",
    "    validation_data=val_ds,\n",
    "    num_workers=5,\n",
    "    shuffle_buffer_length=2048,\n",
    "    ckpt_path='/mnt/scratch/kashif/pytorch-transformer-ts/transformer/lightning_logs/version_200/checkpoints/epoch=87-step=8800.ckpt',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=test_ds_4, \n",
    "    predictor=predictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = list(forecast_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = list(ts_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_metrics, ts_metrics = evaluator(iter(tss), iter(forecasts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds 1\n",
    "agg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "date_formater = mdates.DateFormatter('%b, %d')\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "for idx, (forecast, ts) in islice(enumerate(zip(forecasts, tss)),9):\n",
    "    ax = plt.subplot(3, 3, idx+1)\n",
    "\n",
    "    ts[-4 * 24:].plot(ax=ax, label=\"target\", )\n",
    "    forecast.plot( color='g')\n",
    "    plt.xticks(rotation=60)\n",
    "\n",
    "plt.gcf().tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds 2\n",
    "agg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "date_formater = mdates.DateFormatter('%b, %d')\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "for idx, (forecast, ts) in islice(enumerate(zip(forecasts, tss)),9):\n",
    "    ax = plt.subplot(3, 3, idx+1)\n",
    "\n",
    "    ts[-4 * 24:].plot(ax=ax, label=\"target\", )\n",
    "    forecast.plot( color='g')\n",
    "    plt.xticks(rotation=60)\n",
    "\n",
    "plt.gcf().tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds 3\n",
    "agg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "date_formater = mdates.DateFormatter('%b, %d')\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "for idx, (forecast, ts) in islice(enumerate(zip(forecasts, tss)),9):\n",
    "    ax = plt.subplot(3, 3, idx+1)\n",
    "\n",
    "    ts[-4 * 24:].plot(ax=ax, label=\"target\", )\n",
    "    forecast.plot( color='g')\n",
    "    plt.xticks(rotation=60)\n",
    "\n",
    "plt.gcf().tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds 4\n",
    "agg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "date_formater = mdates.DateFormatter('%b, %d')\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "for idx, (forecast, ts) in islice(enumerate(zip(forecasts, tss)),9):\n",
    "    ax = plt.subplot(3, 3, idx+1)\n",
    "\n",
    "    ts[-4 * 24:].plot(ax=ax, label=\"target\", )\n",
    "    forecast.plot( color='g')\n",
    "    plt.xticks(rotation=60)\n",
    "\n",
    "plt.gcf().tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prob_forecasts(ts_entry, forecast_entry):\n",
    "    plot_length = 70\n",
    "    prediction_intervals = (50.0, 90.0)\n",
    "    legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "    ts_entry[-plot_length:].plot(ax=ax)  # plot the time series\n",
    "    forecast_entry.plot(prediction_intervals=prediction_intervals, color='g')\n",
    "    plt.grid(which=\"both\")\n",
    "    plt.legend(legend, loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2222\n",
    "plot_prob_forecasts(tss[index], forecasts[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
