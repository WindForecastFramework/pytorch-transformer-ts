{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catch22 features for all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from gluonts.dataset.common import ListDataset\n",
    "import pycatch22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for i in [\"electricity\", \"traffic\", \"m4_hourly\", \"m4_daily\", \"m4_weekly\", \"m4_monthly\", \"m4_quarterly\", \"solar-energy\"]:\n",
    "   dataset = get_dataset(i)\n",
    "   train_ds = ListDataset(dataset.train, freq=dataset.metadata.freq)\n",
    "   dff = pd.DataFrame()\n",
    "   for ts in iter(train_ds):\n",
    "      train_series = to_pandas(ts)\n",
    "      df = pd.DataFrame(pycatch22.catch22_all(list(train_series)))\n",
    "      df = df.T\n",
    "      new_header = df.iloc[0] #grab the first row for the header\n",
    "      df = df[1:] #take the data less the header row\n",
    "      df.columns = new_header #set the header row as the df header\n",
    "      \n",
    "      dff = dff.append(df)\n",
    "   dff = dff.reset_index(drop=True)\n",
    "   data = data.append(pd.DataFrame(dff.mean(axis=0)).T.reset_index(drop=True))\n",
    "   \n",
    "data['dataset'] = [\"electricity\", \"traffic\", \"m4_hourly\", \"m4_daily\", \"m4_weekly\", \"m4_monthly\", \"m4_quarterly\", \"solar-energy\"]\n",
    "data.to_csv('catch22.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import \\\n",
    "    r2_score, get_scorer\n",
    "from sklearn.linear_model import \\\n",
    "    Lasso, Ridge, LassoCV,LinearRegression\n",
    "from sklearn.preprocessing import \\\n",
    "    StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import \\\n",
    "    KFold, RepeatedKFold, GridSearchCV, \\\n",
    "    cross_validate, train_test_split\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df.csv\")\n",
    "catch22 = pd.read_csv(\"catch22.csv\")\n",
    "data = df.merge(catch22, how='left', on=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr = data[data['model']=='transformer'].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr = data[data['model']=='Hopfield'].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr = data[data['model']=='switch'].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr = data[data['model']=='Informer'].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr = data[data['model']=='etsformer'].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.get_dummies(data['dataset'])\n",
    "# data = data.merge(dataset, how='outer',left_index=True, right_index=True)\n",
    "data = data.drop(['dataset'], axis=1)\n",
    "data.model = pd.Categorical(data.model)\n",
    "data['code'] = data.model.cat.codes\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "sss.get_n_splits(data.drop(['model'], axis=1), data['code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seen data, seen model-- not possible, ideally would be same data point except that we perfrom straified split with respect to model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set: seen model, seen dataset(other model type has seen the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in sss.split(data.drop(['model'], axis=1), data['code']):\n",
    "    model_type =  pd.get_dummies(data['model'])\n",
    "    data_temp = data.merge(model_type, how='outer',left_index=True, right_index=True)\n",
    "    data_temp = data_temp.drop(['model'], axis=1)\n",
    "    X = np.array(data_temp.drop(['error','code'], axis=1))[train_index]\n",
    "    y = np.array(data_temp['error'])[train_index]\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    clf = linear_model.Lasso(alpha=0.01).fit(X, y)\n",
    "    elastic_net = ElasticNet(alpha=0.04, l1_ratio=0)\n",
    "    #lasso, elastic net,gridsearch on hyperparameter, more statistics, remove onehot encoding(dataset), add ett dataset \n",
    "    #4 quadrants of testing(unseen data, unseen model)\n",
    "    #have some sparsity(lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp=pd.DataFrame()\n",
    "temp_test = pd.DataFrame()\n",
    "for i in list(train_index):\n",
    "    temp = temp.append(data.iloc[i,:])\n",
    "for i in list(test_index):\n",
    "    temp_test = temp_test.append(data.iloc[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(data_temp.drop(['error','code'], axis=1))[test_index]\n",
    "y_test = np.array(data_temp['error'])[test_index]\n",
    "y_pred = reg.predict(X_test)\n",
    "y_pred_train = reg.predict(X)\n",
    "print('test')\n",
    "print('mse prediction:',mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 score prediction\", r2_score(y_test, y_pred))\n",
    "print(\"train\")\n",
    "print('mse prediction:',mean_squared_error(y, y_pred_train))\n",
    "print(\"R2 score prediction\", r2_score(y, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mse prediction:',mean_squared_error(y, clf.predict(X)))\n",
    "print(\"R2 score prediction\", r2_score(y, clf.predict(X)))\n",
    "print('test')\n",
    "print('mse prediction:',mean_squared_error(y_test, clf.predict(X_test)))\n",
    "print(\"R2 score prediction\", r2_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame()\n",
    "temp['features'] = list(data_temp.drop(['error','code'], axis=1).columns)\n",
    "temp['coefficient'] = reg.coef_\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y, y_pred_train)\n",
    "plt.xlabel(\"true value\")\n",
    "plt.ylabel(\"predicted value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"true value\")\n",
    "plt.ylabel(\"predicted value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set: seen model, unseen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type =  pd.get_dummies(data['model'])\n",
    "data_temp = data.merge(model_type, how='outer',left_index=True, right_index=True)\n",
    "test_data = data_temp[(data_temp['dataset']=='m4_monthly') | (data_temp['dataset']=='solar-energy')].reset_index(drop=True).drop(['model', 'dataset'], axis=1)\n",
    "train_data = data_temp[(data_temp['dataset']!='m4_monthly') & (data_temp['dataset']!='solar-energy')].reset_index(drop=True).drop(['model', 'dataset'], axis=1)\n",
    "reg = LinearRegression().fit(train_data.drop(['error'], axis=1), train_data['error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop(['error'], axis=1)\n",
    "y_test = test_data['error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "y_pred_train = reg.predict(train_data.drop(['error'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('mse prediction:',mean_squared_error(y, clf.predict(X)))\n",
    "# print(\"R2 score prediction\", r2_score(y, clf.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('MSE:',mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE:',mean_squared_error(train_data['error'], y_pred_train))\n",
    "print(\"R2 score:\", r2_score(train_data['error'], y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame()\n",
    "temp['features'] = list(train_data.drop(['error'], axis=1).columns)\n",
    "temp['coefficient'] = reg.coef_\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_data['error'], y_pred_train)\n",
    "plt.xlabel(\"true value\")\n",
    "plt.ylabel(\"predicted value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"true value\")\n",
    "plt.ylabel(\"predicted value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### seen data, unseen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df.csv\")\n",
    "catch22 = pd.read_csv(\"catch22.csv\")\n",
    "data = df.merge(catch22, how='left', on=\"dataset\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data[(data['model']=='linformer')|(data['model']=='Informer')].reset_index(drop=True).drop(['model', 'dataset'], axis=1)\n",
    "train_data = data[(data['model']!='linformer')&(data['model']!='Informer')].reset_index(drop=True).drop(['model', 'dataset'], axis=1)\n",
    "reg = LinearRegression().fit(train_data.drop(['error'], axis=1), train_data['error'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = test_data.drop(['error'], axis=1)\n",
    "y_test = test_data['error']\n",
    "y_pred = reg.predict(X_test)\n",
    "y_pred_train = reg.predict(train_data.drop(['error'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Test data\")\n",
    "print('MSE:',mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred))\n",
    "print(\"Train data\")\n",
    "print('MSE:',mean_squared_error(train_data['error'], y_pred_train))\n",
    "print(\"R2 score:\", r2_score(train_data['error'], y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_data['error'], y_pred_train)\n",
    "plt.xlabel(\"true value\")\n",
    "plt.ylabel(\"predicted value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"true value\")\n",
    "plt.ylabel(\"predicted value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unseen data, unseen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df.csv\")\n",
    "catch22 = pd.read_csv(\"catch22.csv\")\n",
    "data = df.merge(catch22, how='left', on=\"dataset\")\n",
    "model_type =  pd.get_dummies(data['model'])\n",
    "data_temp = data.merge(model_type, how='outer',left_index=True, right_index=True)\n",
    "test_data = data_temp[((data_temp['model']=='linformer')|(data_temp['model']=='Informer') | (data_temp['model']=='nystorm')) & ((data_temp['dataset']=='m4_quarterly') | (data_temp['dataset']=='m4_weekly') | (data_temp['dataset']=='m4_daily'))].reset_index(drop=True).drop(['model', 'dataset'], axis=1)\n",
    "train_data = data_temp[(data_temp['model']!='linformer')&(data_temp['model']!='Informer')&(data_temp['model']!='nystorm')&(data_temp['dataset']!='m4_quarterly')& (data_temp['dataset']!='m4_weekly') & (data_temp['dataset']!='m4_daily')].reset_index(drop=True).drop(['model', 'dataset'], axis=1)\n",
    "\n",
    "train_x = train_data.drop(['error'],axis=1)\n",
    "train_y = train_data['error']\n",
    "test_x = test_data.drop(['error'], axis=1)\n",
    "test_y = test_data['error']\n",
    "\n",
    "\n",
    "reg = LinearRegression().fit(train_x, train_y)\n",
    "y_pred = reg.predict(test_x)\n",
    "y_pred_train = reg.predict(train_x)\n",
    "print(\"Test data\")\n",
    "print('mse prediction:',mean_squared_error(test_y, y_pred))\n",
    "print(\"R2 score prediction\", r2_score(test_y, y_pred))\n",
    "print(\"Train data\")\n",
    "print('mse prediction:',mean_squared_error(train_y, y_pred_train))\n",
    "print(\"R2 score prediction\", r2_score(train_y, y_pred_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp[((data_temp['model']=='linformer')|(data_temp['model']=='Informer') | (data_temp['model']=='nystorm')) & ((data_temp['dataset']=='m4_quarterly') | (data_temp['dataset']=='m4_weekly') | (data_temp['dataset']=='m4_daily'))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in sss.split(data.drop(['model'], axis=1), data['code']):\n",
    "     model_type =  pd.get_dummies(data['model'])\n",
    "     data_temp = data.merge(model_type, how='outer',left_index=True, right_index=True)\n",
    "     data_temp = data_temp.drop(['model'], axis=1)\n",
    "     X = np.array(data_temp.drop(['error','code'], axis=1))[train_index]\n",
    "     y = np.array(data_temp['error'])[train_index]\n",
    "     \n",
    "\n",
    "     sc = StandardScaler()\n",
    "     X_scaled = sc.fit_transform(X)\n",
    "     # X_scaled = pd.DataFrame(data = X_scaled, columns = X.columns)\n",
    "     cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "     lasso_alphas = np.linspace(0, 0.2, 21)\n",
    "     lasso = Lasso()\n",
    "     grid = dict()\n",
    "     grid['alpha'] = lasso_alphas\n",
    "     gscv = GridSearchCV( lasso, grid, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "     results = gscv.fit(X_scaled, y)\n",
    "     print('MSE: %.5f' % results.best_score_)\n",
    "     print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#elastic net\n",
    "\n",
    "\n",
    "for train_index, test_index in sss.split(data.drop(['model'], axis=1), data['code']):\n",
    "    model_type =  pd.get_dummies(data['model'])\n",
    "    data_temp = data.merge(model_type, how='outer',left_index=True, right_index=True)\n",
    "    data_temp = data_temp.drop(['model'], axis=1)\n",
    "    X = np.array(data_temp.drop(['error','code'], axis=1))[train_index]\n",
    "    y = np.array(data_temp['error'])[train_index]\n",
    "\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_scaled = sc.fit_transform(X)\n",
    "    # X_scaled = pd.DataFrame(data = X_scaled, columns = X.columns)\n",
    "    param_grid = [\n",
    "    {'alpha': np.linspace(0, 0.2, 21), 'l1_ratio': [0, 0.2, .5, .8, 1]},]\n",
    "    elastic_net = ElasticNet()\n",
    "    grid_search = GridSearchCV(elastic_net, param_grid, cv=5,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            return_train_score=True)\n",
    "    grid_search.fit(X, y)\n",
    "    cvres = grid_search.cv_results_\n",
    "    for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "        print(np.sqrt(-mean_score), params)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(model, X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    train_errors, val_errors = [], []\n",
    "    for m in range(1, len(X_train)):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = model.predict(X_train[:m])\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        train_errors.append(mean_squared_error(y_train_predict, y_train[:m]))\n",
    "        val_errors.append(mean_squared_error(y_val_predict, y_val))\n",
    "        plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
    "        plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(lasso,X,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(elastic_net,X,y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "rapids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "766cfe2864b800c6196a6f9652521f0de5a64fb97f94472e69f0b3f394df521a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
