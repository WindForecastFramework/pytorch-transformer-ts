{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catch22 features for all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/gluonts/json.py:102: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  \"Using `json`-module for json-handling. \"\n"
     ]
    }
   ],
   "source": [
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from gluonts.dataset.common import ListDataset\n",
    "import pycatch22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for i in [\"electricity\", \"traffic\", \"m4_hourly\", \"m4_daily\", \"m4_weekly\", \"m4_monthly\", \"m4_quarterly\", \"solar-energy\"]:\n",
    "   dataset = get_dataset(i)\n",
    "   train_ds = ListDataset(dataset.train, freq=dataset.metadata.freq)\n",
    "   dff = pd.DataFrame()\n",
    "   for ts in iter(train_ds):\n",
    "      train_series = to_pandas(ts)\n",
    "      df = pd.DataFrame(pycatch22.catch22_all(list(train_series)))\n",
    "      df = df.T\n",
    "      new_header = df.iloc[0] #grab the first row for the header\n",
    "      df = df[1:] #take the data less the header row\n",
    "      df.columns = new_header #set the header row as the df header\n",
    "      \n",
    "      dff = dff.append(df)\n",
    "   dff = dff.reset_index(drop=True)\n",
    "   data = data.append(pd.DataFrame(dff.mean(axis=0)).T.reset_index(drop=True))\n",
    "   \n",
    "data['dataset'] = [\"electricity\", \"traffic\", \"m4_hourly\", \"m4_daily\", \"m4_weekly\", \"m4_monthly\", \"m4_quarterly\", \"solar-energy\"]\n",
    "data.to_csv('catch22.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import \\\n",
    "    r2_score, get_scorer\n",
    "from sklearn.linear_model import \\\n",
    "    Lasso, Ridge, LassoCV,LinearRegression\n",
    "from sklearn.preprocessing import \\\n",
    "    StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import \\\n",
    "    KFold, RepeatedKFold, GridSearchCV, \\\n",
    "    cross_validate, train_test_split\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df.csv\")\n",
    "catch22 = pd.read_csv(\"catch22.csv\")\n",
    "data = df.merge(catch22, how='left', on=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>error</th>\n",
       "      <th>dataset</th>\n",
       "      <th>DN_HistogramMode_5</th>\n",
       "      <th>DN_HistogramMode_10</th>\n",
       "      <th>CO_f1ecac</th>\n",
       "      <th>CO_FirstMin_ac</th>\n",
       "      <th>CO_HistogramAMI_even_2_5</th>\n",
       "      <th>CO_trev_1_num</th>\n",
       "      <th>MD_hrv_classic_pnn40</th>\n",
       "      <th>...</th>\n",
       "      <th>FC_LocalSimple_mean1_tauresrat</th>\n",
       "      <th>DN_OutlierInclude_p_001_mdrmd</th>\n",
       "      <th>DN_OutlierInclude_n_001_mdrmd</th>\n",
       "      <th>SP_Summaries_welch_rect_area_5_1</th>\n",
       "      <th>SB_BinaryStats_diff_longstretch0</th>\n",
       "      <th>SB_MotifThree_quantile_hh</th>\n",
       "      <th>SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1</th>\n",
       "      <th>SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1</th>\n",
       "      <th>SP_Summaries_welch_rect_centroid</th>\n",
       "      <th>FC_LocalSimple_mean3_stderr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformer</td>\n",
       "      <td>0.071823</td>\n",
       "      <td>electricity</td>\n",
       "      <td>-0.028579</td>\n",
       "      <td>-0.015877</td>\n",
       "      <td>68.972046</td>\n",
       "      <td>11.551402</td>\n",
       "      <td>0.328209</td>\n",
       "      <td>0.034421</td>\n",
       "      <td>0.796559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530281</td>\n",
       "      <td>-0.110817</td>\n",
       "      <td>0.019799</td>\n",
       "      <td>0.922117</td>\n",
       "      <td>13.551402</td>\n",
       "      <td>1.666226</td>\n",
       "      <td>0.551215</td>\n",
       "      <td>0.500312</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.612052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformer</td>\n",
       "      <td>0.142111</td>\n",
       "      <td>traffic</td>\n",
       "      <td>-0.218283</td>\n",
       "      <td>-0.272866</td>\n",
       "      <td>3.967025</td>\n",
       "      <td>11.607889</td>\n",
       "      <td>0.127119</td>\n",
       "      <td>-0.047471</td>\n",
       "      <td>0.821459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424628</td>\n",
       "      <td>0.044064</td>\n",
       "      <td>-0.015226</td>\n",
       "      <td>0.819510</td>\n",
       "      <td>16.247100</td>\n",
       "      <td>1.656631</td>\n",
       "      <td>0.182877</td>\n",
       "      <td>0.602227</td>\n",
       "      <td>0.285211</td>\n",
       "      <td>0.764539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transformer</td>\n",
       "      <td>0.081466</td>\n",
       "      <td>m4_hourly</td>\n",
       "      <td>-0.406036</td>\n",
       "      <td>-0.565346</td>\n",
       "      <td>5.103959</td>\n",
       "      <td>11.608696</td>\n",
       "      <td>0.492538</td>\n",
       "      <td>0.008895</td>\n",
       "      <td>0.885336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677594</td>\n",
       "      <td>0.181327</td>\n",
       "      <td>-0.199676</td>\n",
       "      <td>0.934384</td>\n",
       "      <td>13.978261</td>\n",
       "      <td>1.622224</td>\n",
       "      <td>0.236598</td>\n",
       "      <td>0.529259</td>\n",
       "      <td>0.265386</td>\n",
       "      <td>0.567447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transformer</td>\n",
       "      <td>0.066343</td>\n",
       "      <td>m4_daily</td>\n",
       "      <td>-0.172686</td>\n",
       "      <td>-0.206331</td>\n",
       "      <td>290.202151</td>\n",
       "      <td>720.344689</td>\n",
       "      <td>1.074898</td>\n",
       "      <td>-0.029044</td>\n",
       "      <td>0.434763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016825</td>\n",
       "      <td>0.234980</td>\n",
       "      <td>-0.265987</td>\n",
       "      <td>0.983666</td>\n",
       "      <td>9.890229</td>\n",
       "      <td>1.309419</td>\n",
       "      <td>0.429876</td>\n",
       "      <td>0.653066</td>\n",
       "      <td>0.018977</td>\n",
       "      <td>0.124719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformer</td>\n",
       "      <td>0.155053</td>\n",
       "      <td>m4_weekly</td>\n",
       "      <td>-0.377490</td>\n",
       "      <td>-0.441451</td>\n",
       "      <td>126.895132</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.796780</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>0.532645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034918</td>\n",
       "      <td>0.307455</td>\n",
       "      <td>-0.174684</td>\n",
       "      <td>0.902329</td>\n",
       "      <td>9.495822</td>\n",
       "      <td>1.490107</td>\n",
       "      <td>0.400648</td>\n",
       "      <td>0.662246</td>\n",
       "      <td>0.086446</td>\n",
       "      <td>0.296566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         model     error      dataset  DN_HistogramMode_5  \\\n",
       "0  transformer  0.071823  electricity           -0.028579   \n",
       "1  transformer  0.142111      traffic           -0.218283   \n",
       "2  transformer  0.081466    m4_hourly           -0.406036   \n",
       "3  transformer  0.066343     m4_daily           -0.172686   \n",
       "4  transformer  0.155053    m4_weekly           -0.377490   \n",
       "\n",
       "   DN_HistogramMode_10   CO_f1ecac  CO_FirstMin_ac  CO_HistogramAMI_even_2_5  \\\n",
       "0            -0.015877   68.972046       11.551402                  0.328209   \n",
       "1            -0.272866    3.967025       11.607889                  0.127119   \n",
       "2            -0.565346    5.103959       11.608696                  0.492538   \n",
       "3            -0.206331  290.202151      720.344689                  1.074898   \n",
       "4            -0.441451  126.895132      326.000000                  0.796780   \n",
       "\n",
       "   CO_trev_1_num  MD_hrv_classic_pnn40  ...  FC_LocalSimple_mean1_tauresrat  \\\n",
       "0       0.034421              0.796559  ...                        0.530281   \n",
       "1      -0.047471              0.821459  ...                        0.424628   \n",
       "2       0.008895              0.885336  ...                        0.677594   \n",
       "3      -0.029044              0.434763  ...                        0.016825   \n",
       "4       0.008714              0.532645  ...                        0.034918   \n",
       "\n",
       "   DN_OutlierInclude_p_001_mdrmd  DN_OutlierInclude_n_001_mdrmd  \\\n",
       "0                      -0.110817                       0.019799   \n",
       "1                       0.044064                      -0.015226   \n",
       "2                       0.181327                      -0.199676   \n",
       "3                       0.234980                      -0.265987   \n",
       "4                       0.307455                      -0.174684   \n",
       "\n",
       "   SP_Summaries_welch_rect_area_5_1  SB_BinaryStats_diff_longstretch0  \\\n",
       "0                          0.922117                         13.551402   \n",
       "1                          0.819510                         16.247100   \n",
       "2                          0.934384                         13.978261   \n",
       "3                          0.983666                          9.890229   \n",
       "4                          0.902329                          9.495822   \n",
       "\n",
       "   SB_MotifThree_quantile_hh  SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1  \\\n",
       "0                   1.666226                                     0.551215   \n",
       "1                   1.656631                                     0.182877   \n",
       "2                   1.622224                                     0.236598   \n",
       "3                   1.309419                                     0.429876   \n",
       "4                   1.490107                                     0.400648   \n",
       "\n",
       "   SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1  SP_Summaries_welch_rect_centroid  \\\n",
       "0                                0.500312                          0.237013   \n",
       "1                                0.602227                          0.285211   \n",
       "2                                0.529259                          0.265386   \n",
       "3                                0.653066                          0.018977   \n",
       "4                                0.662246                          0.086446   \n",
       "\n",
       "   FC_LocalSimple_mean3_stderr  \n",
       "0                     0.612052  \n",
       "1                     0.764539  \n",
       "2                     0.567447  \n",
       "3                     0.124719  \n",
       "4                     0.296566  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d0/l9cqdxf90hbg0dj97q8bs7kc0000gn/T/ipykernel_76447/2251774514.py:2: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "  corr.style.background_gradient(cmap='coolwarm').set_precision(2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f9225_row0_col0, #T_f9225_row1_col1, #T_f9225_row2_col2, #T_f9225_row3_col3, #T_f9225_row4_col4, #T_f9225_row5_col5, #T_f9225_row6_col6, #T_f9225_row7_col7, #T_f9225_row8_col8, #T_f9225_row9_col9, #T_f9225_row10_col10, #T_f9225_row11_col11, #T_f9225_row12_col12, #T_f9225_row13_col13, #T_f9225_row14_col14, #T_f9225_row15_col15, #T_f9225_row16_col16, #T_f9225_row17_col17, #T_f9225_row18_col18, #T_f9225_row19_col19, #T_f9225_row20_col20, #T_f9225_row21_col21, #T_f9225_row22_col22 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row0_col1 {\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row0_col2, #T_f9225_row20_col21 {\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row0_col3, #T_f9225_row0_col19, #T_f9225_row13_col12, #T_f9225_row17_col12 {\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row0_col4, #T_f9225_row0_col10 {\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row0_col5, #T_f9225_row13_col5 {\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row0_col6 {\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row0_col7, #T_f9225_row4_col6 {\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row0_col8, #T_f9225_row2_col20, #T_f9225_row11_col13, #T_f9225_row12_col2, #T_f9225_row17_col4, #T_f9225_row20_col1, #T_f9225_row21_col11 {\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row0_col9, #T_f9225_row19_col4 {\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row0_col11, #T_f9225_row1_col0, #T_f9225_row2_col13, #T_f9225_row4_col1 {\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row0_col12, #T_f9225_row10_col6, #T_f9225_row19_col22 {\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row0_col13, #T_f9225_row10_col3, #T_f9225_row16_col19, #T_f9225_row19_col16, #T_f9225_row21_col7 {\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row0_col14, #T_f9225_row7_col0, #T_f9225_row12_col1, #T_f9225_row13_col10 {\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row0_col15, #T_f9225_row10_col9, #T_f9225_row19_col9 {\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row0_col16, #T_f9225_row2_col4, #T_f9225_row18_col19, #T_f9225_row20_col0 {\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row0_col17, #T_f9225_row3_col19, #T_f9225_row6_col18, #T_f9225_row19_col8 {\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row0_col18, #T_f9225_row6_col4, #T_f9225_row6_col19 {\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row0_col20, #T_f9225_row2_col17, #T_f9225_row8_col19 {\n",
       "  background-color: #ead5c9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row0_col21, #T_f9225_row3_col10, #T_f9225_row15_col21 {\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row0_col22, #T_f9225_row3_col16 {\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row1_col2 {\n",
       "  background-color: #b8122a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row1_col3, #T_f9225_row13_col11, #T_f9225_row16_col0 {\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row1_col4 {\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row1_col5, #T_f9225_row7_col12, #T_f9225_row8_col21, #T_f9225_row17_col3 {\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row1_col6 {\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row1_col7, #T_f9225_row14_col3, #T_f9225_row18_col21, #T_f9225_row21_col1 {\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row1_col8, #T_f9225_row2_col8, #T_f9225_row13_col4, #T_f9225_row17_col10, #T_f9225_row21_col4, #T_f9225_row22_col20 {\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row1_col9, #T_f9225_row4_col15, #T_f9225_row9_col1, #T_f9225_row18_col16, #T_f9225_row19_col10 {\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row1_col10, #T_f9225_row19_col11 {\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row1_col11, #T_f9225_row8_col2 {\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row1_col12, #T_f9225_row8_col1, #T_f9225_row22_col6 {\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row1_col13 {\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row1_col14, #T_f9225_row6_col22, #T_f9225_row19_col14 {\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row1_col15, #T_f9225_row14_col11 {\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row1_col16, #T_f9225_row3_col0 {\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row1_col17 {\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row1_col18, #T_f9225_row22_col2 {\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row1_col19, #T_f9225_row3_col21, #T_f9225_row22_col4 {\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row1_col20, #T_f9225_row11_col1, #T_f9225_row21_col12 {\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row1_col21, #T_f9225_row7_col1, #T_f9225_row13_col20 {\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row1_col22, #T_f9225_row5_col8, #T_f9225_row8_col4, #T_f9225_row20_col11 {\n",
       "  background-color: #ec7f63;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row2_col0, #T_f9225_row19_col12, #T_f9225_row19_col17, #T_f9225_row19_col18 {\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row2_col1 {\n",
       "  background-color: #b70d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row2_col3 {\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row2_col5, #T_f9225_row5_col22, #T_f9225_row7_col4, #T_f9225_row13_col14, #T_f9225_row18_col20, #T_f9225_row22_col9 {\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row2_col6, #T_f9225_row2_col14 {\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row2_col7, #T_f9225_row2_col21, #T_f9225_row5_col3, #T_f9225_row10_col2 {\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row2_col9, #T_f9225_row9_col0 {\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row2_col10 {\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row2_col11, #T_f9225_row2_col12, #T_f9225_row10_col21 {\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row2_col15, #T_f9225_row13_col21, #T_f9225_row16_col11 {\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row2_col16, #T_f9225_row7_col5, #T_f9225_row12_col21 {\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row2_col18, #T_f9225_row3_col11, #T_f9225_row5_col20, #T_f9225_row10_col14 {\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row2_col19, #T_f9225_row5_col1, #T_f9225_row5_col2, #T_f9225_row8_col13, #T_f9225_row11_col15, #T_f9225_row11_col18, #T_f9225_row11_col22, #T_f9225_row12_col7, #T_f9225_row12_col18, #T_f9225_row13_col3, #T_f9225_row14_col17, #T_f9225_row14_col21, #T_f9225_row15_col5, #T_f9225_row15_col9, #T_f9225_row15_col20, #T_f9225_row17_col14, #T_f9225_row18_col4, #T_f9225_row18_col10, #T_f9225_row18_col11, #T_f9225_row18_col12, #T_f9225_row19_col0, #T_f9225_row21_col3, #T_f9225_row21_col6, #T_f9225_row21_col14, #T_f9225_row22_col8, #T_f9225_row22_col16 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row2_col22 {\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row3_col1, #T_f9225_row10_col0 {\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row3_col2, #T_f9225_row22_col19 {\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row3_col4, #T_f9225_row16_col14, #T_f9225_row20_col4, #T_f9225_row20_col5 {\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row3_col5 {\n",
       "  background-color: #f7ba9f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row3_col6, #T_f9225_row6_col3 {\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row3_col7, #T_f9225_row18_col0, #T_f9225_row20_col2 {\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row3_col8, #T_f9225_row8_col3 {\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row3_col9, #T_f9225_row16_col8 {\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row3_col12, #T_f9225_row5_col14, #T_f9225_row8_col14, #T_f9225_row14_col8 {\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row3_col13, #T_f9225_row13_col8, #T_f9225_row15_col11, #T_f9225_row21_col8 {\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row3_col14, #T_f9225_row7_col13, #T_f9225_row8_col16, #T_f9225_row9_col20, #T_f9225_row14_col10, #T_f9225_row17_col18 {\n",
       "  background-color: #f7b497;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row3_col15, #T_f9225_row3_col18 {\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row3_col17, #T_f9225_row4_col7, #T_f9225_row7_col11, #T_f9225_row16_col22, #T_f9225_row22_col10 {\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row3_col20, #T_f9225_row14_col19 {\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row3_col22, #T_f9225_row11_col0 {\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row4_col0, #T_f9225_row10_col13, #T_f9225_row13_col6 {\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row4_col2, #T_f9225_row17_col0 {\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row4_col3, #T_f9225_row13_col7 {\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row4_col5, #T_f9225_row5_col4, #T_f9225_row18_col1 {\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row4_col8, #T_f9225_row22_col1 {\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row4_col9, #T_f9225_row9_col4, #T_f9225_row16_col12 {\n",
       "  background-color: #f18f71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row4_col10, #T_f9225_row4_col12, #T_f9225_row12_col4 {\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row4_col11 {\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row4_col13, #T_f9225_row10_col18, #T_f9225_row16_col15 {\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row4_col14, #T_f9225_row10_col11, #T_f9225_row14_col9, #T_f9225_row15_col2, #T_f9225_row21_col13 {\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row4_col16, #T_f9225_row13_col22, #T_f9225_row16_col9 {\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row4_col17, #T_f9225_row13_col9, #T_f9225_row21_col9 {\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row4_col18, #T_f9225_row6_col17, #T_f9225_row6_col21, #T_f9225_row7_col10, #T_f9225_row17_col8 {\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row4_col19 {\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row4_col20 {\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row4_col21, #T_f9225_row5_col17, #T_f9225_row21_col5 {\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row4_col22, #T_f9225_row8_col22, #T_f9225_row9_col22 {\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row5_col0, #T_f9225_row9_col2, #T_f9225_row20_col6 {\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row5_col6 {\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row5_col7, #T_f9225_row5_col21 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row5_col9, #T_f9225_row9_col5 {\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row5_col10, #T_f9225_row11_col19 {\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row5_col11, #T_f9225_row5_col12, #T_f9225_row9_col11, #T_f9225_row22_col15 {\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row5_col13, #T_f9225_row15_col19, #T_f9225_row17_col11 {\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row5_col15, #T_f9225_row14_col0, #T_f9225_row22_col5 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row5_col16, #T_f9225_row8_col9, #T_f9225_row12_col14 {\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row5_col18 {\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row5_col19, #T_f9225_row18_col2 {\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row6_col0 {\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row6_col1 {\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row6_col2, #T_f9225_row21_col19 {\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row6_col5 {\n",
       "  background-color: #ebd3c6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row6_col7, #T_f9225_row19_col13, #T_f9225_row20_col10 {\n",
       "  background-color: #f2c9b4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row6_col8, #T_f9225_row18_col6, #T_f9225_row20_col8 {\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row6_col9, #T_f9225_row6_col12, #T_f9225_row8_col20 {\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row6_col10, #T_f9225_row14_col1 {\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row6_col11 {\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row6_col13, #T_f9225_row10_col15 {\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row6_col14, #T_f9225_row14_col16 {\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row6_col15, #T_f9225_row16_col10 {\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row6_col16 {\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row6_col20, #T_f9225_row8_col7, #T_f9225_row15_col16, #T_f9225_row16_col2, #T_f9225_row20_col18 {\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row7_col2 {\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row7_col3, #T_f9225_row16_col18 {\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row7_col6, #T_f9225_row10_col1, #T_f9225_row13_col0, #T_f9225_row13_col15, #T_f9225_row15_col17, #T_f9225_row17_col2 {\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row7_col8, #T_f9225_row16_col21 {\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row7_col9, #T_f9225_row8_col0, #T_f9225_row8_col17, #T_f9225_row11_col7, #T_f9225_row18_col9 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row7_col14, #T_f9225_row9_col17, #T_f9225_row12_col0 {\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row7_col15, #T_f9225_row8_col12, #T_f9225_row15_col7, #T_f9225_row15_col22 {\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row7_col16 {\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row7_col17, #T_f9225_row21_col2 {\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row7_col18, #T_f9225_row18_col7 {\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row7_col19, #T_f9225_row9_col19 {\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row7_col20, #T_f9225_row21_col16 {\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row7_col21, #T_f9225_row13_col19, #T_f9225_row16_col20 {\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row7_col22, #T_f9225_row14_col12, #T_f9225_row22_col7 {\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row8_col5, #T_f9225_row11_col16, #T_f9225_row22_col17 {\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row8_col6 {\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row8_col10, #T_f9225_row10_col20, #T_f9225_row13_col18 {\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row8_col11, #T_f9225_row11_col14 {\n",
       "  background-color: #e67259;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row8_col15, #T_f9225_row12_col17 {\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row8_col18 {\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row9_col3, #T_f9225_row17_col20, #T_f9225_row18_col17, #T_f9225_row21_col15 {\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row9_col6 {\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row9_col7, #T_f9225_row16_col1, #T_f9225_row18_col5, #T_f9225_row19_col1 {\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row9_col8 {\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row9_col10, #T_f9225_row17_col19 {\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row9_col12, #T_f9225_row12_col9 {\n",
       "  background-color: #cb3e38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row9_col13 {\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row9_col14, #T_f9225_row11_col8 {\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row9_col15, #T_f9225_row15_col12 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row9_col16 {\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row9_col18, #T_f9225_row14_col22 {\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row9_col21, #T_f9225_row17_col16 {\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row10_col4, #T_f9225_row11_col4 {\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row10_col5, #T_f9225_row15_col6 {\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row10_col7, #T_f9225_row18_col3 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row10_col8 {\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row10_col12, #T_f9225_row14_col5 {\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row10_col16, #T_f9225_row20_col16 {\n",
       "  background-color: #f5c2aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row10_col17, #T_f9225_row16_col7, #T_f9225_row20_col22 {\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row10_col19, #T_f9225_row10_col22, #T_f9225_row15_col3, #T_f9225_row17_col9, #T_f9225_row21_col10 {\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row11_col2, #T_f9225_row14_col7, #T_f9225_row17_col5 {\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row11_col3, #T_f9225_row17_col7 {\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row11_col5, #T_f9225_row12_col5, #T_f9225_row12_col8 {\n",
       "  background-color: #d55042;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row11_col6 {\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row11_col9 {\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row11_col10, #T_f9225_row11_col20 {\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row11_col12, #T_f9225_row12_col11 {\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row11_col17, #T_f9225_row15_col14 {\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row11_col21, #T_f9225_row20_col7 {\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row12_col3, #T_f9225_row12_col10, #T_f9225_row12_col16 {\n",
       "  background-color: #f39577;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row12_col6, #T_f9225_row13_col1 {\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row12_col13 {\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row12_col15, #T_f9225_row12_col22, #T_f9225_row17_col6, #T_f9225_row22_col14 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row12_col19 {\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row12_col20, #T_f9225_row14_col6, #T_f9225_row16_col4 {\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row13_col2, #T_f9225_row16_col13, #T_f9225_row20_col14 {\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row13_col16 {\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row13_col17 {\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row14_col2 {\n",
       "  background-color: #b3cdfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row14_col4, #T_f9225_row17_col22 {\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row14_col13, #T_f9225_row19_col2, #T_f9225_row22_col11, #T_f9225_row22_col12 {\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row14_col15 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row14_col18 {\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row14_col20, #T_f9225_row19_col6 {\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row15_col0 {\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row15_col1, #T_f9225_row16_col5 {\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row15_col4 {\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row15_col8, #T_f9225_row22_col3 {\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row15_col10 {\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row15_col13, #T_f9225_row19_col3 {\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row15_col18, #T_f9225_row18_col15 {\n",
       "  background-color: #c32e31;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row16_col3 {\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row16_col6 {\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row16_col17 {\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row17_col1, #T_f9225_row18_col13, #T_f9225_row21_col20 {\n",
       "  background-color: #f1ccb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row17_col13 {\n",
       "  background-color: #da5a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row17_col15 {\n",
       "  background-color: #f1cdba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row17_col21, #T_f9225_row21_col17 {\n",
       "  background-color: #ba162b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row18_col8, #T_f9225_row20_col15 {\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row18_col14 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row18_col22, #T_f9225_row22_col18 {\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row19_col5, #T_f9225_row21_col18 {\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row19_col7 {\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row19_col15 {\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row19_col20 {\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row19_col21 {\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row20_col3 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row20_col9 {\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row20_col12 {\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row20_col13, #T_f9225_row20_col17 {\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row20_col19, #T_f9225_row21_col0 {\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row21_col22 {\n",
       "  background-color: #dc5d4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9225_row22_col0 {\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row22_col13 {\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9225_row22_col21 {\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f9225\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f9225_level0_col0\" class=\"col_heading level0 col0\" >error</th>\n",
       "      <th id=\"T_f9225_level0_col1\" class=\"col_heading level0 col1\" >DN_HistogramMode_5</th>\n",
       "      <th id=\"T_f9225_level0_col2\" class=\"col_heading level0 col2\" >DN_HistogramMode_10</th>\n",
       "      <th id=\"T_f9225_level0_col3\" class=\"col_heading level0 col3\" >CO_f1ecac</th>\n",
       "      <th id=\"T_f9225_level0_col4\" class=\"col_heading level0 col4\" >CO_FirstMin_ac</th>\n",
       "      <th id=\"T_f9225_level0_col5\" class=\"col_heading level0 col5\" >CO_HistogramAMI_even_2_5</th>\n",
       "      <th id=\"T_f9225_level0_col6\" class=\"col_heading level0 col6\" >CO_trev_1_num</th>\n",
       "      <th id=\"T_f9225_level0_col7\" class=\"col_heading level0 col7\" >MD_hrv_classic_pnn40</th>\n",
       "      <th id=\"T_f9225_level0_col8\" class=\"col_heading level0 col8\" >SB_BinaryStats_mean_longstretch1</th>\n",
       "      <th id=\"T_f9225_level0_col9\" class=\"col_heading level0 col9\" >SB_TransitionMatrix_3ac_sumdiagcov</th>\n",
       "      <th id=\"T_f9225_level0_col10\" class=\"col_heading level0 col10\" >PD_PeriodicityWang_th0_01</th>\n",
       "      <th id=\"T_f9225_level0_col11\" class=\"col_heading level0 col11\" >CO_Embed2_Dist_tau_d_expfit_meandiff</th>\n",
       "      <th id=\"T_f9225_level0_col12\" class=\"col_heading level0 col12\" >IN_AutoMutualInfoStats_40_gaussian_fmmi</th>\n",
       "      <th id=\"T_f9225_level0_col13\" class=\"col_heading level0 col13\" >FC_LocalSimple_mean1_tauresrat</th>\n",
       "      <th id=\"T_f9225_level0_col14\" class=\"col_heading level0 col14\" >DN_OutlierInclude_p_001_mdrmd</th>\n",
       "      <th id=\"T_f9225_level0_col15\" class=\"col_heading level0 col15\" >DN_OutlierInclude_n_001_mdrmd</th>\n",
       "      <th id=\"T_f9225_level0_col16\" class=\"col_heading level0 col16\" >SP_Summaries_welch_rect_area_5_1</th>\n",
       "      <th id=\"T_f9225_level0_col17\" class=\"col_heading level0 col17\" >SB_BinaryStats_diff_longstretch0</th>\n",
       "      <th id=\"T_f9225_level0_col18\" class=\"col_heading level0 col18\" >SB_MotifThree_quantile_hh</th>\n",
       "      <th id=\"T_f9225_level0_col19\" class=\"col_heading level0 col19\" >SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1</th>\n",
       "      <th id=\"T_f9225_level0_col20\" class=\"col_heading level0 col20\" >SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1</th>\n",
       "      <th id=\"T_f9225_level0_col21\" class=\"col_heading level0 col21\" >SP_Summaries_welch_rect_centroid</th>\n",
       "      <th id=\"T_f9225_level0_col22\" class=\"col_heading level0 col22\" >FC_LocalSimple_mean3_stderr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row0\" class=\"row_heading level0 row0\" >error</th>\n",
       "      <td id=\"T_f9225_row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "      <td id=\"T_f9225_row0_col1\" class=\"data row0 col1\" >0.13</td>\n",
       "      <td id=\"T_f9225_row0_col2\" class=\"data row0 col2\" >0.27</td>\n",
       "      <td id=\"T_f9225_row0_col3\" class=\"data row0 col3\" >-0.37</td>\n",
       "      <td id=\"T_f9225_row0_col4\" class=\"data row0 col4\" >-0.07</td>\n",
       "      <td id=\"T_f9225_row0_col5\" class=\"data row0 col5\" >-0.30</td>\n",
       "      <td id=\"T_f9225_row0_col6\" class=\"data row0 col6\" >-0.10</td>\n",
       "      <td id=\"T_f9225_row0_col7\" class=\"data row0 col7\" >-0.15</td>\n",
       "      <td id=\"T_f9225_row0_col8\" class=\"data row0 col8\" >-0.39</td>\n",
       "      <td id=\"T_f9225_row0_col9\" class=\"data row0 col9\" >-0.28</td>\n",
       "      <td id=\"T_f9225_row0_col10\" class=\"data row0 col10\" >0.06</td>\n",
       "      <td id=\"T_f9225_row0_col11\" class=\"data row0 col11\" >-0.18</td>\n",
       "      <td id=\"T_f9225_row0_col12\" class=\"data row0 col12\" >-0.20</td>\n",
       "      <td id=\"T_f9225_row0_col13\" class=\"data row0 col13\" >0.37</td>\n",
       "      <td id=\"T_f9225_row0_col14\" class=\"data row0 col14\" >-0.43</td>\n",
       "      <td id=\"T_f9225_row0_col15\" class=\"data row0 col15\" >0.15</td>\n",
       "      <td id=\"T_f9225_row0_col16\" class=\"data row0 col16\" >-0.00</td>\n",
       "      <td id=\"T_f9225_row0_col17\" class=\"data row0 col17\" >0.20</td>\n",
       "      <td id=\"T_f9225_row0_col18\" class=\"data row0 col18\" >-0.08</td>\n",
       "      <td id=\"T_f9225_row0_col19\" class=\"data row0 col19\" >-0.44</td>\n",
       "      <td id=\"T_f9225_row0_col20\" class=\"data row0 col20\" >0.21</td>\n",
       "      <td id=\"T_f9225_row0_col21\" class=\"data row0 col21\" >0.33</td>\n",
       "      <td id=\"T_f9225_row0_col22\" class=\"data row0 col22\" >0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row1\" class=\"row_heading level0 row1\" >DN_HistogramMode_5</th>\n",
       "      <td id=\"T_f9225_row1_col0\" class=\"data row1 col0\" >0.13</td>\n",
       "      <td id=\"T_f9225_row1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "      <td id=\"T_f9225_row1_col2\" class=\"data row1 col2\" >0.98</td>\n",
       "      <td id=\"T_f9225_row1_col3\" class=\"data row1 col3\" >-0.20</td>\n",
       "      <td id=\"T_f9225_row1_col4\" class=\"data row1 col4\" >-0.12</td>\n",
       "      <td id=\"T_f9225_row1_col5\" class=\"data row1 col5\" >-0.85</td>\n",
       "      <td id=\"T_f9225_row1_col6\" class=\"data row1 col6\" >-0.18</td>\n",
       "      <td id=\"T_f9225_row1_col7\" class=\"data row1 col7\" >0.36</td>\n",
       "      <td id=\"T_f9225_row1_col8\" class=\"data row1 col8\" >-0.41</td>\n",
       "      <td id=\"T_f9225_row1_col9\" class=\"data row1 col9\" >-0.65</td>\n",
       "      <td id=\"T_f9225_row1_col10\" class=\"data row1 col10\" >0.20</td>\n",
       "      <td id=\"T_f9225_row1_col11\" class=\"data row1 col11\" >-0.51</td>\n",
       "      <td id=\"T_f9225_row1_col12\" class=\"data row1 col12\" >-0.48</td>\n",
       "      <td id=\"T_f9225_row1_col13\" class=\"data row1 col13\" >-0.10</td>\n",
       "      <td id=\"T_f9225_row1_col14\" class=\"data row1 col14\" >-0.20</td>\n",
       "      <td id=\"T_f9225_row1_col15\" class=\"data row1 col15\" >0.72</td>\n",
       "      <td id=\"T_f9225_row1_col16\" class=\"data row1 col16\" >-0.74</td>\n",
       "      <td id=\"T_f9225_row1_col17\" class=\"data row1 col17\" >0.25</td>\n",
       "      <td id=\"T_f9225_row1_col18\" class=\"data row1 col18\" >0.52</td>\n",
       "      <td id=\"T_f9225_row1_col19\" class=\"data row1 col19\" >-0.74</td>\n",
       "      <td id=\"T_f9225_row1_col20\" class=\"data row1 col20\" >-0.44</td>\n",
       "      <td id=\"T_f9225_row1_col21\" class=\"data row1 col21\" >0.38</td>\n",
       "      <td id=\"T_f9225_row1_col22\" class=\"data row1 col22\" >0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row2\" class=\"row_heading level0 row2\" >DN_HistogramMode_10</th>\n",
       "      <td id=\"T_f9225_row2_col0\" class=\"data row2 col0\" >0.27</td>\n",
       "      <td id=\"T_f9225_row2_col1\" class=\"data row2 col1\" >0.98</td>\n",
       "      <td id=\"T_f9225_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_f9225_row2_col3\" class=\"data row2 col3\" >-0.21</td>\n",
       "      <td id=\"T_f9225_row2_col4\" class=\"data row2 col4\" >-0.02</td>\n",
       "      <td id=\"T_f9225_row2_col5\" class=\"data row2 col5\" >-0.83</td>\n",
       "      <td id=\"T_f9225_row2_col6\" class=\"data row2 col6\" >-0.12</td>\n",
       "      <td id=\"T_f9225_row2_col7\" class=\"data row2 col7\" >0.29</td>\n",
       "      <td id=\"T_f9225_row2_col8\" class=\"data row2 col8\" >-0.41</td>\n",
       "      <td id=\"T_f9225_row2_col9\" class=\"data row2 col9\" >-0.65</td>\n",
       "      <td id=\"T_f9225_row2_col10\" class=\"data row2 col10\" >0.32</td>\n",
       "      <td id=\"T_f9225_row2_col11\" class=\"data row2 col11\" >-0.43</td>\n",
       "      <td id=\"T_f9225_row2_col12\" class=\"data row2 col12\" >-0.42</td>\n",
       "      <td id=\"T_f9225_row2_col13\" class=\"data row2 col13\" >-0.07</td>\n",
       "      <td id=\"T_f9225_row2_col14\" class=\"data row2 col14\" >-0.17</td>\n",
       "      <td id=\"T_f9225_row2_col15\" class=\"data row2 col15\" >0.68</td>\n",
       "      <td id=\"T_f9225_row2_col16\" class=\"data row2 col16\" >-0.61</td>\n",
       "      <td id=\"T_f9225_row2_col17\" class=\"data row2 col17\" >0.20</td>\n",
       "      <td id=\"T_f9225_row2_col18\" class=\"data row2 col18\" >0.42</td>\n",
       "      <td id=\"T_f9225_row2_col19\" class=\"data row2 col19\" >-0.81</td>\n",
       "      <td id=\"T_f9225_row2_col20\" class=\"data row2 col20\" >-0.37</td>\n",
       "      <td id=\"T_f9225_row2_col21\" class=\"data row2 col21\" >0.34</td>\n",
       "      <td id=\"T_f9225_row2_col22\" class=\"data row2 col22\" >0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row3\" class=\"row_heading level0 row3\" >CO_f1ecac</th>\n",
       "      <td id=\"T_f9225_row3_col0\" class=\"data row3 col0\" >-0.37</td>\n",
       "      <td id=\"T_f9225_row3_col1\" class=\"data row3 col1\" >-0.20</td>\n",
       "      <td id=\"T_f9225_row3_col2\" class=\"data row3 col2\" >-0.21</td>\n",
       "      <td id=\"T_f9225_row3_col3\" class=\"data row3 col3\" >1.00</td>\n",
       "      <td id=\"T_f9225_row3_col4\" class=\"data row3 col4\" >0.49</td>\n",
       "      <td id=\"T_f9225_row3_col5\" class=\"data row3 col5\" >0.36</td>\n",
       "      <td id=\"T_f9225_row3_col6\" class=\"data row3 col6\" >0.11</td>\n",
       "      <td id=\"T_f9225_row3_col7\" class=\"data row3 col7\" >-0.43</td>\n",
       "      <td id=\"T_f9225_row3_col8\" class=\"data row3 col8\" >0.92</td>\n",
       "      <td id=\"T_f9225_row3_col9\" class=\"data row3 col9\" >0.39</td>\n",
       "      <td id=\"T_f9225_row3_col10\" class=\"data row3 col10\" >0.38</td>\n",
       "      <td id=\"T_f9225_row3_col11\" class=\"data row3 col11\" >0.42</td>\n",
       "      <td id=\"T_f9225_row3_col12\" class=\"data row3 col12\" >0.59</td>\n",
       "      <td id=\"T_f9225_row3_col13\" class=\"data row3 col13\" >-0.72</td>\n",
       "      <td id=\"T_f9225_row3_col14\" class=\"data row3 col14\" >0.42</td>\n",
       "      <td id=\"T_f9225_row3_col15\" class=\"data row3 col15\" >-0.38</td>\n",
       "      <td id=\"T_f9225_row3_col16\" class=\"data row3 col16\" >0.28</td>\n",
       "      <td id=\"T_f9225_row3_col17\" class=\"data row3 col17\" >-0.69</td>\n",
       "      <td id=\"T_f9225_row3_col18\" class=\"data row3 col18\" >-0.41</td>\n",
       "      <td id=\"T_f9225_row3_col19\" class=\"data row3 col19\" >0.18</td>\n",
       "      <td id=\"T_f9225_row3_col20\" class=\"data row3 col20\" >-0.17</td>\n",
       "      <td id=\"T_f9225_row3_col21\" class=\"data row3 col21\" >-0.72</td>\n",
       "      <td id=\"T_f9225_row3_col22\" class=\"data row3 col22\" >-0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row4\" class=\"row_heading level0 row4\" >CO_FirstMin_ac</th>\n",
       "      <td id=\"T_f9225_row4_col0\" class=\"data row4 col0\" >-0.07</td>\n",
       "      <td id=\"T_f9225_row4_col1\" class=\"data row4 col1\" >-0.12</td>\n",
       "      <td id=\"T_f9225_row4_col2\" class=\"data row4 col2\" >-0.02</td>\n",
       "      <td id=\"T_f9225_row4_col3\" class=\"data row4 col3\" >0.49</td>\n",
       "      <td id=\"T_f9225_row4_col4\" class=\"data row4 col4\" >1.00</td>\n",
       "      <td id=\"T_f9225_row4_col5\" class=\"data row4 col5\" >0.51</td>\n",
       "      <td id=\"T_f9225_row4_col6\" class=\"data row4 col6\" >-0.03</td>\n",
       "      <td id=\"T_f9225_row4_col7\" class=\"data row4 col7\" >-0.81</td>\n",
       "      <td id=\"T_f9225_row4_col8\" class=\"data row4 col8\" >0.65</td>\n",
       "      <td id=\"T_f9225_row4_col9\" class=\"data row4 col9\" >0.58</td>\n",
       "      <td id=\"T_f9225_row4_col10\" class=\"data row4 col10\" >0.90</td>\n",
       "      <td id=\"T_f9225_row4_col11\" class=\"data row4 col11\" >0.90</td>\n",
       "      <td id=\"T_f9225_row4_col12\" class=\"data row4 col12\" >0.88</td>\n",
       "      <td id=\"T_f9225_row4_col13\" class=\"data row4 col13\" >-0.47</td>\n",
       "      <td id=\"T_f9225_row4_col14\" class=\"data row4 col14\" >0.69</td>\n",
       "      <td id=\"T_f9225_row4_col15\" class=\"data row4 col15\" >-0.69</td>\n",
       "      <td id=\"T_f9225_row4_col16\" class=\"data row4 col16\" >0.48</td>\n",
       "      <td id=\"T_f9225_row4_col17\" class=\"data row4 col17\" >-0.44</td>\n",
       "      <td id=\"T_f9225_row4_col18\" class=\"data row4 col18\" >-0.87</td>\n",
       "      <td id=\"T_f9225_row4_col19\" class=\"data row4 col19\" >-0.29</td>\n",
       "      <td id=\"T_f9225_row4_col20\" class=\"data row4 col20\" >0.48</td>\n",
       "      <td id=\"T_f9225_row4_col21\" class=\"data row4 col21\" >-0.47</td>\n",
       "      <td id=\"T_f9225_row4_col22\" class=\"data row4 col22\" >-0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row5\" class=\"row_heading level0 row5\" >CO_HistogramAMI_even_2_5</th>\n",
       "      <td id=\"T_f9225_row5_col0\" class=\"data row5 col0\" >-0.30</td>\n",
       "      <td id=\"T_f9225_row5_col1\" class=\"data row5 col1\" >-0.85</td>\n",
       "      <td id=\"T_f9225_row5_col2\" class=\"data row5 col2\" >-0.83</td>\n",
       "      <td id=\"T_f9225_row5_col3\" class=\"data row5 col3\" >0.36</td>\n",
       "      <td id=\"T_f9225_row5_col4\" class=\"data row5 col4\" >0.51</td>\n",
       "      <td id=\"T_f9225_row5_col5\" class=\"data row5 col5\" >1.00</td>\n",
       "      <td id=\"T_f9225_row5_col6\" class=\"data row5 col6\" >0.17</td>\n",
       "      <td id=\"T_f9225_row5_col7\" class=\"data row5 col7\" >-0.67</td>\n",
       "      <td id=\"T_f9225_row5_col8\" class=\"data row5 col8\" >0.66</td>\n",
       "      <td id=\"T_f9225_row5_col9\" class=\"data row5 col9\" >0.93</td>\n",
       "      <td id=\"T_f9225_row5_col10\" class=\"data row5 col10\" >0.13</td>\n",
       "      <td id=\"T_f9225_row5_col11\" class=\"data row5 col11\" >0.82</td>\n",
       "      <td id=\"T_f9225_row5_col12\" class=\"data row5 col12\" >0.82</td>\n",
       "      <td id=\"T_f9225_row5_col13\" class=\"data row5 col13\" >-0.29</td>\n",
       "      <td id=\"T_f9225_row5_col14\" class=\"data row5 col14\" >0.62</td>\n",
       "      <td id=\"T_f9225_row5_col15\" class=\"data row5 col15\" >-0.89</td>\n",
       "      <td id=\"T_f9225_row5_col16\" class=\"data row5 col16\" >0.72</td>\n",
       "      <td id=\"T_f9225_row5_col17\" class=\"data row5 col17\" >-0.47</td>\n",
       "      <td id=\"T_f9225_row5_col18\" class=\"data row5 col18\" >-0.77</td>\n",
       "      <td id=\"T_f9225_row5_col19\" class=\"data row5 col19\" >0.43</td>\n",
       "      <td id=\"T_f9225_row5_col20\" class=\"data row5 col20\" >0.48</td>\n",
       "      <td id=\"T_f9225_row5_col21\" class=\"data row5 col21\" >-0.56</td>\n",
       "      <td id=\"T_f9225_row5_col22\" class=\"data row5 col22\" >-0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row6\" class=\"row_heading level0 row6\" >CO_trev_1_num</th>\n",
       "      <td id=\"T_f9225_row6_col0\" class=\"data row6 col0\" >-0.10</td>\n",
       "      <td id=\"T_f9225_row6_col1\" class=\"data row6 col1\" >-0.18</td>\n",
       "      <td id=\"T_f9225_row6_col2\" class=\"data row6 col2\" >-0.12</td>\n",
       "      <td id=\"T_f9225_row6_col3\" class=\"data row6 col3\" >0.11</td>\n",
       "      <td id=\"T_f9225_row6_col4\" class=\"data row6 col4\" >-0.03</td>\n",
       "      <td id=\"T_f9225_row6_col5\" class=\"data row6 col5\" >0.17</td>\n",
       "      <td id=\"T_f9225_row6_col6\" class=\"data row6 col6\" >1.00</td>\n",
       "      <td id=\"T_f9225_row6_col7\" class=\"data row6 col7\" >0.25</td>\n",
       "      <td id=\"T_f9225_row6_col8\" class=\"data row6 col8\" >0.08</td>\n",
       "      <td id=\"T_f9225_row6_col9\" class=\"data row6 col9\" >0.03</td>\n",
       "      <td id=\"T_f9225_row6_col10\" class=\"data row6 col10\" >-0.05</td>\n",
       "      <td id=\"T_f9225_row6_col11\" class=\"data row6 col11\" >0.01</td>\n",
       "      <td id=\"T_f9225_row6_col12\" class=\"data row6 col12\" >-0.02</td>\n",
       "      <td id=\"T_f9225_row6_col13\" class=\"data row6 col13\" >-0.27</td>\n",
       "      <td id=\"T_f9225_row6_col14\" class=\"data row6 col14\" >0.52</td>\n",
       "      <td id=\"T_f9225_row6_col15\" class=\"data row6 col15\" >0.22</td>\n",
       "      <td id=\"T_f9225_row6_col16\" class=\"data row6 col16\" >0.55</td>\n",
       "      <td id=\"T_f9225_row6_col17\" class=\"data row6 col17\" >-0.70</td>\n",
       "      <td id=\"T_f9225_row6_col18\" class=\"data row6 col18\" >0.12</td>\n",
       "      <td id=\"T_f9225_row6_col19\" class=\"data row6 col19\" >-0.00</td>\n",
       "      <td id=\"T_f9225_row6_col20\" class=\"data row6 col20\" >-0.54</td>\n",
       "      <td id=\"T_f9225_row6_col21\" class=\"data row6 col21\" >-0.71</td>\n",
       "      <td id=\"T_f9225_row6_col22\" class=\"data row6 col22\" >-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row7\" class=\"row_heading level0 row7\" >MD_hrv_classic_pnn40</th>\n",
       "      <td id=\"T_f9225_row7_col0\" class=\"data row7 col0\" >-0.15</td>\n",
       "      <td id=\"T_f9225_row7_col1\" class=\"data row7 col1\" >0.36</td>\n",
       "      <td id=\"T_f9225_row7_col2\" class=\"data row7 col2\" >0.29</td>\n",
       "      <td id=\"T_f9225_row7_col3\" class=\"data row7 col3\" >-0.43</td>\n",
       "      <td id=\"T_f9225_row7_col4\" class=\"data row7 col4\" >-0.81</td>\n",
       "      <td id=\"T_f9225_row7_col5\" class=\"data row7 col5\" >-0.67</td>\n",
       "      <td id=\"T_f9225_row7_col6\" class=\"data row7 col6\" >0.25</td>\n",
       "      <td id=\"T_f9225_row7_col7\" class=\"data row7 col7\" >1.00</td>\n",
       "      <td id=\"T_f9225_row7_col8\" class=\"data row7 col8\" >-0.68</td>\n",
       "      <td id=\"T_f9225_row7_col9\" class=\"data row7 col9\" >-0.80</td>\n",
       "      <td id=\"T_f9225_row7_col10\" class=\"data row7 col10\" >-0.56</td>\n",
       "      <td id=\"T_f9225_row7_col11\" class=\"data row7 col11\" >-0.85</td>\n",
       "      <td id=\"T_f9225_row7_col12\" class=\"data row7 col12\" >-0.91</td>\n",
       "      <td id=\"T_f9225_row7_col13\" class=\"data row7 col13\" >0.43</td>\n",
       "      <td id=\"T_f9225_row7_col14\" class=\"data row7 col14\" >-0.49</td>\n",
       "      <td id=\"T_f9225_row7_col15\" class=\"data row7 col15\" >0.83</td>\n",
       "      <td id=\"T_f9225_row7_col16\" class=\"data row7 col16\" >-0.37</td>\n",
       "      <td id=\"T_f9225_row7_col17\" class=\"data row7 col17\" >0.36</td>\n",
       "      <td id=\"T_f9225_row7_col18\" class=\"data row7 col18\" >0.94</td>\n",
       "      <td id=\"T_f9225_row7_col19\" class=\"data row7 col19\" >0.18</td>\n",
       "      <td id=\"T_f9225_row7_col20\" class=\"data row7 col20\" >-0.62</td>\n",
       "      <td id=\"T_f9225_row7_col21\" class=\"data row7 col21\" >0.32</td>\n",
       "      <td id=\"T_f9225_row7_col22\" class=\"data row7 col22\" >0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row8\" class=\"row_heading level0 row8\" >SB_BinaryStats_mean_longstretch1</th>\n",
       "      <td id=\"T_f9225_row8_col0\" class=\"data row8 col0\" >-0.39</td>\n",
       "      <td id=\"T_f9225_row8_col1\" class=\"data row8 col1\" >-0.41</td>\n",
       "      <td id=\"T_f9225_row8_col2\" class=\"data row8 col2\" >-0.41</td>\n",
       "      <td id=\"T_f9225_row8_col3\" class=\"data row8 col3\" >0.92</td>\n",
       "      <td id=\"T_f9225_row8_col4\" class=\"data row8 col4\" >0.65</td>\n",
       "      <td id=\"T_f9225_row8_col5\" class=\"data row8 col5\" >0.66</td>\n",
       "      <td id=\"T_f9225_row8_col6\" class=\"data row8 col6\" >0.08</td>\n",
       "      <td id=\"T_f9225_row8_col7\" class=\"data row8 col7\" >-0.68</td>\n",
       "      <td id=\"T_f9225_row8_col8\" class=\"data row8 col8\" >1.00</td>\n",
       "      <td id=\"T_f9225_row8_col9\" class=\"data row8 col9\" >0.72</td>\n",
       "      <td id=\"T_f9225_row8_col10\" class=\"data row8 col10\" >0.41</td>\n",
       "      <td id=\"T_f9225_row8_col11\" class=\"data row8 col11\" >0.68</td>\n",
       "      <td id=\"T_f9225_row8_col12\" class=\"data row8 col12\" >0.83</td>\n",
       "      <td id=\"T_f9225_row8_col13\" class=\"data row8 col13\" >-0.75</td>\n",
       "      <td id=\"T_f9225_row8_col14\" class=\"data row8 col14\" >0.62</td>\n",
       "      <td id=\"T_f9225_row8_col15\" class=\"data row8 col15\" >-0.66</td>\n",
       "      <td id=\"T_f9225_row8_col16\" class=\"data row8 col16\" >0.41</td>\n",
       "      <td id=\"T_f9225_row8_col17\" class=\"data row8 col17\" >-0.72</td>\n",
       "      <td id=\"T_f9225_row8_col18\" class=\"data row8 col18\" >-0.66</td>\n",
       "      <td id=\"T_f9225_row8_col19\" class=\"data row8 col19\" >0.19</td>\n",
       "      <td id=\"T_f9225_row8_col20\" class=\"data row8 col20\" >0.08</td>\n",
       "      <td id=\"T_f9225_row8_col21\" class=\"data row8 col21\" >-0.75</td>\n",
       "      <td id=\"T_f9225_row8_col22\" class=\"data row8 col22\" >-0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row9\" class=\"row_heading level0 row9\" >SB_TransitionMatrix_3ac_sumdiagcov</th>\n",
       "      <td id=\"T_f9225_row9_col0\" class=\"data row9 col0\" >-0.28</td>\n",
       "      <td id=\"T_f9225_row9_col1\" class=\"data row9 col1\" >-0.65</td>\n",
       "      <td id=\"T_f9225_row9_col2\" class=\"data row9 col2\" >-0.65</td>\n",
       "      <td id=\"T_f9225_row9_col3\" class=\"data row9 col3\" >0.39</td>\n",
       "      <td id=\"T_f9225_row9_col4\" class=\"data row9 col4\" >0.58</td>\n",
       "      <td id=\"T_f9225_row9_col5\" class=\"data row9 col5\" >0.93</td>\n",
       "      <td id=\"T_f9225_row9_col6\" class=\"data row9 col6\" >0.03</td>\n",
       "      <td id=\"T_f9225_row9_col7\" class=\"data row9 col7\" >-0.80</td>\n",
       "      <td id=\"T_f9225_row9_col8\" class=\"data row9 col8\" >0.72</td>\n",
       "      <td id=\"T_f9225_row9_col9\" class=\"data row9 col9\" >1.00</td>\n",
       "      <td id=\"T_f9225_row9_col10\" class=\"data row9 col10\" >0.18</td>\n",
       "      <td id=\"T_f9225_row9_col11\" class=\"data row9 col11\" >0.82</td>\n",
       "      <td id=\"T_f9225_row9_col12\" class=\"data row9 col12\" >0.88</td>\n",
       "      <td id=\"T_f9225_row9_col13\" class=\"data row9 col13\" >-0.51</td>\n",
       "      <td id=\"T_f9225_row9_col14\" class=\"data row9 col14\" >0.68</td>\n",
       "      <td id=\"T_f9225_row9_col15\" class=\"data row9 col15\" >-0.85</td>\n",
       "      <td id=\"T_f9225_row9_col16\" class=\"data row9 col16\" >0.48</td>\n",
       "      <td id=\"T_f9225_row9_col17\" class=\"data row9 col17\" >-0.49</td>\n",
       "      <td id=\"T_f9225_row9_col18\" class=\"data row9 col18\" >-0.79</td>\n",
       "      <td id=\"T_f9225_row9_col19\" class=\"data row9 col19\" >0.18</td>\n",
       "      <td id=\"T_f9225_row9_col20\" class=\"data row9 col20\" >0.43</td>\n",
       "      <td id=\"T_f9225_row9_col21\" class=\"data row9 col21\" >-0.50</td>\n",
       "      <td id=\"T_f9225_row9_col22\" class=\"data row9 col22\" >-0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row10\" class=\"row_heading level0 row10\" >PD_PeriodicityWang_th0_01</th>\n",
       "      <td id=\"T_f9225_row10_col0\" class=\"data row10 col0\" >0.06</td>\n",
       "      <td id=\"T_f9225_row10_col1\" class=\"data row10 col1\" >0.20</td>\n",
       "      <td id=\"T_f9225_row10_col2\" class=\"data row10 col2\" >0.32</td>\n",
       "      <td id=\"T_f9225_row10_col3\" class=\"data row10 col3\" >0.38</td>\n",
       "      <td id=\"T_f9225_row10_col4\" class=\"data row10 col4\" >0.90</td>\n",
       "      <td id=\"T_f9225_row10_col5\" class=\"data row10 col5\" >0.13</td>\n",
       "      <td id=\"T_f9225_row10_col6\" class=\"data row10 col6\" >-0.05</td>\n",
       "      <td id=\"T_f9225_row10_col7\" class=\"data row10 col7\" >-0.56</td>\n",
       "      <td id=\"T_f9225_row10_col8\" class=\"data row10 col8\" >0.41</td>\n",
       "      <td id=\"T_f9225_row10_col9\" class=\"data row10 col9\" >0.18</td>\n",
       "      <td id=\"T_f9225_row10_col10\" class=\"data row10 col10\" >1.00</td>\n",
       "      <td id=\"T_f9225_row10_col11\" class=\"data row10 col11\" >0.66</td>\n",
       "      <td id=\"T_f9225_row10_col12\" class=\"data row10 col12\" >0.61</td>\n",
       "      <td id=\"T_f9225_row10_col13\" class=\"data row10 col13\" >-0.30</td>\n",
       "      <td id=\"T_f9225_row10_col14\" class=\"data row10 col14\" >0.48</td>\n",
       "      <td id=\"T_f9225_row10_col15\" class=\"data row10 col15\" >-0.38</td>\n",
       "      <td id=\"T_f9225_row10_col16\" class=\"data row10 col16\" >0.33</td>\n",
       "      <td id=\"T_f9225_row10_col17\" class=\"data row10 col17\" >-0.29</td>\n",
       "      <td id=\"T_f9225_row10_col18\" class=\"data row10 col18\" >-0.63</td>\n",
       "      <td id=\"T_f9225_row10_col19\" class=\"data row10 col19\" >-0.45</td>\n",
       "      <td id=\"T_f9225_row10_col20\" class=\"data row10 col20\" >0.36</td>\n",
       "      <td id=\"T_f9225_row10_col21\" class=\"data row10 col21\" >-0.31</td>\n",
       "      <td id=\"T_f9225_row10_col22\" class=\"data row10 col22\" >-0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row11\" class=\"row_heading level0 row11\" >CO_Embed2_Dist_tau_d_expfit_meandiff</th>\n",
       "      <td id=\"T_f9225_row11_col0\" class=\"data row11 col0\" >-0.18</td>\n",
       "      <td id=\"T_f9225_row11_col1\" class=\"data row11 col1\" >-0.51</td>\n",
       "      <td id=\"T_f9225_row11_col2\" class=\"data row11 col2\" >-0.43</td>\n",
       "      <td id=\"T_f9225_row11_col3\" class=\"data row11 col3\" >0.42</td>\n",
       "      <td id=\"T_f9225_row11_col4\" class=\"data row11 col4\" >0.90</td>\n",
       "      <td id=\"T_f9225_row11_col5\" class=\"data row11 col5\" >0.82</td>\n",
       "      <td id=\"T_f9225_row11_col6\" class=\"data row11 col6\" >0.01</td>\n",
       "      <td id=\"T_f9225_row11_col7\" class=\"data row11 col7\" >-0.85</td>\n",
       "      <td id=\"T_f9225_row11_col8\" class=\"data row11 col8\" >0.68</td>\n",
       "      <td id=\"T_f9225_row11_col9\" class=\"data row11 col9\" >0.82</td>\n",
       "      <td id=\"T_f9225_row11_col10\" class=\"data row11 col10\" >0.66</td>\n",
       "      <td id=\"T_f9225_row11_col11\" class=\"data row11 col11\" >1.00</td>\n",
       "      <td id=\"T_f9225_row11_col12\" class=\"data row11 col12\" >0.96</td>\n",
       "      <td id=\"T_f9225_row11_col13\" class=\"data row11 col13\" >-0.36</td>\n",
       "      <td id=\"T_f9225_row11_col14\" class=\"data row11 col14\" >0.71</td>\n",
       "      <td id=\"T_f9225_row11_col15\" class=\"data row11 col15\" >-0.90</td>\n",
       "      <td id=\"T_f9225_row11_col16\" class=\"data row11 col16\" >0.67</td>\n",
       "      <td id=\"T_f9225_row11_col17\" class=\"data row11 col17\" >-0.43</td>\n",
       "      <td id=\"T_f9225_row11_col18\" class=\"data row11 col18\" >-0.95</td>\n",
       "      <td id=\"T_f9225_row11_col19\" class=\"data row11 col19\" >0.04</td>\n",
       "      <td id=\"T_f9225_row11_col20\" class=\"data row11 col20\" >0.63</td>\n",
       "      <td id=\"T_f9225_row11_col21\" class=\"data row11 col21\" >-0.51</td>\n",
       "      <td id=\"T_f9225_row11_col22\" class=\"data row11 col22\" >-0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row12\" class=\"row_heading level0 row12\" >IN_AutoMutualInfoStats_40_gaussian_fmmi</th>\n",
       "      <td id=\"T_f9225_row12_col0\" class=\"data row12 col0\" >-0.20</td>\n",
       "      <td id=\"T_f9225_row12_col1\" class=\"data row12 col1\" >-0.48</td>\n",
       "      <td id=\"T_f9225_row12_col2\" class=\"data row12 col2\" >-0.42</td>\n",
       "      <td id=\"T_f9225_row12_col3\" class=\"data row12 col3\" >0.59</td>\n",
       "      <td id=\"T_f9225_row12_col4\" class=\"data row12 col4\" >0.88</td>\n",
       "      <td id=\"T_f9225_row12_col5\" class=\"data row12 col5\" >0.82</td>\n",
       "      <td id=\"T_f9225_row12_col6\" class=\"data row12 col6\" >-0.02</td>\n",
       "      <td id=\"T_f9225_row12_col7\" class=\"data row12 col7\" >-0.91</td>\n",
       "      <td id=\"T_f9225_row12_col8\" class=\"data row12 col8\" >0.83</td>\n",
       "      <td id=\"T_f9225_row12_col9\" class=\"data row12 col9\" >0.88</td>\n",
       "      <td id=\"T_f9225_row12_col10\" class=\"data row12 col10\" >0.61</td>\n",
       "      <td id=\"T_f9225_row12_col11\" class=\"data row12 col11\" >0.96</td>\n",
       "      <td id=\"T_f9225_row12_col12\" class=\"data row12 col12\" >1.00</td>\n",
       "      <td id=\"T_f9225_row12_col13\" class=\"data row12 col13\" >-0.55</td>\n",
       "      <td id=\"T_f9225_row12_col14\" class=\"data row12 col14\" >0.72</td>\n",
       "      <td id=\"T_f9225_row12_col15\" class=\"data row12 col15\" >-0.89</td>\n",
       "      <td id=\"T_f9225_row12_col16\" class=\"data row12 col16\" >0.56</td>\n",
       "      <td id=\"T_f9225_row12_col17\" class=\"data row12 col17\" >-0.54</td>\n",
       "      <td id=\"T_f9225_row12_col18\" class=\"data row12 col18\" >-0.94</td>\n",
       "      <td id=\"T_f9225_row12_col19\" class=\"data row12 col19\" >0.01</td>\n",
       "      <td id=\"T_f9225_row12_col20\" class=\"data row12 col20\" >0.51</td>\n",
       "      <td id=\"T_f9225_row12_col21\" class=\"data row12 col21\" >-0.58</td>\n",
       "      <td id=\"T_f9225_row12_col22\" class=\"data row12 col22\" >-0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row13\" class=\"row_heading level0 row13\" >FC_LocalSimple_mean1_tauresrat</th>\n",
       "      <td id=\"T_f9225_row13_col0\" class=\"data row13 col0\" >0.37</td>\n",
       "      <td id=\"T_f9225_row13_col1\" class=\"data row13 col1\" >-0.10</td>\n",
       "      <td id=\"T_f9225_row13_col2\" class=\"data row13 col2\" >-0.07</td>\n",
       "      <td id=\"T_f9225_row13_col3\" class=\"data row13 col3\" >-0.72</td>\n",
       "      <td id=\"T_f9225_row13_col4\" class=\"data row13 col4\" >-0.47</td>\n",
       "      <td id=\"T_f9225_row13_col5\" class=\"data row13 col5\" >-0.29</td>\n",
       "      <td id=\"T_f9225_row13_col6\" class=\"data row13 col6\" >-0.27</td>\n",
       "      <td id=\"T_f9225_row13_col7\" class=\"data row13 col7\" >0.43</td>\n",
       "      <td id=\"T_f9225_row13_col8\" class=\"data row13 col8\" >-0.75</td>\n",
       "      <td id=\"T_f9225_row13_col9\" class=\"data row13 col9\" >-0.51</td>\n",
       "      <td id=\"T_f9225_row13_col10\" class=\"data row13 col10\" >-0.30</td>\n",
       "      <td id=\"T_f9225_row13_col11\" class=\"data row13 col11\" >-0.36</td>\n",
       "      <td id=\"T_f9225_row13_col12\" class=\"data row13 col12\" >-0.55</td>\n",
       "      <td id=\"T_f9225_row13_col13\" class=\"data row13 col13\" >1.00</td>\n",
       "      <td id=\"T_f9225_row13_col14\" class=\"data row13 col14\" >-0.73</td>\n",
       "      <td id=\"T_f9225_row13_col15\" class=\"data row13 col15\" >0.17</td>\n",
       "      <td id=\"T_f9225_row13_col16\" class=\"data row13 col16\" >-0.02</td>\n",
       "      <td id=\"T_f9225_row13_col17\" class=\"data row13 col17\" >0.80</td>\n",
       "      <td id=\"T_f9225_row13_col18\" class=\"data row13 col18\" >0.29</td>\n",
       "      <td id=\"T_f9225_row13_col19\" class=\"data row13 col19\" >0.31</td>\n",
       "      <td id=\"T_f9225_row13_col20\" class=\"data row13 col20\" >0.39</td>\n",
       "      <td id=\"T_f9225_row13_col21\" class=\"data row13 col21\" >0.70</td>\n",
       "      <td id=\"T_f9225_row13_col22\" class=\"data row13 col22\" >0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row14\" class=\"row_heading level0 row14\" >DN_OutlierInclude_p_001_mdrmd</th>\n",
       "      <td id=\"T_f9225_row14_col0\" class=\"data row14 col0\" >-0.43</td>\n",
       "      <td id=\"T_f9225_row14_col1\" class=\"data row14 col1\" >-0.20</td>\n",
       "      <td id=\"T_f9225_row14_col2\" class=\"data row14 col2\" >-0.17</td>\n",
       "      <td id=\"T_f9225_row14_col3\" class=\"data row14 col3\" >0.42</td>\n",
       "      <td id=\"T_f9225_row14_col4\" class=\"data row14 col4\" >0.69</td>\n",
       "      <td id=\"T_f9225_row14_col5\" class=\"data row14 col5\" >0.62</td>\n",
       "      <td id=\"T_f9225_row14_col6\" class=\"data row14 col6\" >0.52</td>\n",
       "      <td id=\"T_f9225_row14_col7\" class=\"data row14 col7\" >-0.49</td>\n",
       "      <td id=\"T_f9225_row14_col8\" class=\"data row14 col8\" >0.62</td>\n",
       "      <td id=\"T_f9225_row14_col9\" class=\"data row14 col9\" >0.68</td>\n",
       "      <td id=\"T_f9225_row14_col10\" class=\"data row14 col10\" >0.48</td>\n",
       "      <td id=\"T_f9225_row14_col11\" class=\"data row14 col11\" >0.71</td>\n",
       "      <td id=\"T_f9225_row14_col12\" class=\"data row14 col12\" >0.72</td>\n",
       "      <td id=\"T_f9225_row14_col13\" class=\"data row14 col13\" >-0.73</td>\n",
       "      <td id=\"T_f9225_row14_col14\" class=\"data row14 col14\" >1.00</td>\n",
       "      <td id=\"T_f9225_row14_col15\" class=\"data row14 col15\" >-0.44</td>\n",
       "      <td id=\"T_f9225_row14_col16\" class=\"data row14 col16\" >0.51</td>\n",
       "      <td id=\"T_f9225_row14_col17\" class=\"data row14 col17\" >-0.78</td>\n",
       "      <td id=\"T_f9225_row14_col18\" class=\"data row14 col18\" >-0.54</td>\n",
       "      <td id=\"T_f9225_row14_col19\" class=\"data row14 col19\" >-0.20</td>\n",
       "      <td id=\"T_f9225_row14_col20\" class=\"data row14 col20\" >-0.03</td>\n",
       "      <td id=\"T_f9225_row14_col21\" class=\"data row14 col21\" >-0.78</td>\n",
       "      <td id=\"T_f9225_row14_col22\" class=\"data row14 col22\" >-0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row15\" class=\"row_heading level0 row15\" >DN_OutlierInclude_n_001_mdrmd</th>\n",
       "      <td id=\"T_f9225_row15_col0\" class=\"data row15 col0\" >0.15</td>\n",
       "      <td id=\"T_f9225_row15_col1\" class=\"data row15 col1\" >0.72</td>\n",
       "      <td id=\"T_f9225_row15_col2\" class=\"data row15 col2\" >0.68</td>\n",
       "      <td id=\"T_f9225_row15_col3\" class=\"data row15 col3\" >-0.38</td>\n",
       "      <td id=\"T_f9225_row15_col4\" class=\"data row15 col4\" >-0.69</td>\n",
       "      <td id=\"T_f9225_row15_col5\" class=\"data row15 col5\" >-0.89</td>\n",
       "      <td id=\"T_f9225_row15_col6\" class=\"data row15 col6\" >0.22</td>\n",
       "      <td id=\"T_f9225_row15_col7\" class=\"data row15 col7\" >0.83</td>\n",
       "      <td id=\"T_f9225_row15_col8\" class=\"data row15 col8\" >-0.66</td>\n",
       "      <td id=\"T_f9225_row15_col9\" class=\"data row15 col9\" >-0.85</td>\n",
       "      <td id=\"T_f9225_row15_col10\" class=\"data row15 col10\" >-0.38</td>\n",
       "      <td id=\"T_f9225_row15_col11\" class=\"data row15 col11\" >-0.90</td>\n",
       "      <td id=\"T_f9225_row15_col12\" class=\"data row15 col12\" >-0.89</td>\n",
       "      <td id=\"T_f9225_row15_col13\" class=\"data row15 col13\" >0.17</td>\n",
       "      <td id=\"T_f9225_row15_col14\" class=\"data row15 col14\" >-0.44</td>\n",
       "      <td id=\"T_f9225_row15_col15\" class=\"data row15 col15\" >1.00</td>\n",
       "      <td id=\"T_f9225_row15_col16\" class=\"data row15 col16\" >-0.60</td>\n",
       "      <td id=\"T_f9225_row15_col17\" class=\"data row15 col17\" >0.23</td>\n",
       "      <td id=\"T_f9225_row15_col18\" class=\"data row15 col18\" >0.92</td>\n",
       "      <td id=\"T_f9225_row15_col19\" class=\"data row15 col19\" >-0.33</td>\n",
       "      <td id=\"T_f9225_row15_col20\" class=\"data row15 col20\" >-0.76</td>\n",
       "      <td id=\"T_f9225_row15_col21\" class=\"data row15 col21\" >0.32</td>\n",
       "      <td id=\"T_f9225_row15_col22\" class=\"data row15 col22\" >0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row16\" class=\"row_heading level0 row16\" >SP_Summaries_welch_rect_area_5_1</th>\n",
       "      <td id=\"T_f9225_row16_col0\" class=\"data row16 col0\" >-0.00</td>\n",
       "      <td id=\"T_f9225_row16_col1\" class=\"data row16 col1\" >-0.74</td>\n",
       "      <td id=\"T_f9225_row16_col2\" class=\"data row16 col2\" >-0.61</td>\n",
       "      <td id=\"T_f9225_row16_col3\" class=\"data row16 col3\" >0.28</td>\n",
       "      <td id=\"T_f9225_row16_col4\" class=\"data row16 col4\" >0.48</td>\n",
       "      <td id=\"T_f9225_row16_col5\" class=\"data row16 col5\" >0.72</td>\n",
       "      <td id=\"T_f9225_row16_col6\" class=\"data row16 col6\" >0.55</td>\n",
       "      <td id=\"T_f9225_row16_col7\" class=\"data row16 col7\" >-0.37</td>\n",
       "      <td id=\"T_f9225_row16_col8\" class=\"data row16 col8\" >0.41</td>\n",
       "      <td id=\"T_f9225_row16_col9\" class=\"data row16 col9\" >0.48</td>\n",
       "      <td id=\"T_f9225_row16_col10\" class=\"data row16 col10\" >0.33</td>\n",
       "      <td id=\"T_f9225_row16_col11\" class=\"data row16 col11\" >0.67</td>\n",
       "      <td id=\"T_f9225_row16_col12\" class=\"data row16 col12\" >0.56</td>\n",
       "      <td id=\"T_f9225_row16_col13\" class=\"data row16 col13\" >-0.02</td>\n",
       "      <td id=\"T_f9225_row16_col14\" class=\"data row16 col14\" >0.51</td>\n",
       "      <td id=\"T_f9225_row16_col15\" class=\"data row16 col15\" >-0.60</td>\n",
       "      <td id=\"T_f9225_row16_col16\" class=\"data row16 col16\" >1.00</td>\n",
       "      <td id=\"T_f9225_row16_col17\" class=\"data row16 col17\" >-0.53</td>\n",
       "      <td id=\"T_f9225_row16_col18\" class=\"data row16 col18\" >-0.62</td>\n",
       "      <td id=\"T_f9225_row16_col19\" class=\"data row16 col19\" >0.35</td>\n",
       "      <td id=\"T_f9225_row16_col20\" class=\"data row16 col20\" >0.33</td>\n",
       "      <td id=\"T_f9225_row16_col21\" class=\"data row16 col21\" >-0.67</td>\n",
       "      <td id=\"T_f9225_row16_col22\" class=\"data row16 col22\" >-0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row17\" class=\"row_heading level0 row17\" >SB_BinaryStats_diff_longstretch0</th>\n",
       "      <td id=\"T_f9225_row17_col0\" class=\"data row17 col0\" >0.20</td>\n",
       "      <td id=\"T_f9225_row17_col1\" class=\"data row17 col1\" >0.25</td>\n",
       "      <td id=\"T_f9225_row17_col2\" class=\"data row17 col2\" >0.20</td>\n",
       "      <td id=\"T_f9225_row17_col3\" class=\"data row17 col3\" >-0.69</td>\n",
       "      <td id=\"T_f9225_row17_col4\" class=\"data row17 col4\" >-0.44</td>\n",
       "      <td id=\"T_f9225_row17_col5\" class=\"data row17 col5\" >-0.47</td>\n",
       "      <td id=\"T_f9225_row17_col6\" class=\"data row17 col6\" >-0.70</td>\n",
       "      <td id=\"T_f9225_row17_col7\" class=\"data row17 col7\" >0.36</td>\n",
       "      <td id=\"T_f9225_row17_col8\" class=\"data row17 col8\" >-0.72</td>\n",
       "      <td id=\"T_f9225_row17_col9\" class=\"data row17 col9\" >-0.49</td>\n",
       "      <td id=\"T_f9225_row17_col10\" class=\"data row17 col10\" >-0.29</td>\n",
       "      <td id=\"T_f9225_row17_col11\" class=\"data row17 col11\" >-0.43</td>\n",
       "      <td id=\"T_f9225_row17_col12\" class=\"data row17 col12\" >-0.54</td>\n",
       "      <td id=\"T_f9225_row17_col13\" class=\"data row17 col13\" >0.80</td>\n",
       "      <td id=\"T_f9225_row17_col14\" class=\"data row17 col14\" >-0.78</td>\n",
       "      <td id=\"T_f9225_row17_col15\" class=\"data row17 col15\" >0.23</td>\n",
       "      <td id=\"T_f9225_row17_col16\" class=\"data row17 col16\" >-0.53</td>\n",
       "      <td id=\"T_f9225_row17_col17\" class=\"data row17 col17\" >1.00</td>\n",
       "      <td id=\"T_f9225_row17_col18\" class=\"data row17 col18\" >0.37</td>\n",
       "      <td id=\"T_f9225_row17_col19\" class=\"data row17 col19\" >0.09</td>\n",
       "      <td id=\"T_f9225_row17_col20\" class=\"data row17 col20\" >0.37</td>\n",
       "      <td id=\"T_f9225_row17_col21\" class=\"data row17 col21\" >0.97</td>\n",
       "      <td id=\"T_f9225_row17_col22\" class=\"data row17 col22\" >0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row18\" class=\"row_heading level0 row18\" >SB_MotifThree_quantile_hh</th>\n",
       "      <td id=\"T_f9225_row18_col0\" class=\"data row18 col0\" >-0.08</td>\n",
       "      <td id=\"T_f9225_row18_col1\" class=\"data row18 col1\" >0.52</td>\n",
       "      <td id=\"T_f9225_row18_col2\" class=\"data row18 col2\" >0.42</td>\n",
       "      <td id=\"T_f9225_row18_col3\" class=\"data row18 col3\" >-0.41</td>\n",
       "      <td id=\"T_f9225_row18_col4\" class=\"data row18 col4\" >-0.87</td>\n",
       "      <td id=\"T_f9225_row18_col5\" class=\"data row18 col5\" >-0.77</td>\n",
       "      <td id=\"T_f9225_row18_col6\" class=\"data row18 col6\" >0.12</td>\n",
       "      <td id=\"T_f9225_row18_col7\" class=\"data row18 col7\" >0.94</td>\n",
       "      <td id=\"T_f9225_row18_col8\" class=\"data row18 col8\" >-0.66</td>\n",
       "      <td id=\"T_f9225_row18_col9\" class=\"data row18 col9\" >-0.79</td>\n",
       "      <td id=\"T_f9225_row18_col10\" class=\"data row18 col10\" >-0.63</td>\n",
       "      <td id=\"T_f9225_row18_col11\" class=\"data row18 col11\" >-0.95</td>\n",
       "      <td id=\"T_f9225_row18_col12\" class=\"data row18 col12\" >-0.94</td>\n",
       "      <td id=\"T_f9225_row18_col13\" class=\"data row18 col13\" >0.29</td>\n",
       "      <td id=\"T_f9225_row18_col14\" class=\"data row18 col14\" >-0.54</td>\n",
       "      <td id=\"T_f9225_row18_col15\" class=\"data row18 col15\" >0.92</td>\n",
       "      <td id=\"T_f9225_row18_col16\" class=\"data row18 col16\" >-0.62</td>\n",
       "      <td id=\"T_f9225_row18_col17\" class=\"data row18 col17\" >0.37</td>\n",
       "      <td id=\"T_f9225_row18_col18\" class=\"data row18 col18\" >1.00</td>\n",
       "      <td id=\"T_f9225_row18_col19\" class=\"data row18 col19\" >0.01</td>\n",
       "      <td id=\"T_f9225_row18_col20\" class=\"data row18 col20\" >-0.71</td>\n",
       "      <td id=\"T_f9225_row18_col21\" class=\"data row18 col21\" >0.41</td>\n",
       "      <td id=\"T_f9225_row18_col22\" class=\"data row18 col22\" >0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row19\" class=\"row_heading level0 row19\" >SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1</th>\n",
       "      <td id=\"T_f9225_row19_col0\" class=\"data row19 col0\" >-0.44</td>\n",
       "      <td id=\"T_f9225_row19_col1\" class=\"data row19 col1\" >-0.74</td>\n",
       "      <td id=\"T_f9225_row19_col2\" class=\"data row19 col2\" >-0.81</td>\n",
       "      <td id=\"T_f9225_row19_col3\" class=\"data row19 col3\" >0.18</td>\n",
       "      <td id=\"T_f9225_row19_col4\" class=\"data row19 col4\" >-0.29</td>\n",
       "      <td id=\"T_f9225_row19_col5\" class=\"data row19 col5\" >0.43</td>\n",
       "      <td id=\"T_f9225_row19_col6\" class=\"data row19 col6\" >-0.00</td>\n",
       "      <td id=\"T_f9225_row19_col7\" class=\"data row19 col7\" >0.18</td>\n",
       "      <td id=\"T_f9225_row19_col8\" class=\"data row19 col8\" >0.19</td>\n",
       "      <td id=\"T_f9225_row19_col9\" class=\"data row19 col9\" >0.18</td>\n",
       "      <td id=\"T_f9225_row19_col10\" class=\"data row19 col10\" >-0.45</td>\n",
       "      <td id=\"T_f9225_row19_col11\" class=\"data row19 col11\" >0.04</td>\n",
       "      <td id=\"T_f9225_row19_col12\" class=\"data row19 col12\" >0.01</td>\n",
       "      <td id=\"T_f9225_row19_col13\" class=\"data row19 col13\" >0.31</td>\n",
       "      <td id=\"T_f9225_row19_col14\" class=\"data row19 col14\" >-0.20</td>\n",
       "      <td id=\"T_f9225_row19_col15\" class=\"data row19 col15\" >-0.33</td>\n",
       "      <td id=\"T_f9225_row19_col16\" class=\"data row19 col16\" >0.35</td>\n",
       "      <td id=\"T_f9225_row19_col17\" class=\"data row19 col17\" >0.09</td>\n",
       "      <td id=\"T_f9225_row19_col18\" class=\"data row19 col18\" >0.01</td>\n",
       "      <td id=\"T_f9225_row19_col19\" class=\"data row19 col19\" >1.00</td>\n",
       "      <td id=\"T_f9225_row19_col20\" class=\"data row19 col20\" >0.16</td>\n",
       "      <td id=\"T_f9225_row19_col21\" class=\"data row19 col21\" >-0.11</td>\n",
       "      <td id=\"T_f9225_row19_col22\" class=\"data row19 col22\" >-0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row20\" class=\"row_heading level0 row20\" >SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1</th>\n",
       "      <td id=\"T_f9225_row20_col0\" class=\"data row20 col0\" >0.21</td>\n",
       "      <td id=\"T_f9225_row20_col1\" class=\"data row20 col1\" >-0.44</td>\n",
       "      <td id=\"T_f9225_row20_col2\" class=\"data row20 col2\" >-0.37</td>\n",
       "      <td id=\"T_f9225_row20_col3\" class=\"data row20 col3\" >-0.17</td>\n",
       "      <td id=\"T_f9225_row20_col4\" class=\"data row20 col4\" >0.48</td>\n",
       "      <td id=\"T_f9225_row20_col5\" class=\"data row20 col5\" >0.48</td>\n",
       "      <td id=\"T_f9225_row20_col6\" class=\"data row20 col6\" >-0.54</td>\n",
       "      <td id=\"T_f9225_row20_col7\" class=\"data row20 col7\" >-0.62</td>\n",
       "      <td id=\"T_f9225_row20_col8\" class=\"data row20 col8\" >0.08</td>\n",
       "      <td id=\"T_f9225_row20_col9\" class=\"data row20 col9\" >0.43</td>\n",
       "      <td id=\"T_f9225_row20_col10\" class=\"data row20 col10\" >0.36</td>\n",
       "      <td id=\"T_f9225_row20_col11\" class=\"data row20 col11\" >0.63</td>\n",
       "      <td id=\"T_f9225_row20_col12\" class=\"data row20 col12\" >0.51</td>\n",
       "      <td id=\"T_f9225_row20_col13\" class=\"data row20 col13\" >0.39</td>\n",
       "      <td id=\"T_f9225_row20_col14\" class=\"data row20 col14\" >-0.03</td>\n",
       "      <td id=\"T_f9225_row20_col15\" class=\"data row20 col15\" >-0.76</td>\n",
       "      <td id=\"T_f9225_row20_col16\" class=\"data row20 col16\" >0.33</td>\n",
       "      <td id=\"T_f9225_row20_col17\" class=\"data row20 col17\" >0.37</td>\n",
       "      <td id=\"T_f9225_row20_col18\" class=\"data row20 col18\" >-0.71</td>\n",
       "      <td id=\"T_f9225_row20_col19\" class=\"data row20 col19\" >0.16</td>\n",
       "      <td id=\"T_f9225_row20_col20\" class=\"data row20 col20\" >1.00</td>\n",
       "      <td id=\"T_f9225_row20_col21\" class=\"data row20 col21\" >0.28</td>\n",
       "      <td id=\"T_f9225_row20_col22\" class=\"data row20 col22\" >-0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row21\" class=\"row_heading level0 row21\" >SP_Summaries_welch_rect_centroid</th>\n",
       "      <td id=\"T_f9225_row21_col0\" class=\"data row21 col0\" >0.33</td>\n",
       "      <td id=\"T_f9225_row21_col1\" class=\"data row21 col1\" >0.38</td>\n",
       "      <td id=\"T_f9225_row21_col2\" class=\"data row21 col2\" >0.34</td>\n",
       "      <td id=\"T_f9225_row21_col3\" class=\"data row21 col3\" >-0.72</td>\n",
       "      <td id=\"T_f9225_row21_col4\" class=\"data row21 col4\" >-0.47</td>\n",
       "      <td id=\"T_f9225_row21_col5\" class=\"data row21 col5\" >-0.56</td>\n",
       "      <td id=\"T_f9225_row21_col6\" class=\"data row21 col6\" >-0.71</td>\n",
       "      <td id=\"T_f9225_row21_col7\" class=\"data row21 col7\" >0.32</td>\n",
       "      <td id=\"T_f9225_row21_col8\" class=\"data row21 col8\" >-0.75</td>\n",
       "      <td id=\"T_f9225_row21_col9\" class=\"data row21 col9\" >-0.50</td>\n",
       "      <td id=\"T_f9225_row21_col10\" class=\"data row21 col10\" >-0.31</td>\n",
       "      <td id=\"T_f9225_row21_col11\" class=\"data row21 col11\" >-0.51</td>\n",
       "      <td id=\"T_f9225_row21_col12\" class=\"data row21 col12\" >-0.58</td>\n",
       "      <td id=\"T_f9225_row21_col13\" class=\"data row21 col13\" >0.70</td>\n",
       "      <td id=\"T_f9225_row21_col14\" class=\"data row21 col14\" >-0.78</td>\n",
       "      <td id=\"T_f9225_row21_col15\" class=\"data row21 col15\" >0.32</td>\n",
       "      <td id=\"T_f9225_row21_col16\" class=\"data row21 col16\" >-0.67</td>\n",
       "      <td id=\"T_f9225_row21_col17\" class=\"data row21 col17\" >0.97</td>\n",
       "      <td id=\"T_f9225_row21_col18\" class=\"data row21 col18\" >0.41</td>\n",
       "      <td id=\"T_f9225_row21_col19\" class=\"data row21 col19\" >-0.11</td>\n",
       "      <td id=\"T_f9225_row21_col20\" class=\"data row21 col20\" >0.28</td>\n",
       "      <td id=\"T_f9225_row21_col21\" class=\"data row21 col21\" >1.00</td>\n",
       "      <td id=\"T_f9225_row21_col22\" class=\"data row21 col22\" >0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9225_level0_row22\" class=\"row_heading level0 row22\" >FC_LocalSimple_mean3_stderr</th>\n",
       "      <td id=\"T_f9225_row22_col0\" class=\"data row22 col0\" >0.24</td>\n",
       "      <td id=\"T_f9225_row22_col1\" class=\"data row22 col1\" >0.63</td>\n",
       "      <td id=\"T_f9225_row22_col2\" class=\"data row22 col2\" >0.55</td>\n",
       "      <td id=\"T_f9225_row22_col3\" class=\"data row22 col3\" >-0.59</td>\n",
       "      <td id=\"T_f9225_row22_col4\" class=\"data row22 col4\" >-0.80</td>\n",
       "      <td id=\"T_f9225_row22_col5\" class=\"data row22 col5\" >-0.87</td>\n",
       "      <td id=\"T_f9225_row22_col6\" class=\"data row22 col6\" >-0.30</td>\n",
       "      <td id=\"T_f9225_row22_col7\" class=\"data row22 col7\" >0.73</td>\n",
       "      <td id=\"T_f9225_row22_col8\" class=\"data row22 col8\" >-0.79</td>\n",
       "      <td id=\"T_f9225_row22_col9\" class=\"data row22 col9\" >-0.80</td>\n",
       "      <td id=\"T_f9225_row22_col10\" class=\"data row22 col10\" >-0.55</td>\n",
       "      <td id=\"T_f9225_row22_col11\" class=\"data row22 col11\" >-0.93</td>\n",
       "      <td id=\"T_f9225_row22_col12\" class=\"data row22 col12\" >-0.92</td>\n",
       "      <td id=\"T_f9225_row22_col13\" class=\"data row22 col13\" >0.46</td>\n",
       "      <td id=\"T_f9225_row22_col14\" class=\"data row22 col14\" >-0.77</td>\n",
       "      <td id=\"T_f9225_row22_col15\" class=\"data row22 col15\" >0.83</td>\n",
       "      <td id=\"T_f9225_row22_col16\" class=\"data row22 col16\" >-0.82</td>\n",
       "      <td id=\"T_f9225_row22_col17\" class=\"data row22 col17\" >0.68</td>\n",
       "      <td id=\"T_f9225_row22_col18\" class=\"data row22 col18\" >0.86</td>\n",
       "      <td id=\"T_f9225_row22_col19\" class=\"data row22 col19\" >-0.19</td>\n",
       "      <td id=\"T_f9225_row22_col20\" class=\"data row22 col20\" >-0.39</td>\n",
       "      <td id=\"T_f9225_row22_col21\" class=\"data row22 col21\" >0.77</td>\n",
       "      <td id=\"T_f9225_row22_col22\" class=\"data row22 col22\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9d72709cd0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = data[data['model']=='transformer'].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d0/l9cqdxf90hbg0dj97q8bs7kc0000gn/T/ipykernel_76447/922814538.py:2: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "  corr.style.background_gradient(cmap='coolwarm').set_precision(2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_17d5d_row0_col0, #T_17d5d_row1_col1, #T_17d5d_row2_col2, #T_17d5d_row3_col3, #T_17d5d_row4_col4, #T_17d5d_row5_col5, #T_17d5d_row6_col6, #T_17d5d_row7_col7, #T_17d5d_row8_col8, #T_17d5d_row9_col9, #T_17d5d_row10_col10, #T_17d5d_row11_col11, #T_17d5d_row12_col12, #T_17d5d_row13_col13, #T_17d5d_row14_col14, #T_17d5d_row15_col15, #T_17d5d_row16_col16, #T_17d5d_row17_col17, #T_17d5d_row18_col18, #T_17d5d_row19_col19, #T_17d5d_row20_col20, #T_17d5d_row21_col21, #T_17d5d_row22_col22 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row0_col1, #T_17d5d_row2_col19, #T_17d5d_row16_col19 {\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row0_col2, #T_17d5d_row0_col7, #T_17d5d_row10_col1, #T_17d5d_row10_col6, #T_17d5d_row15_col0, #T_17d5d_row19_col2 {\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row0_col3, #T_17d5d_row10_col18, #T_17d5d_row16_col18, #T_17d5d_row21_col4 {\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row0_col4, #T_17d5d_row0_col10, #T_17d5d_row9_col7 {\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row0_col5, #T_17d5d_row9_col1 {\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row0_col6, #T_17d5d_row2_col8 {\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row0_col8, #T_17d5d_row11_col21, #T_17d5d_row19_col1 {\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row0_col9, #T_17d5d_row1_col9, #T_17d5d_row20_col18 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row0_col11, #T_17d5d_row0_col14, #T_17d5d_row8_col1, #T_17d5d_row16_col15, #T_17d5d_row17_col12 {\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row0_col12, #T_17d5d_row14_col13, #T_17d5d_row16_col2 {\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row0_col13, #T_17d5d_row0_col21, #T_17d5d_row12_col20 {\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row0_col15, #T_17d5d_row1_col7, #T_17d5d_row19_col8, #T_17d5d_row19_col17, #T_17d5d_row20_col2 {\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row0_col16, #T_17d5d_row3_col1 {\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row0_col17, #T_17d5d_row17_col7 {\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row0_col18, #T_17d5d_row8_col10, #T_17d5d_row13_col20, #T_17d5d_row16_col9 {\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row0_col19 {\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row0_col20 {\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row0_col22 {\n",
       "  background-color: #f39577;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row1_col0, #T_17d5d_row1_col17, #T_17d5d_row6_col10 {\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row1_col2, #T_17d5d_row4_col3, #T_17d5d_row6_col8, #T_17d5d_row6_col16, #T_17d5d_row22_col13 {\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row1_col3, #T_17d5d_row18_col2, #T_17d5d_row22_col19 {\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row1_col4, #T_17d5d_row4_col19, #T_17d5d_row20_col9 {\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row1_col5, #T_17d5d_row7_col12, #T_17d5d_row16_col1, #T_17d5d_row22_col11 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row1_col6, #T_17d5d_row4_col15, #T_17d5d_row11_col1, #T_17d5d_row15_col10, #T_17d5d_row17_col5 {\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row1_col8, #T_17d5d_row1_col14, #T_17d5d_row20_col1 {\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row1_col10, #T_17d5d_row2_col3, #T_17d5d_row3_col9, #T_17d5d_row4_col2, #T_17d5d_row6_col5 {\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row1_col11, #T_17d5d_row9_col18 {\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row1_col12, #T_17d5d_row7_col16, #T_17d5d_row10_col13, #T_17d5d_row16_col0 {\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row1_col13 {\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row1_col15, #T_17d5d_row3_col12, #T_17d5d_row15_col22, #T_17d5d_row16_col12, #T_17d5d_row20_col6, #T_17d5d_row22_col15 {\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row1_col16, #T_17d5d_row7_col4 {\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row1_col18, #T_17d5d_row2_col1 {\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row1_col19, #T_17d5d_row2_col5, #T_17d5d_row8_col7 {\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row1_col20, #T_17d5d_row6_col9, #T_17d5d_row13_col5 {\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row1_col21, #T_17d5d_row2_col17 {\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row1_col22, #T_17d5d_row10_col14, #T_17d5d_row11_col20 {\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row2_col0, #T_17d5d_row8_col20 {\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row2_col4, #T_17d5d_row17_col1 {\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row2_col6, #T_17d5d_row9_col4, #T_17d5d_row11_col3 {\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row2_col7, #T_17d5d_row19_col7 {\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row2_col9, #T_17d5d_row5_col1, #T_17d5d_row8_col0, #T_17d5d_row8_col13, #T_17d5d_row8_col21, #T_17d5d_row9_col2, #T_17d5d_row9_col17, #T_17d5d_row11_col18, #T_17d5d_row12_col22, #T_17d5d_row14_col7, #T_17d5d_row14_col15, #T_17d5d_row15_col6, #T_17d5d_row15_col19, #T_17d5d_row15_col20, #T_17d5d_row18_col4, #T_17d5d_row18_col10, #T_17d5d_row18_col11, #T_17d5d_row18_col12, #T_17d5d_row18_col14, #T_17d5d_row21_col3, #T_17d5d_row21_col8, #T_17d5d_row22_col5, #T_17d5d_row22_col9, #T_17d5d_row22_col16 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row2_col10, #T_17d5d_row2_col22, #T_17d5d_row15_col21 {\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row2_col11 {\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row2_col12, #T_17d5d_row9_col10 {\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row2_col13 {\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row2_col14, #T_17d5d_row13_col19, #T_17d5d_row16_col10, #T_17d5d_row21_col2 {\n",
       "  background-color: #f1cdba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row2_col15, #T_17d5d_row17_col11 {\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row2_col16, #T_17d5d_row3_col15, #T_17d5d_row10_col21, #T_17d5d_row17_col10, #T_17d5d_row18_col19, #T_17d5d_row19_col0, #T_17d5d_row22_col6 {\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row2_col18, #T_17d5d_row5_col10 {\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row2_col20, #T_17d5d_row6_col2, #T_17d5d_row11_col6, #T_17d5d_row13_col0 {\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row2_col21, #T_17d5d_row3_col10, #T_17d5d_row8_col19, #T_17d5d_row18_col13, #T_17d5d_row20_col13 {\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row3_col0 {\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row3_col2, #T_17d5d_row6_col17, #T_17d5d_row7_col0 {\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row3_col4, #T_17d5d_row17_col20, #T_17d5d_row21_col1 {\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row3_col5, #T_17d5d_row3_col16, #T_17d5d_row17_col18, #T_17d5d_row22_col2 {\n",
       "  background-color: #f2c9b4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row3_col6, #T_17d5d_row4_col16, #T_17d5d_row6_col3, #T_17d5d_row9_col8, #T_17d5d_row16_col6 {\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row3_col7, #T_17d5d_row21_col6 {\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row3_col8, #T_17d5d_row8_col3 {\n",
       "  background-color: #c32e31;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row3_col11, #T_17d5d_row4_col20, #T_17d5d_row8_col6, #T_17d5d_row14_col19, #T_17d5d_row18_col1, #T_17d5d_row20_col4, #T_17d5d_row20_col12, #T_17d5d_row22_col0 {\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row3_col13, #T_17d5d_row12_col18 {\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row3_col14, #T_17d5d_row6_col14, #T_17d5d_row12_col9, #T_17d5d_row16_col11 {\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row3_col17, #T_17d5d_row4_col22, #T_17d5d_row5_col17, #T_17d5d_row9_col0, #T_17d5d_row11_col15, #T_17d5d_row16_col21, #T_17d5d_row22_col14 {\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row3_col18, #T_17d5d_row14_col17, #T_17d5d_row17_col4 {\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row3_col19 {\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row3_col20, #T_17d5d_row16_col13 {\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row3_col21, #T_17d5d_row14_col18 {\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row3_col22, #T_17d5d_row9_col21 {\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row4_col0, #T_17d5d_row7_col20 {\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row4_col1 {\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row4_col5, #T_17d5d_row13_col7, #T_17d5d_row21_col7 {\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row4_col6, #T_17d5d_row16_col3, #T_17d5d_row19_col11, #T_17d5d_row19_col16, #T_17d5d_row20_col10 {\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row4_col7, #T_17d5d_row4_col18, #T_17d5d_row11_col0 {\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row4_col8, #T_17d5d_row14_col20 {\n",
       "  background-color: #ec8165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row4_col9, #T_17d5d_row9_col16, #T_17d5d_row10_col3, #T_17d5d_row17_col19 {\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row4_col10, #T_17d5d_row4_col12, #T_17d5d_row9_col5, #T_17d5d_row12_col4 {\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row4_col11, #T_17d5d_row10_col4, #T_17d5d_row11_col4, #T_17d5d_row12_col14, #T_17d5d_row14_col12 {\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row4_col13, #T_17d5d_row7_col9, #T_17d5d_row15_col4, #T_17d5d_row21_col14 {\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row4_col14, #T_17d5d_row8_col12, #T_17d5d_row18_col22 {\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row4_col17, #T_17d5d_row6_col1, #T_17d5d_row10_col7 {\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row4_col21, #T_17d5d_row17_col3 {\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row5_col0, #T_17d5d_row7_col10, #T_17d5d_row13_col3, #T_17d5d_row16_col22, #T_17d5d_row22_col8 {\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row5_col2, #T_17d5d_row7_col14, #T_17d5d_row11_col7 {\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row5_col3, #T_17d5d_row5_col20, #T_17d5d_row20_col5 {\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row5_col4 {\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row5_col6, #T_17d5d_row13_col6 {\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row5_col7, #T_17d5d_row7_col3, #T_17d5d_row12_col1, #T_17d5d_row13_col4, #T_17d5d_row15_col5 {\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row5_col8, #T_17d5d_row11_col9, #T_17d5d_row14_col10, #T_17d5d_row16_col14 {\n",
       "  background-color: #f39475;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row5_col9 {\n",
       "  background-color: #cb3e38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row5_col11 {\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row5_col12 {\n",
       "  background-color: #dc5d4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row5_col13, #T_17d5d_row10_col0, #T_17d5d_row11_col13 {\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row5_col14 {\n",
       "  background-color: #f18f71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row5_col15 {\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row5_col16, #T_17d5d_row11_col8 {\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row5_col18, #T_17d5d_row13_col12, #T_17d5d_row17_col8, #T_17d5d_row21_col10 {\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row5_col19, #T_17d5d_row7_col17, #T_17d5d_row13_col2 {\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row5_col21, #T_17d5d_row9_col22, #T_17d5d_row14_col21 {\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row5_col22 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row6_col0, #T_17d5d_row11_col2 {\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row6_col4 {\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row6_col7, #T_17d5d_row10_col22, #T_17d5d_row11_col17, #T_17d5d_row17_col16 {\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row6_col11, #T_17d5d_row7_col21, #T_17d5d_row20_col17 {\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row6_col12, #T_17d5d_row10_col20 {\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row6_col13, #T_17d5d_row20_col21, #T_17d5d_row21_col20 {\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row6_col15, #T_17d5d_row7_col11 {\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row6_col18 {\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row6_col19, #T_17d5d_row22_col18 {\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row6_col20, #T_17d5d_row22_col1 {\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row6_col21, #T_17d5d_row15_col2 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row6_col22, #T_17d5d_row9_col6, #T_17d5d_row15_col9 {\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row7_col1, #T_17d5d_row12_col6, #T_17d5d_row19_col3 {\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row7_col2, #T_17d5d_row13_col14 {\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row7_col5, #T_17d5d_row21_col11 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row7_col6 {\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row7_col8, #T_17d5d_row8_col22 {\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row7_col13, #T_17d5d_row16_col8 {\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row7_col15, #T_17d5d_row12_col8, #T_17d5d_row14_col4, #T_17d5d_row15_col7 {\n",
       "  background-color: #d55042;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row7_col18, #T_17d5d_row18_col7 {\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row7_col19 {\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row7_col22, #T_17d5d_row10_col11 {\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row8_col2, #T_17d5d_row19_col22, #T_17d5d_row20_col3 {\n",
       "  background-color: #c3d5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row8_col4, #T_17d5d_row13_col21, #T_17d5d_row20_col11 {\n",
       "  background-color: #ec7f63;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row8_col5, #T_17d5d_row12_col3, #T_17d5d_row12_col16, #T_17d5d_row14_col5, #T_17d5d_row15_col1 {\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row8_col9 {\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row8_col11 {\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row8_col14, #T_17d5d_row18_col15, #T_17d5d_row22_col21 {\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row8_col15 {\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row8_col16, #T_17d5d_row10_col8 {\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row8_col17, #T_17d5d_row13_col9, #T_17d5d_row21_col16, #T_17d5d_row22_col10 {\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row8_col18, #T_17d5d_row18_col6, #T_17d5d_row22_col3 {\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row9_col3, #T_17d5d_row11_col19, #T_17d5d_row18_col0 {\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row9_col11, #T_17d5d_row10_col12 {\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row9_col12 {\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row9_col13, #T_17d5d_row15_col11 {\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row9_col14 {\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row9_col15, #T_17d5d_row17_col14 {\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row9_col19 {\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row9_col20 {\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row10_col2, #T_17d5d_row21_col15 {\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row10_col5, #T_17d5d_row12_col19 {\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row10_col9 {\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row10_col15 {\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row10_col16, #T_17d5d_row16_col20 {\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row10_col17, #T_17d5d_row19_col9 {\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row10_col19, #T_17d5d_row12_col2 {\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row11_col5 {\n",
       "  background-color: #e16751;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row11_col10 {\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row11_col12, #T_17d5d_row12_col11 {\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row11_col14, #T_17d5d_row14_col11 {\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row11_col16, #T_17d5d_row14_col3, #T_17d5d_row14_col6 {\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row11_col22, #T_17d5d_row12_col7, #T_17d5d_row22_col12 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row12_col0, #T_17d5d_row17_col9, #T_17d5d_row20_col15 {\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row12_col5 {\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row12_col10, #T_17d5d_row18_col21, #T_17d5d_row20_col19 {\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row12_col13 {\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row12_col15, #T_17d5d_row18_col5, #T_17d5d_row18_col16 {\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row12_col17 {\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row12_col21, #T_17d5d_row18_col20 {\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row13_col1 {\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row13_col8, #T_17d5d_row22_col4 {\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row13_col10, #T_17d5d_row14_col1, #T_17d5d_row15_col16 {\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row13_col11, #T_17d5d_row22_col20 {\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row13_col15 {\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row13_col16 {\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row13_col17 {\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row13_col18, #T_17d5d_row21_col0 {\n",
       "  background-color: #f7ba9f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row13_col22 {\n",
       "  background-color: #f59c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row14_col0, #T_17d5d_row14_col22 {\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row14_col2, #T_17d5d_row17_col6, #T_17d5d_row18_col17 {\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row14_col8, #T_17d5d_row19_col6 {\n",
       "  background-color: #d1493f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row14_col9, #T_17d5d_row20_col16 {\n",
       "  background-color: #f5c2aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row14_col16 {\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row15_col3, #T_17d5d_row18_col3 {\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row15_col8, #T_17d5d_row15_col12, #T_17d5d_row16_col17, #T_17d5d_row21_col5, #T_17d5d_row21_col9, #T_17d5d_row21_col12 {\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row15_col13 {\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row15_col14 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row15_col17 {\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row15_col18, #T_17d5d_row21_col22 {\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row16_col4 {\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row16_col5 {\n",
       "  background-color: #e67259;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row16_col7 {\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row17_col0 {\n",
       "  background-color: #ead5c9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row17_col2, #T_17d5d_row19_col14 {\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row17_col13 {\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row17_col15 {\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row17_col21 {\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row17_col22, #T_17d5d_row20_col14 {\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row18_col8, #T_17d5d_row19_col15 {\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row18_col9 {\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row19_col4 {\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row19_col5 {\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row19_col10 {\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row19_col12 {\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row19_col13 {\n",
       "  background-color: #f1ccb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row19_col18, #T_17d5d_row20_col0, #T_17d5d_row21_col19 {\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row19_col20, #T_17d5d_row21_col18 {\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row19_col21 {\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row20_col7 {\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row20_col8 {\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row20_col22 {\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d5d_row21_col13 {\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row21_col17 {\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row22_col7 {\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d5d_row22_col17 {\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_17d5d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_17d5d_level0_col0\" class=\"col_heading level0 col0\" >error</th>\n",
       "      <th id=\"T_17d5d_level0_col1\" class=\"col_heading level0 col1\" >DN_HistogramMode_5</th>\n",
       "      <th id=\"T_17d5d_level0_col2\" class=\"col_heading level0 col2\" >DN_HistogramMode_10</th>\n",
       "      <th id=\"T_17d5d_level0_col3\" class=\"col_heading level0 col3\" >CO_f1ecac</th>\n",
       "      <th id=\"T_17d5d_level0_col4\" class=\"col_heading level0 col4\" >CO_FirstMin_ac</th>\n",
       "      <th id=\"T_17d5d_level0_col5\" class=\"col_heading level0 col5\" >CO_HistogramAMI_even_2_5</th>\n",
       "      <th id=\"T_17d5d_level0_col6\" class=\"col_heading level0 col6\" >CO_trev_1_num</th>\n",
       "      <th id=\"T_17d5d_level0_col7\" class=\"col_heading level0 col7\" >MD_hrv_classic_pnn40</th>\n",
       "      <th id=\"T_17d5d_level0_col8\" class=\"col_heading level0 col8\" >SB_BinaryStats_mean_longstretch1</th>\n",
       "      <th id=\"T_17d5d_level0_col9\" class=\"col_heading level0 col9\" >SB_TransitionMatrix_3ac_sumdiagcov</th>\n",
       "      <th id=\"T_17d5d_level0_col10\" class=\"col_heading level0 col10\" >PD_PeriodicityWang_th0_01</th>\n",
       "      <th id=\"T_17d5d_level0_col11\" class=\"col_heading level0 col11\" >CO_Embed2_Dist_tau_d_expfit_meandiff</th>\n",
       "      <th id=\"T_17d5d_level0_col12\" class=\"col_heading level0 col12\" >IN_AutoMutualInfoStats_40_gaussian_fmmi</th>\n",
       "      <th id=\"T_17d5d_level0_col13\" class=\"col_heading level0 col13\" >FC_LocalSimple_mean1_tauresrat</th>\n",
       "      <th id=\"T_17d5d_level0_col14\" class=\"col_heading level0 col14\" >DN_OutlierInclude_p_001_mdrmd</th>\n",
       "      <th id=\"T_17d5d_level0_col15\" class=\"col_heading level0 col15\" >DN_OutlierInclude_n_001_mdrmd</th>\n",
       "      <th id=\"T_17d5d_level0_col16\" class=\"col_heading level0 col16\" >SP_Summaries_welch_rect_area_5_1</th>\n",
       "      <th id=\"T_17d5d_level0_col17\" class=\"col_heading level0 col17\" >SB_BinaryStats_diff_longstretch0</th>\n",
       "      <th id=\"T_17d5d_level0_col18\" class=\"col_heading level0 col18\" >SB_MotifThree_quantile_hh</th>\n",
       "      <th id=\"T_17d5d_level0_col19\" class=\"col_heading level0 col19\" >SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1</th>\n",
       "      <th id=\"T_17d5d_level0_col20\" class=\"col_heading level0 col20\" >SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1</th>\n",
       "      <th id=\"T_17d5d_level0_col21\" class=\"col_heading level0 col21\" >SP_Summaries_welch_rect_centroid</th>\n",
       "      <th id=\"T_17d5d_level0_col22\" class=\"col_heading level0 col22\" >FC_LocalSimple_mean3_stderr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row0\" class=\"row_heading level0 row0\" >error</th>\n",
       "      <td id=\"T_17d5d_row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row0_col1\" class=\"data row0 col1\" >0.25</td>\n",
       "      <td id=\"T_17d5d_row0_col2\" class=\"data row0 col2\" >0.27</td>\n",
       "      <td id=\"T_17d5d_row0_col3\" class=\"data row0 col3\" >-0.51</td>\n",
       "      <td id=\"T_17d5d_row0_col4\" class=\"data row0 col4\" >-0.43</td>\n",
       "      <td id=\"T_17d5d_row0_col5\" class=\"data row0 col5\" >-0.52</td>\n",
       "      <td id=\"T_17d5d_row0_col6\" class=\"data row0 col6\" >0.02</td>\n",
       "      <td id=\"T_17d5d_row0_col7\" class=\"data row0 col7\" >0.19</td>\n",
       "      <td id=\"T_17d5d_row0_col8\" class=\"data row0 col8\" >-0.60</td>\n",
       "      <td id=\"T_17d5d_row0_col9\" class=\"data row0 col9\" >-0.49</td>\n",
       "      <td id=\"T_17d5d_row0_col10\" class=\"data row0 col10\" >-0.25</td>\n",
       "      <td id=\"T_17d5d_row0_col11\" class=\"data row0 col11\" >-0.52</td>\n",
       "      <td id=\"T_17d5d_row0_col12\" class=\"data row0 col12\" >-0.55</td>\n",
       "      <td id=\"T_17d5d_row0_col13\" class=\"data row0 col13\" >0.47</td>\n",
       "      <td id=\"T_17d5d_row0_col14\" class=\"data row0 col14\" >-0.50</td>\n",
       "      <td id=\"T_17d5d_row0_col15\" class=\"data row0 col15\" >0.32</td>\n",
       "      <td id=\"T_17d5d_row0_col16\" class=\"data row0 col16\" >-0.20</td>\n",
       "      <td id=\"T_17d5d_row0_col17\" class=\"data row0 col17\" >0.28</td>\n",
       "      <td id=\"T_17d5d_row0_col18\" class=\"data row0 col18\" >0.29</td>\n",
       "      <td id=\"T_17d5d_row0_col19\" class=\"data row0 col19\" >-0.20</td>\n",
       "      <td id=\"T_17d5d_row0_col20\" class=\"data row0 col20\" >-0.06</td>\n",
       "      <td id=\"T_17d5d_row0_col21\" class=\"data row0 col21\" >0.45</td>\n",
       "      <td id=\"T_17d5d_row0_col22\" class=\"data row0 col22\" >0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row1\" class=\"row_heading level0 row1\" >DN_HistogramMode_5</th>\n",
       "      <td id=\"T_17d5d_row1_col0\" class=\"data row1 col0\" >0.25</td>\n",
       "      <td id=\"T_17d5d_row1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row1_col2\" class=\"data row1 col2\" >0.53</td>\n",
       "      <td id=\"T_17d5d_row1_col3\" class=\"data row1 col3\" >-0.18</td>\n",
       "      <td id=\"T_17d5d_row1_col4\" class=\"data row1 col4\" >-0.10</td>\n",
       "      <td id=\"T_17d5d_row1_col5\" class=\"data row1 col5\" >-0.80</td>\n",
       "      <td id=\"T_17d5d_row1_col6\" class=\"data row1 col6\" >-0.49</td>\n",
       "      <td id=\"T_17d5d_row1_col7\" class=\"data row1 col7\" >0.33</td>\n",
       "      <td id=\"T_17d5d_row1_col8\" class=\"data row1 col8\" >-0.40</td>\n",
       "      <td id=\"T_17d5d_row1_col9\" class=\"data row1 col9\" >-0.48</td>\n",
       "      <td id=\"T_17d5d_row1_col10\" class=\"data row1 col10\" >0.23</td>\n",
       "      <td id=\"T_17d5d_row1_col11\" class=\"data row1 col11\" >-0.49</td>\n",
       "      <td id=\"T_17d5d_row1_col12\" class=\"data row1 col12\" >-0.45</td>\n",
       "      <td id=\"T_17d5d_row1_col13\" class=\"data row1 col13\" >-0.05</td>\n",
       "      <td id=\"T_17d5d_row1_col14\" class=\"data row1 col14\" >-0.46</td>\n",
       "      <td id=\"T_17d5d_row1_col15\" class=\"data row1 col15\" >0.58</td>\n",
       "      <td id=\"T_17d5d_row1_col16\" class=\"data row1 col16\" >-0.76</td>\n",
       "      <td id=\"T_17d5d_row1_col17\" class=\"data row1 col17\" >0.22</td>\n",
       "      <td id=\"T_17d5d_row1_col18\" class=\"data row1 col18\" >0.48</td>\n",
       "      <td id=\"T_17d5d_row1_col19\" class=\"data row1 col19\" >-0.57</td>\n",
       "      <td id=\"T_17d5d_row1_col20\" class=\"data row1 col20\" >-0.37</td>\n",
       "      <td id=\"T_17d5d_row1_col21\" class=\"data row1 col21\" >0.51</td>\n",
       "      <td id=\"T_17d5d_row1_col22\" class=\"data row1 col22\" >0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row2\" class=\"row_heading level0 row2\" >DN_HistogramMode_10</th>\n",
       "      <td id=\"T_17d5d_row2_col0\" class=\"data row2 col0\" >0.27</td>\n",
       "      <td id=\"T_17d5d_row2_col1\" class=\"data row2 col1\" >0.53</td>\n",
       "      <td id=\"T_17d5d_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row2_col3\" class=\"data row2 col3\" >0.14</td>\n",
       "      <td id=\"T_17d5d_row2_col4\" class=\"data row2 col4\" >0.20</td>\n",
       "      <td id=\"T_17d5d_row2_col5\" class=\"data row2 col5\" >-0.66</td>\n",
       "      <td id=\"T_17d5d_row2_col6\" class=\"data row2 col6\" >0.44</td>\n",
       "      <td id=\"T_17d5d_row2_col7\" class=\"data row2 col7\" >-0.25</td>\n",
       "      <td id=\"T_17d5d_row2_col8\" class=\"data row2 col8\" >-0.00</td>\n",
       "      <td id=\"T_17d5d_row2_col9\" class=\"data row2 col9\" >-0.70</td>\n",
       "      <td id=\"T_17d5d_row2_col10\" class=\"data row2 col10\" >0.43</td>\n",
       "      <td id=\"T_17d5d_row2_col11\" class=\"data row2 col11\" >-0.05</td>\n",
       "      <td id=\"T_17d5d_row2_col12\" class=\"data row2 col12\" >-0.10</td>\n",
       "      <td id=\"T_17d5d_row2_col13\" class=\"data row2 col13\" >0.16</td>\n",
       "      <td id=\"T_17d5d_row2_col14\" class=\"data row2 col14\" >0.21</td>\n",
       "      <td id=\"T_17d5d_row2_col15\" class=\"data row2 col15\" >-0.28</td>\n",
       "      <td id=\"T_17d5d_row2_col16\" class=\"data row2 col16\" >-0.37</td>\n",
       "      <td id=\"T_17d5d_row2_col17\" class=\"data row2 col17\" >0.56</td>\n",
       "      <td id=\"T_17d5d_row2_col18\" class=\"data row2 col18\" >-0.11</td>\n",
       "      <td id=\"T_17d5d_row2_col19\" class=\"data row2 col19\" >0.27</td>\n",
       "      <td id=\"T_17d5d_row2_col20\" class=\"data row2 col20\" >0.39</td>\n",
       "      <td id=\"T_17d5d_row2_col21\" class=\"data row2 col21\" >0.31</td>\n",
       "      <td id=\"T_17d5d_row2_col22\" class=\"data row2 col22\" >0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row3\" class=\"row_heading level0 row3\" >CO_f1ecac</th>\n",
       "      <td id=\"T_17d5d_row3_col0\" class=\"data row3 col0\" >-0.51</td>\n",
       "      <td id=\"T_17d5d_row3_col1\" class=\"data row3 col1\" >-0.18</td>\n",
       "      <td id=\"T_17d5d_row3_col2\" class=\"data row3 col2\" >0.14</td>\n",
       "      <td id=\"T_17d5d_row3_col3\" class=\"data row3 col3\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row3_col4\" class=\"data row3 col4\" >0.49</td>\n",
       "      <td id=\"T_17d5d_row3_col5\" class=\"data row3 col5\" >0.27</td>\n",
       "      <td id=\"T_17d5d_row3_col6\" class=\"data row3 col6\" >0.49</td>\n",
       "      <td id=\"T_17d5d_row3_col7\" class=\"data row3 col7\" >-0.46</td>\n",
       "      <td id=\"T_17d5d_row3_col8\" class=\"data row3 col8\" >0.92</td>\n",
       "      <td id=\"T_17d5d_row3_col9\" class=\"data row3 col9\" >0.19</td>\n",
       "      <td id=\"T_17d5d_row3_col10\" class=\"data row3 col10\" >0.39</td>\n",
       "      <td id=\"T_17d5d_row3_col11\" class=\"data row3 col11\" >0.44</td>\n",
       "      <td id=\"T_17d5d_row3_col12\" class=\"data row3 col12\" >0.58</td>\n",
       "      <td id=\"T_17d5d_row3_col13\" class=\"data row3 col13\" >-0.73</td>\n",
       "      <td id=\"T_17d5d_row3_col14\" class=\"data row3 col14\" >0.67</td>\n",
       "      <td id=\"T_17d5d_row3_col15\" class=\"data row3 col15\" >-0.42</td>\n",
       "      <td id=\"T_17d5d_row3_col16\" class=\"data row3 col16\" >0.28</td>\n",
       "      <td id=\"T_17d5d_row3_col17\" class=\"data row3 col17\" >-0.53</td>\n",
       "      <td id=\"T_17d5d_row3_col18\" class=\"data row3 col18\" >-0.43</td>\n",
       "      <td id=\"T_17d5d_row3_col19\" class=\"data row3 col19\" >0.33</td>\n",
       "      <td id=\"T_17d5d_row3_col20\" class=\"data row3 col20\" >-0.07</td>\n",
       "      <td id=\"T_17d5d_row3_col21\" class=\"data row3 col21\" >-0.81</td>\n",
       "      <td id=\"T_17d5d_row3_col22\" class=\"data row3 col22\" >-0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row4\" class=\"row_heading level0 row4\" >CO_FirstMin_ac</th>\n",
       "      <td id=\"T_17d5d_row4_col0\" class=\"data row4 col0\" >-0.43</td>\n",
       "      <td id=\"T_17d5d_row4_col1\" class=\"data row4 col1\" >-0.10</td>\n",
       "      <td id=\"T_17d5d_row4_col2\" class=\"data row4 col2\" >0.20</td>\n",
       "      <td id=\"T_17d5d_row4_col3\" class=\"data row4 col3\" >0.49</td>\n",
       "      <td id=\"T_17d5d_row4_col4\" class=\"data row4 col4\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row4_col5\" class=\"data row4 col5\" >0.45</td>\n",
       "      <td id=\"T_17d5d_row4_col6\" class=\"data row4 col6\" >0.29</td>\n",
       "      <td id=\"T_17d5d_row4_col7\" class=\"data row4 col7\" >-0.80</td>\n",
       "      <td id=\"T_17d5d_row4_col8\" class=\"data row4 col8\" >0.65</td>\n",
       "      <td id=\"T_17d5d_row4_col9\" class=\"data row4 col9\" >0.42</td>\n",
       "      <td id=\"T_17d5d_row4_col10\" class=\"data row4 col10\" >0.90</td>\n",
       "      <td id=\"T_17d5d_row4_col11\" class=\"data row4 col11\" >0.90</td>\n",
       "      <td id=\"T_17d5d_row4_col12\" class=\"data row4 col12\" >0.88</td>\n",
       "      <td id=\"T_17d5d_row4_col13\" class=\"data row4 col13\" >-0.50</td>\n",
       "      <td id=\"T_17d5d_row4_col14\" class=\"data row4 col14\" >0.82</td>\n",
       "      <td id=\"T_17d5d_row4_col15\" class=\"data row4 col15\" >-0.58</td>\n",
       "      <td id=\"T_17d5d_row4_col16\" class=\"data row4 col16\" >0.48</td>\n",
       "      <td id=\"T_17d5d_row4_col17\" class=\"data row4 col17\" >-0.36</td>\n",
       "      <td id=\"T_17d5d_row4_col18\" class=\"data row4 col18\" >-0.86</td>\n",
       "      <td id=\"T_17d5d_row4_col19\" class=\"data row4 col19\" >-0.02</td>\n",
       "      <td id=\"T_17d5d_row4_col20\" class=\"data row4 col20\" >0.47</td>\n",
       "      <td id=\"T_17d5d_row4_col21\" class=\"data row4 col21\" >-0.55</td>\n",
       "      <td id=\"T_17d5d_row4_col22\" class=\"data row4 col22\" >-0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row5\" class=\"row_heading level0 row5\" >CO_HistogramAMI_even_2_5</th>\n",
       "      <td id=\"T_17d5d_row5_col0\" class=\"data row5 col0\" >-0.52</td>\n",
       "      <td id=\"T_17d5d_row5_col1\" class=\"data row5 col1\" >-0.80</td>\n",
       "      <td id=\"T_17d5d_row5_col2\" class=\"data row5 col2\" >-0.66</td>\n",
       "      <td id=\"T_17d5d_row5_col3\" class=\"data row5 col3\" >0.27</td>\n",
       "      <td id=\"T_17d5d_row5_col4\" class=\"data row5 col4\" >0.45</td>\n",
       "      <td id=\"T_17d5d_row5_col5\" class=\"data row5 col5\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row5_col6\" class=\"data row5 col6\" >0.12</td>\n",
       "      <td id=\"T_17d5d_row5_col7\" class=\"data row5 col7\" >-0.51</td>\n",
       "      <td id=\"T_17d5d_row5_col8\" class=\"data row5 col8\" >0.57</td>\n",
       "      <td id=\"T_17d5d_row5_col9\" class=\"data row5 col9\" >0.89</td>\n",
       "      <td id=\"T_17d5d_row5_col10\" class=\"data row5 col10\" >0.07</td>\n",
       "      <td id=\"T_17d5d_row5_col11\" class=\"data row5 col11\" >0.74</td>\n",
       "      <td id=\"T_17d5d_row5_col12\" class=\"data row5 col12\" >0.77</td>\n",
       "      <td id=\"T_17d5d_row5_col13\" class=\"data row5 col13\" >-0.38</td>\n",
       "      <td id=\"T_17d5d_row5_col14\" class=\"data row5 col14\" >0.57</td>\n",
       "      <td id=\"T_17d5d_row5_col15\" class=\"data row5 col15\" >-0.48</td>\n",
       "      <td id=\"T_17d5d_row5_col16\" class=\"data row5 col16\" >0.70</td>\n",
       "      <td id=\"T_17d5d_row5_col17\" class=\"data row5 col17\" >-0.54</td>\n",
       "      <td id=\"T_17d5d_row5_col18\" class=\"data row5 col18\" >-0.65</td>\n",
       "      <td id=\"T_17d5d_row5_col19\" class=\"data row5 col19\" >0.13</td>\n",
       "      <td id=\"T_17d5d_row5_col20\" class=\"data row5 col20\" >0.26</td>\n",
       "      <td id=\"T_17d5d_row5_col21\" class=\"data row5 col21\" >-0.64</td>\n",
       "      <td id=\"T_17d5d_row5_col22\" class=\"data row5 col22\" >-0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row6\" class=\"row_heading level0 row6\" >CO_trev_1_num</th>\n",
       "      <td id=\"T_17d5d_row6_col0\" class=\"data row6 col0\" >0.02</td>\n",
       "      <td id=\"T_17d5d_row6_col1\" class=\"data row6 col1\" >-0.49</td>\n",
       "      <td id=\"T_17d5d_row6_col2\" class=\"data row6 col2\" >0.44</td>\n",
       "      <td id=\"T_17d5d_row6_col3\" class=\"data row6 col3\" >0.49</td>\n",
       "      <td id=\"T_17d5d_row6_col4\" class=\"data row6 col4\" >0.29</td>\n",
       "      <td id=\"T_17d5d_row6_col5\" class=\"data row6 col5\" >0.12</td>\n",
       "      <td id=\"T_17d5d_row6_col6\" class=\"data row6 col6\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row6_col7\" class=\"data row6 col7\" >-0.51</td>\n",
       "      <td id=\"T_17d5d_row6_col8\" class=\"data row6 col8\" >0.49</td>\n",
       "      <td id=\"T_17d5d_row6_col9\" class=\"data row6 col9\" >-0.26</td>\n",
       "      <td id=\"T_17d5d_row6_col10\" class=\"data row6 col10\" >0.23</td>\n",
       "      <td id=\"T_17d5d_row6_col11\" class=\"data row6 col11\" >0.41</td>\n",
       "      <td id=\"T_17d5d_row6_col12\" class=\"data row6 col12\" >0.33</td>\n",
       "      <td id=\"T_17d5d_row6_col13\" class=\"data row6 col13\" >0.13</td>\n",
       "      <td id=\"T_17d5d_row6_col14\" class=\"data row6 col14\" >0.67</td>\n",
       "      <td id=\"T_17d5d_row6_col15\" class=\"data row6 col15\" >-0.80</td>\n",
       "      <td id=\"T_17d5d_row6_col16\" class=\"data row6 col16\" >0.49</td>\n",
       "      <td id=\"T_17d5d_row6_col17\" class=\"data row6 col17\" >0.17</td>\n",
       "      <td id=\"T_17d5d_row6_col18\" class=\"data row6 col18\" >-0.55</td>\n",
       "      <td id=\"T_17d5d_row6_col19\" class=\"data row6 col19\" >0.85</td>\n",
       "      <td id=\"T_17d5d_row6_col20\" class=\"data row6 col20\" >0.61</td>\n",
       "      <td id=\"T_17d5d_row6_col21\" class=\"data row6 col21\" >-0.39</td>\n",
       "      <td id=\"T_17d5d_row6_col22\" class=\"data row6 col22\" >-0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row7\" class=\"row_heading level0 row7\" >MD_hrv_classic_pnn40</th>\n",
       "      <td id=\"T_17d5d_row7_col0\" class=\"data row7 col0\" >0.19</td>\n",
       "      <td id=\"T_17d5d_row7_col1\" class=\"data row7 col1\" >0.33</td>\n",
       "      <td id=\"T_17d5d_row7_col2\" class=\"data row7 col2\" >-0.25</td>\n",
       "      <td id=\"T_17d5d_row7_col3\" class=\"data row7 col3\" >-0.46</td>\n",
       "      <td id=\"T_17d5d_row7_col4\" class=\"data row7 col4\" >-0.80</td>\n",
       "      <td id=\"T_17d5d_row7_col5\" class=\"data row7 col5\" >-0.51</td>\n",
       "      <td id=\"T_17d5d_row7_col6\" class=\"data row7 col6\" >-0.51</td>\n",
       "      <td id=\"T_17d5d_row7_col7\" class=\"data row7 col7\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row7_col8\" class=\"data row7 col8\" >-0.70</td>\n",
       "      <td id=\"T_17d5d_row7_col9\" class=\"data row7 col9\" >-0.45</td>\n",
       "      <td id=\"T_17d5d_row7_col10\" class=\"data row7 col10\" >-0.56</td>\n",
       "      <td id=\"T_17d5d_row7_col11\" class=\"data row7 col11\" >-0.84</td>\n",
       "      <td id=\"T_17d5d_row7_col12\" class=\"data row7 col12\" >-0.87</td>\n",
       "      <td id=\"T_17d5d_row7_col13\" class=\"data row7 col13\" >0.44</td>\n",
       "      <td id=\"T_17d5d_row7_col14\" class=\"data row7 col14\" >-0.88</td>\n",
       "      <td id=\"T_17d5d_row7_col15\" class=\"data row7 col15\" >0.82</td>\n",
       "      <td id=\"T_17d5d_row7_col16\" class=\"data row7 col16\" >-0.38</td>\n",
       "      <td id=\"T_17d5d_row7_col17\" class=\"data row7 col17\" >0.18</td>\n",
       "      <td id=\"T_17d5d_row7_col18\" class=\"data row7 col18\" >0.94</td>\n",
       "      <td id=\"T_17d5d_row7_col19\" class=\"data row7 col19\" >-0.25</td>\n",
       "      <td id=\"T_17d5d_row7_col20\" class=\"data row7 col20\" >-0.66</td>\n",
       "      <td id=\"T_17d5d_row7_col21\" class=\"data row7 col21\" >0.44</td>\n",
       "      <td id=\"T_17d5d_row7_col22\" class=\"data row7 col22\" >0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row8\" class=\"row_heading level0 row8\" >SB_BinaryStats_mean_longstretch1</th>\n",
       "      <td id=\"T_17d5d_row8_col0\" class=\"data row8 col0\" >-0.60</td>\n",
       "      <td id=\"T_17d5d_row8_col1\" class=\"data row8 col1\" >-0.40</td>\n",
       "      <td id=\"T_17d5d_row8_col2\" class=\"data row8 col2\" >-0.00</td>\n",
       "      <td id=\"T_17d5d_row8_col3\" class=\"data row8 col3\" >0.92</td>\n",
       "      <td id=\"T_17d5d_row8_col4\" class=\"data row8 col4\" >0.65</td>\n",
       "      <td id=\"T_17d5d_row8_col5\" class=\"data row8 col5\" >0.57</td>\n",
       "      <td id=\"T_17d5d_row8_col6\" class=\"data row8 col6\" >0.49</td>\n",
       "      <td id=\"T_17d5d_row8_col7\" class=\"data row8 col7\" >-0.70</td>\n",
       "      <td id=\"T_17d5d_row8_col8\" class=\"data row8 col8\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row8_col9\" class=\"data row8 col9\" >0.48</td>\n",
       "      <td id=\"T_17d5d_row8_col10\" class=\"data row8 col10\" >0.41</td>\n",
       "      <td id=\"T_17d5d_row8_col11\" class=\"data row8 col11\" >0.69</td>\n",
       "      <td id=\"T_17d5d_row8_col12\" class=\"data row8 col12\" >0.82</td>\n",
       "      <td id=\"T_17d5d_row8_col13\" class=\"data row8 col13\" >-0.76</td>\n",
       "      <td id=\"T_17d5d_row8_col14\" class=\"data row8 col14\" >0.84</td>\n",
       "      <td id=\"T_17d5d_row8_col15\" class=\"data row8 col15\" >-0.63</td>\n",
       "      <td id=\"T_17d5d_row8_col16\" class=\"data row8 col16\" >0.42</td>\n",
       "      <td id=\"T_17d5d_row8_col17\" class=\"data row8 col17\" >-0.55</td>\n",
       "      <td id=\"T_17d5d_row8_col18\" class=\"data row8 col18\" >-0.68</td>\n",
       "      <td id=\"T_17d5d_row8_col19\" class=\"data row8 col19\" >0.34</td>\n",
       "      <td id=\"T_17d5d_row8_col20\" class=\"data row8 col20\" >0.16</td>\n",
       "      <td id=\"T_17d5d_row8_col21\" class=\"data row8 col21\" >-0.84</td>\n",
       "      <td id=\"T_17d5d_row8_col22\" class=\"data row8 col22\" >-0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row9\" class=\"row_heading level0 row9\" >SB_TransitionMatrix_3ac_sumdiagcov</th>\n",
       "      <td id=\"T_17d5d_row9_col0\" class=\"data row9 col0\" >-0.49</td>\n",
       "      <td id=\"T_17d5d_row9_col1\" class=\"data row9 col1\" >-0.48</td>\n",
       "      <td id=\"T_17d5d_row9_col2\" class=\"data row9 col2\" >-0.70</td>\n",
       "      <td id=\"T_17d5d_row9_col3\" class=\"data row9 col3\" >0.19</td>\n",
       "      <td id=\"T_17d5d_row9_col4\" class=\"data row9 col4\" >0.42</td>\n",
       "      <td id=\"T_17d5d_row9_col5\" class=\"data row9 col5\" >0.89</td>\n",
       "      <td id=\"T_17d5d_row9_col6\" class=\"data row9 col6\" >-0.26</td>\n",
       "      <td id=\"T_17d5d_row9_col7\" class=\"data row9 col7\" >-0.45</td>\n",
       "      <td id=\"T_17d5d_row9_col8\" class=\"data row9 col8\" >0.48</td>\n",
       "      <td id=\"T_17d5d_row9_col9\" class=\"data row9 col9\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row9_col10\" class=\"data row9 col10\" >0.06</td>\n",
       "      <td id=\"T_17d5d_row9_col11\" class=\"data row9 col11\" >0.60</td>\n",
       "      <td id=\"T_17d5d_row9_col12\" class=\"data row9 col12\" >0.71</td>\n",
       "      <td id=\"T_17d5d_row9_col13\" class=\"data row9 col13\" >-0.60</td>\n",
       "      <td id=\"T_17d5d_row9_col14\" class=\"data row9 col14\" >0.37</td>\n",
       "      <td id=\"T_17d5d_row9_col15\" class=\"data row9 col15\" >-0.19</td>\n",
       "      <td id=\"T_17d5d_row9_col16\" class=\"data row9 col16\" >0.39</td>\n",
       "      <td id=\"T_17d5d_row9_col17\" class=\"data row9 col17\" >-0.65</td>\n",
       "      <td id=\"T_17d5d_row9_col18\" class=\"data row9 col18\" >-0.49</td>\n",
       "      <td id=\"T_17d5d_row9_col19\" class=\"data row9 col19\" >-0.26</td>\n",
       "      <td id=\"T_17d5d_row9_col20\" class=\"data row9 col20\" >0.00</td>\n",
       "      <td id=\"T_17d5d_row9_col21\" class=\"data row9 col21\" >-0.50</td>\n",
       "      <td id=\"T_17d5d_row9_col22\" class=\"data row9 col22\" >-0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row10\" class=\"row_heading level0 row10\" >PD_PeriodicityWang_th0_01</th>\n",
       "      <td id=\"T_17d5d_row10_col0\" class=\"data row10 col0\" >-0.25</td>\n",
       "      <td id=\"T_17d5d_row10_col1\" class=\"data row10 col1\" >0.23</td>\n",
       "      <td id=\"T_17d5d_row10_col2\" class=\"data row10 col2\" >0.43</td>\n",
       "      <td id=\"T_17d5d_row10_col3\" class=\"data row10 col3\" >0.39</td>\n",
       "      <td id=\"T_17d5d_row10_col4\" class=\"data row10 col4\" >0.90</td>\n",
       "      <td id=\"T_17d5d_row10_col5\" class=\"data row10 col5\" >0.07</td>\n",
       "      <td id=\"T_17d5d_row10_col6\" class=\"data row10 col6\" >0.23</td>\n",
       "      <td id=\"T_17d5d_row10_col7\" class=\"data row10 col7\" >-0.56</td>\n",
       "      <td id=\"T_17d5d_row10_col8\" class=\"data row10 col8\" >0.41</td>\n",
       "      <td id=\"T_17d5d_row10_col9\" class=\"data row10 col9\" >0.06</td>\n",
       "      <td id=\"T_17d5d_row10_col10\" class=\"data row10 col10\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row10_col11\" class=\"data row10 col11\" >0.66</td>\n",
       "      <td id=\"T_17d5d_row10_col12\" class=\"data row10 col12\" >0.60</td>\n",
       "      <td id=\"T_17d5d_row10_col13\" class=\"data row10 col13\" >-0.33</td>\n",
       "      <td id=\"T_17d5d_row10_col14\" class=\"data row10 col14\" >0.61</td>\n",
       "      <td id=\"T_17d5d_row10_col15\" class=\"data row10 col15\" >-0.36</td>\n",
       "      <td id=\"T_17d5d_row10_col16\" class=\"data row10 col16\" >0.33</td>\n",
       "      <td id=\"T_17d5d_row10_col17\" class=\"data row10 col17\" >-0.22</td>\n",
       "      <td id=\"T_17d5d_row10_col18\" class=\"data row10 col18\" >-0.63</td>\n",
       "      <td id=\"T_17d5d_row10_col19\" class=\"data row10 col19\" >-0.13</td>\n",
       "      <td id=\"T_17d5d_row10_col20\" class=\"data row10 col20\" >0.35</td>\n",
       "      <td id=\"T_17d5d_row10_col21\" class=\"data row10 col21\" >-0.38</td>\n",
       "      <td id=\"T_17d5d_row10_col22\" class=\"data row10 col22\" >-0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row11\" class=\"row_heading level0 row11\" >CO_Embed2_Dist_tau_d_expfit_meandiff</th>\n",
       "      <td id=\"T_17d5d_row11_col0\" class=\"data row11 col0\" >-0.52</td>\n",
       "      <td id=\"T_17d5d_row11_col1\" class=\"data row11 col1\" >-0.49</td>\n",
       "      <td id=\"T_17d5d_row11_col2\" class=\"data row11 col2\" >-0.05</td>\n",
       "      <td id=\"T_17d5d_row11_col3\" class=\"data row11 col3\" >0.44</td>\n",
       "      <td id=\"T_17d5d_row11_col4\" class=\"data row11 col4\" >0.90</td>\n",
       "      <td id=\"T_17d5d_row11_col5\" class=\"data row11 col5\" >0.74</td>\n",
       "      <td id=\"T_17d5d_row11_col6\" class=\"data row11 col6\" >0.41</td>\n",
       "      <td id=\"T_17d5d_row11_col7\" class=\"data row11 col7\" >-0.84</td>\n",
       "      <td id=\"T_17d5d_row11_col8\" class=\"data row11 col8\" >0.69</td>\n",
       "      <td id=\"T_17d5d_row11_col9\" class=\"data row11 col9\" >0.60</td>\n",
       "      <td id=\"T_17d5d_row11_col10\" class=\"data row11 col10\" >0.66</td>\n",
       "      <td id=\"T_17d5d_row11_col11\" class=\"data row11 col11\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row11_col12\" class=\"data row11 col12\" >0.96</td>\n",
       "      <td id=\"T_17d5d_row11_col13\" class=\"data row11 col13\" >-0.38</td>\n",
       "      <td id=\"T_17d5d_row11_col14\" class=\"data row11 col14\" >0.91</td>\n",
       "      <td id=\"T_17d5d_row11_col15\" class=\"data row11 col15\" >-0.77</td>\n",
       "      <td id=\"T_17d5d_row11_col16\" class=\"data row11 col16\" >0.67</td>\n",
       "      <td id=\"T_17d5d_row11_col17\" class=\"data row11 col17\" >-0.32</td>\n",
       "      <td id=\"T_17d5d_row11_col18\" class=\"data row11 col18\" >-0.96</td>\n",
       "      <td id=\"T_17d5d_row11_col19\" class=\"data row11 col19\" >0.23</td>\n",
       "      <td id=\"T_17d5d_row11_col20\" class=\"data row11 col20\" >0.63</td>\n",
       "      <td id=\"T_17d5d_row11_col21\" class=\"data row11 col21\" >-0.60</td>\n",
       "      <td id=\"T_17d5d_row11_col22\" class=\"data row11 col22\" >-0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row12\" class=\"row_heading level0 row12\" >IN_AutoMutualInfoStats_40_gaussian_fmmi</th>\n",
       "      <td id=\"T_17d5d_row12_col0\" class=\"data row12 col0\" >-0.55</td>\n",
       "      <td id=\"T_17d5d_row12_col1\" class=\"data row12 col1\" >-0.45</td>\n",
       "      <td id=\"T_17d5d_row12_col2\" class=\"data row12 col2\" >-0.10</td>\n",
       "      <td id=\"T_17d5d_row12_col3\" class=\"data row12 col3\" >0.58</td>\n",
       "      <td id=\"T_17d5d_row12_col4\" class=\"data row12 col4\" >0.88</td>\n",
       "      <td id=\"T_17d5d_row12_col5\" class=\"data row12 col5\" >0.77</td>\n",
       "      <td id=\"T_17d5d_row12_col6\" class=\"data row12 col6\" >0.33</td>\n",
       "      <td id=\"T_17d5d_row12_col7\" class=\"data row12 col7\" >-0.87</td>\n",
       "      <td id=\"T_17d5d_row12_col8\" class=\"data row12 col8\" >0.82</td>\n",
       "      <td id=\"T_17d5d_row12_col9\" class=\"data row12 col9\" >0.71</td>\n",
       "      <td id=\"T_17d5d_row12_col10\" class=\"data row12 col10\" >0.60</td>\n",
       "      <td id=\"T_17d5d_row12_col11\" class=\"data row12 col11\" >0.96</td>\n",
       "      <td id=\"T_17d5d_row12_col12\" class=\"data row12 col12\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row12_col13\" class=\"data row12 col13\" >-0.62</td>\n",
       "      <td id=\"T_17d5d_row12_col14\" class=\"data row12 col14\" >0.90</td>\n",
       "      <td id=\"T_17d5d_row12_col15\" class=\"data row12 col15\" >-0.70</td>\n",
       "      <td id=\"T_17d5d_row12_col16\" class=\"data row12 col16\" >0.57</td>\n",
       "      <td id=\"T_17d5d_row12_col17\" class=\"data row12 col17\" >-0.49</td>\n",
       "      <td id=\"T_17d5d_row12_col18\" class=\"data row12 col18\" >-0.92</td>\n",
       "      <td id=\"T_17d5d_row12_col19\" class=\"data row12 col19\" >0.13</td>\n",
       "      <td id=\"T_17d5d_row12_col20\" class=\"data row12 col20\" >0.45</td>\n",
       "      <td id=\"T_17d5d_row12_col21\" class=\"data row12 col21\" >-0.70</td>\n",
       "      <td id=\"T_17d5d_row12_col22\" class=\"data row12 col22\" >-0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row13\" class=\"row_heading level0 row13\" >FC_LocalSimple_mean1_tauresrat</th>\n",
       "      <td id=\"T_17d5d_row13_col0\" class=\"data row13 col0\" >0.47</td>\n",
       "      <td id=\"T_17d5d_row13_col1\" class=\"data row13 col1\" >-0.05</td>\n",
       "      <td id=\"T_17d5d_row13_col2\" class=\"data row13 col2\" >0.16</td>\n",
       "      <td id=\"T_17d5d_row13_col3\" class=\"data row13 col3\" >-0.73</td>\n",
       "      <td id=\"T_17d5d_row13_col4\" class=\"data row13 col4\" >-0.50</td>\n",
       "      <td id=\"T_17d5d_row13_col5\" class=\"data row13 col5\" >-0.38</td>\n",
       "      <td id=\"T_17d5d_row13_col6\" class=\"data row13 col6\" >0.13</td>\n",
       "      <td id=\"T_17d5d_row13_col7\" class=\"data row13 col7\" >0.44</td>\n",
       "      <td id=\"T_17d5d_row13_col8\" class=\"data row13 col8\" >-0.76</td>\n",
       "      <td id=\"T_17d5d_row13_col9\" class=\"data row13 col9\" >-0.60</td>\n",
       "      <td id=\"T_17d5d_row13_col10\" class=\"data row13 col10\" >-0.33</td>\n",
       "      <td id=\"T_17d5d_row13_col11\" class=\"data row13 col11\" >-0.38</td>\n",
       "      <td id=\"T_17d5d_row13_col12\" class=\"data row13 col12\" >-0.62</td>\n",
       "      <td id=\"T_17d5d_row13_col13\" class=\"data row13 col13\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row13_col14\" class=\"data row13 col14\" >-0.42</td>\n",
       "      <td id=\"T_17d5d_row13_col15\" class=\"data row13 col15\" >0.07</td>\n",
       "      <td id=\"T_17d5d_row13_col16\" class=\"data row13 col16\" >-0.02</td>\n",
       "      <td id=\"T_17d5d_row13_col17\" class=\"data row13 col17\" >0.76</td>\n",
       "      <td id=\"T_17d5d_row13_col18\" class=\"data row13 col18\" >0.33</td>\n",
       "      <td id=\"T_17d5d_row13_col19\" class=\"data row13 col19\" >0.29</td>\n",
       "      <td id=\"T_17d5d_row13_col20\" class=\"data row13 col20\" >0.33</td>\n",
       "      <td id=\"T_17d5d_row13_col21\" class=\"data row13 col21\" >0.65</td>\n",
       "      <td id=\"T_17d5d_row13_col22\" class=\"data row13 col22\" >0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row14\" class=\"row_heading level0 row14\" >DN_OutlierInclude_p_001_mdrmd</th>\n",
       "      <td id=\"T_17d5d_row14_col0\" class=\"data row14 col0\" >-0.50</td>\n",
       "      <td id=\"T_17d5d_row14_col1\" class=\"data row14 col1\" >-0.46</td>\n",
       "      <td id=\"T_17d5d_row14_col2\" class=\"data row14 col2\" >0.21</td>\n",
       "      <td id=\"T_17d5d_row14_col3\" class=\"data row14 col3\" >0.67</td>\n",
       "      <td id=\"T_17d5d_row14_col4\" class=\"data row14 col4\" >0.82</td>\n",
       "      <td id=\"T_17d5d_row14_col5\" class=\"data row14 col5\" >0.57</td>\n",
       "      <td id=\"T_17d5d_row14_col6\" class=\"data row14 col6\" >0.67</td>\n",
       "      <td id=\"T_17d5d_row14_col7\" class=\"data row14 col7\" >-0.88</td>\n",
       "      <td id=\"T_17d5d_row14_col8\" class=\"data row14 col8\" >0.84</td>\n",
       "      <td id=\"T_17d5d_row14_col9\" class=\"data row14 col9\" >0.37</td>\n",
       "      <td id=\"T_17d5d_row14_col10\" class=\"data row14 col10\" >0.61</td>\n",
       "      <td id=\"T_17d5d_row14_col11\" class=\"data row14 col11\" >0.91</td>\n",
       "      <td id=\"T_17d5d_row14_col12\" class=\"data row14 col12\" >0.90</td>\n",
       "      <td id=\"T_17d5d_row14_col13\" class=\"data row14 col13\" >-0.42</td>\n",
       "      <td id=\"T_17d5d_row14_col14\" class=\"data row14 col14\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row14_col15\" class=\"data row14 col15\" >-0.90</td>\n",
       "      <td id=\"T_17d5d_row14_col16\" class=\"data row14 col16\" >0.55</td>\n",
       "      <td id=\"T_17d5d_row14_col17\" class=\"data row14 col17\" >-0.21</td>\n",
       "      <td id=\"T_17d5d_row14_col18\" class=\"data row14 col18\" >-0.93</td>\n",
       "      <td id=\"T_17d5d_row14_col19\" class=\"data row14 col19\" >0.50</td>\n",
       "      <td id=\"T_17d5d_row14_col20\" class=\"data row14 col20\" >0.64</td>\n",
       "      <td id=\"T_17d5d_row14_col21\" class=\"data row14 col21\" >-0.63</td>\n",
       "      <td id=\"T_17d5d_row14_col22\" class=\"data row14 col22\" >-0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row15\" class=\"row_heading level0 row15\" >DN_OutlierInclude_n_001_mdrmd</th>\n",
       "      <td id=\"T_17d5d_row15_col0\" class=\"data row15 col0\" >0.32</td>\n",
       "      <td id=\"T_17d5d_row15_col1\" class=\"data row15 col1\" >0.58</td>\n",
       "      <td id=\"T_17d5d_row15_col2\" class=\"data row15 col2\" >-0.28</td>\n",
       "      <td id=\"T_17d5d_row15_col3\" class=\"data row15 col3\" >-0.42</td>\n",
       "      <td id=\"T_17d5d_row15_col4\" class=\"data row15 col4\" >-0.58</td>\n",
       "      <td id=\"T_17d5d_row15_col5\" class=\"data row15 col5\" >-0.48</td>\n",
       "      <td id=\"T_17d5d_row15_col6\" class=\"data row15 col6\" >-0.80</td>\n",
       "      <td id=\"T_17d5d_row15_col7\" class=\"data row15 col7\" >0.82</td>\n",
       "      <td id=\"T_17d5d_row15_col8\" class=\"data row15 col8\" >-0.63</td>\n",
       "      <td id=\"T_17d5d_row15_col9\" class=\"data row15 col9\" >-0.19</td>\n",
       "      <td id=\"T_17d5d_row15_col10\" class=\"data row15 col10\" >-0.36</td>\n",
       "      <td id=\"T_17d5d_row15_col11\" class=\"data row15 col11\" >-0.77</td>\n",
       "      <td id=\"T_17d5d_row15_col12\" class=\"data row15 col12\" >-0.70</td>\n",
       "      <td id=\"T_17d5d_row15_col13\" class=\"data row15 col13\" >0.07</td>\n",
       "      <td id=\"T_17d5d_row15_col14\" class=\"data row15 col14\" >-0.90</td>\n",
       "      <td id=\"T_17d5d_row15_col15\" class=\"data row15 col15\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row15_col16\" class=\"data row15 col16\" >-0.48</td>\n",
       "      <td id=\"T_17d5d_row15_col17\" class=\"data row15 col17\" >-0.15</td>\n",
       "      <td id=\"T_17d5d_row15_col18\" class=\"data row15 col18\" >0.85</td>\n",
       "      <td id=\"T_17d5d_row15_col19\" class=\"data row15 col19\" >-0.74</td>\n",
       "      <td id=\"T_17d5d_row15_col20\" class=\"data row15 col20\" >-0.85</td>\n",
       "      <td id=\"T_17d5d_row15_col21\" class=\"data row15 col21\" >0.36</td>\n",
       "      <td id=\"T_17d5d_row15_col22\" class=\"data row15 col22\" >0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row16\" class=\"row_heading level0 row16\" >SP_Summaries_welch_rect_area_5_1</th>\n",
       "      <td id=\"T_17d5d_row16_col0\" class=\"data row16 col0\" >-0.20</td>\n",
       "      <td id=\"T_17d5d_row16_col1\" class=\"data row16 col1\" >-0.76</td>\n",
       "      <td id=\"T_17d5d_row16_col2\" class=\"data row16 col2\" >-0.37</td>\n",
       "      <td id=\"T_17d5d_row16_col3\" class=\"data row16 col3\" >0.28</td>\n",
       "      <td id=\"T_17d5d_row16_col4\" class=\"data row16 col4\" >0.48</td>\n",
       "      <td id=\"T_17d5d_row16_col5\" class=\"data row16 col5\" >0.70</td>\n",
       "      <td id=\"T_17d5d_row16_col6\" class=\"data row16 col6\" >0.49</td>\n",
       "      <td id=\"T_17d5d_row16_col7\" class=\"data row16 col7\" >-0.38</td>\n",
       "      <td id=\"T_17d5d_row16_col8\" class=\"data row16 col8\" >0.42</td>\n",
       "      <td id=\"T_17d5d_row16_col9\" class=\"data row16 col9\" >0.39</td>\n",
       "      <td id=\"T_17d5d_row16_col10\" class=\"data row16 col10\" >0.33</td>\n",
       "      <td id=\"T_17d5d_row16_col11\" class=\"data row16 col11\" >0.67</td>\n",
       "      <td id=\"T_17d5d_row16_col12\" class=\"data row16 col12\" >0.57</td>\n",
       "      <td id=\"T_17d5d_row16_col13\" class=\"data row16 col13\" >-0.02</td>\n",
       "      <td id=\"T_17d5d_row16_col14\" class=\"data row16 col14\" >0.55</td>\n",
       "      <td id=\"T_17d5d_row16_col15\" class=\"data row16 col15\" >-0.48</td>\n",
       "      <td id=\"T_17d5d_row16_col16\" class=\"data row16 col16\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row16_col17\" class=\"data row16 col17\" >-0.46</td>\n",
       "      <td id=\"T_17d5d_row16_col18\" class=\"data row16 col18\" >-0.63</td>\n",
       "      <td id=\"T_17d5d_row16_col19\" class=\"data row16 col19\" >0.28</td>\n",
       "      <td id=\"T_17d5d_row16_col20\" class=\"data row16 col20\" >0.32</td>\n",
       "      <td id=\"T_17d5d_row16_col21\" class=\"data row16 col21\" >-0.72</td>\n",
       "      <td id=\"T_17d5d_row16_col22\" class=\"data row16 col22\" >-0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row17\" class=\"row_heading level0 row17\" >SB_BinaryStats_diff_longstretch0</th>\n",
       "      <td id=\"T_17d5d_row17_col0\" class=\"data row17 col0\" >0.28</td>\n",
       "      <td id=\"T_17d5d_row17_col1\" class=\"data row17 col1\" >0.22</td>\n",
       "      <td id=\"T_17d5d_row17_col2\" class=\"data row17 col2\" >0.56</td>\n",
       "      <td id=\"T_17d5d_row17_col3\" class=\"data row17 col3\" >-0.53</td>\n",
       "      <td id=\"T_17d5d_row17_col4\" class=\"data row17 col4\" >-0.36</td>\n",
       "      <td id=\"T_17d5d_row17_col5\" class=\"data row17 col5\" >-0.54</td>\n",
       "      <td id=\"T_17d5d_row17_col6\" class=\"data row17 col6\" >0.17</td>\n",
       "      <td id=\"T_17d5d_row17_col7\" class=\"data row17 col7\" >0.18</td>\n",
       "      <td id=\"T_17d5d_row17_col8\" class=\"data row17 col8\" >-0.55</td>\n",
       "      <td id=\"T_17d5d_row17_col9\" class=\"data row17 col9\" >-0.65</td>\n",
       "      <td id=\"T_17d5d_row17_col10\" class=\"data row17 col10\" >-0.22</td>\n",
       "      <td id=\"T_17d5d_row17_col11\" class=\"data row17 col11\" >-0.32</td>\n",
       "      <td id=\"T_17d5d_row17_col12\" class=\"data row17 col12\" >-0.49</td>\n",
       "      <td id=\"T_17d5d_row17_col13\" class=\"data row17 col13\" >0.76</td>\n",
       "      <td id=\"T_17d5d_row17_col14\" class=\"data row17 col14\" >-0.21</td>\n",
       "      <td id=\"T_17d5d_row17_col15\" class=\"data row17 col15\" >-0.15</td>\n",
       "      <td id=\"T_17d5d_row17_col16\" class=\"data row17 col16\" >-0.46</td>\n",
       "      <td id=\"T_17d5d_row17_col17\" class=\"data row17 col17\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row17_col18\" class=\"data row17 col18\" >0.24</td>\n",
       "      <td id=\"T_17d5d_row17_col19\" class=\"data row17 col19\" >0.41</td>\n",
       "      <td id=\"T_17d5d_row17_col20\" class=\"data row17 col20\" >0.50</td>\n",
       "      <td id=\"T_17d5d_row17_col21\" class=\"data row17 col21\" >0.82</td>\n",
       "      <td id=\"T_17d5d_row17_col22\" class=\"data row17 col22\" >0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row18\" class=\"row_heading level0 row18\" >SB_MotifThree_quantile_hh</th>\n",
       "      <td id=\"T_17d5d_row18_col0\" class=\"data row18 col0\" >0.29</td>\n",
       "      <td id=\"T_17d5d_row18_col1\" class=\"data row18 col1\" >0.48</td>\n",
       "      <td id=\"T_17d5d_row18_col2\" class=\"data row18 col2\" >-0.11</td>\n",
       "      <td id=\"T_17d5d_row18_col3\" class=\"data row18 col3\" >-0.43</td>\n",
       "      <td id=\"T_17d5d_row18_col4\" class=\"data row18 col4\" >-0.86</td>\n",
       "      <td id=\"T_17d5d_row18_col5\" class=\"data row18 col5\" >-0.65</td>\n",
       "      <td id=\"T_17d5d_row18_col6\" class=\"data row18 col6\" >-0.55</td>\n",
       "      <td id=\"T_17d5d_row18_col7\" class=\"data row18 col7\" >0.94</td>\n",
       "      <td id=\"T_17d5d_row18_col8\" class=\"data row18 col8\" >-0.68</td>\n",
       "      <td id=\"T_17d5d_row18_col9\" class=\"data row18 col9\" >-0.49</td>\n",
       "      <td id=\"T_17d5d_row18_col10\" class=\"data row18 col10\" >-0.63</td>\n",
       "      <td id=\"T_17d5d_row18_col11\" class=\"data row18 col11\" >-0.96</td>\n",
       "      <td id=\"T_17d5d_row18_col12\" class=\"data row18 col12\" >-0.92</td>\n",
       "      <td id=\"T_17d5d_row18_col13\" class=\"data row18 col13\" >0.33</td>\n",
       "      <td id=\"T_17d5d_row18_col14\" class=\"data row18 col14\" >-0.93</td>\n",
       "      <td id=\"T_17d5d_row18_col15\" class=\"data row18 col15\" >0.85</td>\n",
       "      <td id=\"T_17d5d_row18_col16\" class=\"data row18 col16\" >-0.63</td>\n",
       "      <td id=\"T_17d5d_row18_col17\" class=\"data row18 col17\" >0.24</td>\n",
       "      <td id=\"T_17d5d_row18_col18\" class=\"data row18 col18\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row18_col19\" class=\"data row18 col19\" >-0.30</td>\n",
       "      <td id=\"T_17d5d_row18_col20\" class=\"data row18 col20\" >-0.71</td>\n",
       "      <td id=\"T_17d5d_row18_col21\" class=\"data row18 col21\" >0.55</td>\n",
       "      <td id=\"T_17d5d_row18_col22\" class=\"data row18 col22\" >0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row19\" class=\"row_heading level0 row19\" >SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1</th>\n",
       "      <td id=\"T_17d5d_row19_col0\" class=\"data row19 col0\" >-0.20</td>\n",
       "      <td id=\"T_17d5d_row19_col1\" class=\"data row19 col1\" >-0.57</td>\n",
       "      <td id=\"T_17d5d_row19_col2\" class=\"data row19 col2\" >0.27</td>\n",
       "      <td id=\"T_17d5d_row19_col3\" class=\"data row19 col3\" >0.33</td>\n",
       "      <td id=\"T_17d5d_row19_col4\" class=\"data row19 col4\" >-0.02</td>\n",
       "      <td id=\"T_17d5d_row19_col5\" class=\"data row19 col5\" >0.13</td>\n",
       "      <td id=\"T_17d5d_row19_col6\" class=\"data row19 col6\" >0.85</td>\n",
       "      <td id=\"T_17d5d_row19_col7\" class=\"data row19 col7\" >-0.25</td>\n",
       "      <td id=\"T_17d5d_row19_col8\" class=\"data row19 col8\" >0.34</td>\n",
       "      <td id=\"T_17d5d_row19_col9\" class=\"data row19 col9\" >-0.26</td>\n",
       "      <td id=\"T_17d5d_row19_col10\" class=\"data row19 col10\" >-0.13</td>\n",
       "      <td id=\"T_17d5d_row19_col11\" class=\"data row19 col11\" >0.23</td>\n",
       "      <td id=\"T_17d5d_row19_col12\" class=\"data row19 col12\" >0.13</td>\n",
       "      <td id=\"T_17d5d_row19_col13\" class=\"data row19 col13\" >0.29</td>\n",
       "      <td id=\"T_17d5d_row19_col14\" class=\"data row19 col14\" >0.50</td>\n",
       "      <td id=\"T_17d5d_row19_col15\" class=\"data row19 col15\" >-0.74</td>\n",
       "      <td id=\"T_17d5d_row19_col16\" class=\"data row19 col16\" >0.28</td>\n",
       "      <td id=\"T_17d5d_row19_col17\" class=\"data row19 col17\" >0.41</td>\n",
       "      <td id=\"T_17d5d_row19_col18\" class=\"data row19 col18\" >-0.30</td>\n",
       "      <td id=\"T_17d5d_row19_col19\" class=\"data row19 col19\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row19_col20\" class=\"data row19 col20\" >0.58</td>\n",
       "      <td id=\"T_17d5d_row19_col21\" class=\"data row19 col21\" >-0.15</td>\n",
       "      <td id=\"T_17d5d_row19_col22\" class=\"data row19 col22\" >-0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row20\" class=\"row_heading level0 row20\" >SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1</th>\n",
       "      <td id=\"T_17d5d_row20_col0\" class=\"data row20 col0\" >-0.06</td>\n",
       "      <td id=\"T_17d5d_row20_col1\" class=\"data row20 col1\" >-0.37</td>\n",
       "      <td id=\"T_17d5d_row20_col2\" class=\"data row20 col2\" >0.39</td>\n",
       "      <td id=\"T_17d5d_row20_col3\" class=\"data row20 col3\" >-0.07</td>\n",
       "      <td id=\"T_17d5d_row20_col4\" class=\"data row20 col4\" >0.47</td>\n",
       "      <td id=\"T_17d5d_row20_col5\" class=\"data row20 col5\" >0.26</td>\n",
       "      <td id=\"T_17d5d_row20_col6\" class=\"data row20 col6\" >0.61</td>\n",
       "      <td id=\"T_17d5d_row20_col7\" class=\"data row20 col7\" >-0.66</td>\n",
       "      <td id=\"T_17d5d_row20_col8\" class=\"data row20 col8\" >0.16</td>\n",
       "      <td id=\"T_17d5d_row20_col9\" class=\"data row20 col9\" >0.00</td>\n",
       "      <td id=\"T_17d5d_row20_col10\" class=\"data row20 col10\" >0.35</td>\n",
       "      <td id=\"T_17d5d_row20_col11\" class=\"data row20 col11\" >0.63</td>\n",
       "      <td id=\"T_17d5d_row20_col12\" class=\"data row20 col12\" >0.45</td>\n",
       "      <td id=\"T_17d5d_row20_col13\" class=\"data row20 col13\" >0.33</td>\n",
       "      <td id=\"T_17d5d_row20_col14\" class=\"data row20 col14\" >0.64</td>\n",
       "      <td id=\"T_17d5d_row20_col15\" class=\"data row20 col15\" >-0.85</td>\n",
       "      <td id=\"T_17d5d_row20_col16\" class=\"data row20 col16\" >0.32</td>\n",
       "      <td id=\"T_17d5d_row20_col17\" class=\"data row20 col17\" >0.50</td>\n",
       "      <td id=\"T_17d5d_row20_col18\" class=\"data row20 col18\" >-0.71</td>\n",
       "      <td id=\"T_17d5d_row20_col19\" class=\"data row20 col19\" >0.58</td>\n",
       "      <td id=\"T_17d5d_row20_col20\" class=\"data row20 col20\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row20_col21\" class=\"data row20 col21\" >0.09</td>\n",
       "      <td id=\"T_17d5d_row20_col22\" class=\"data row20 col22\" >-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row21\" class=\"row_heading level0 row21\" >SP_Summaries_welch_rect_centroid</th>\n",
       "      <td id=\"T_17d5d_row21_col0\" class=\"data row21 col0\" >0.45</td>\n",
       "      <td id=\"T_17d5d_row21_col1\" class=\"data row21 col1\" >0.51</td>\n",
       "      <td id=\"T_17d5d_row21_col2\" class=\"data row21 col2\" >0.31</td>\n",
       "      <td id=\"T_17d5d_row21_col3\" class=\"data row21 col3\" >-0.81</td>\n",
       "      <td id=\"T_17d5d_row21_col4\" class=\"data row21 col4\" >-0.55</td>\n",
       "      <td id=\"T_17d5d_row21_col5\" class=\"data row21 col5\" >-0.64</td>\n",
       "      <td id=\"T_17d5d_row21_col6\" class=\"data row21 col6\" >-0.39</td>\n",
       "      <td id=\"T_17d5d_row21_col7\" class=\"data row21 col7\" >0.44</td>\n",
       "      <td id=\"T_17d5d_row21_col8\" class=\"data row21 col8\" >-0.84</td>\n",
       "      <td id=\"T_17d5d_row21_col9\" class=\"data row21 col9\" >-0.50</td>\n",
       "      <td id=\"T_17d5d_row21_col10\" class=\"data row21 col10\" >-0.38</td>\n",
       "      <td id=\"T_17d5d_row21_col11\" class=\"data row21 col11\" >-0.60</td>\n",
       "      <td id=\"T_17d5d_row21_col12\" class=\"data row21 col12\" >-0.70</td>\n",
       "      <td id=\"T_17d5d_row21_col13\" class=\"data row21 col13\" >0.65</td>\n",
       "      <td id=\"T_17d5d_row21_col14\" class=\"data row21 col14\" >-0.63</td>\n",
       "      <td id=\"T_17d5d_row21_col15\" class=\"data row21 col15\" >0.36</td>\n",
       "      <td id=\"T_17d5d_row21_col16\" class=\"data row21 col16\" >-0.72</td>\n",
       "      <td id=\"T_17d5d_row21_col17\" class=\"data row21 col17\" >0.82</td>\n",
       "      <td id=\"T_17d5d_row21_col18\" class=\"data row21 col18\" >0.55</td>\n",
       "      <td id=\"T_17d5d_row21_col19\" class=\"data row21 col19\" >-0.15</td>\n",
       "      <td id=\"T_17d5d_row21_col20\" class=\"data row21 col20\" >0.09</td>\n",
       "      <td id=\"T_17d5d_row21_col21\" class=\"data row21 col21\" >1.00</td>\n",
       "      <td id=\"T_17d5d_row21_col22\" class=\"data row21 col22\" >0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d5d_level0_row22\" class=\"row_heading level0 row22\" >FC_LocalSimple_mean3_stderr</th>\n",
       "      <td id=\"T_17d5d_row22_col0\" class=\"data row22 col0\" >0.54</td>\n",
       "      <td id=\"T_17d5d_row22_col1\" class=\"data row22 col1\" >0.62</td>\n",
       "      <td id=\"T_17d5d_row22_col2\" class=\"data row22 col2\" >0.34</td>\n",
       "      <td id=\"T_17d5d_row22_col3\" class=\"data row22 col3\" >-0.56</td>\n",
       "      <td id=\"T_17d5d_row22_col4\" class=\"data row22 col4\" >-0.78</td>\n",
       "      <td id=\"T_17d5d_row22_col5\" class=\"data row22 col5\" >-0.85</td>\n",
       "      <td id=\"T_17d5d_row22_col6\" class=\"data row22 col6\" >-0.34</td>\n",
       "      <td id=\"T_17d5d_row22_col7\" class=\"data row22 col7\" >0.67</td>\n",
       "      <td id=\"T_17d5d_row22_col8\" class=\"data row22 col8\" >-0.76</td>\n",
       "      <td id=\"T_17d5d_row22_col9\" class=\"data row22 col9\" >-0.70</td>\n",
       "      <td id=\"T_17d5d_row22_col10\" class=\"data row22 col10\" >-0.53</td>\n",
       "      <td id=\"T_17d5d_row22_col11\" class=\"data row22 col11\" >-0.90</td>\n",
       "      <td id=\"T_17d5d_row22_col12\" class=\"data row22 col12\" >-0.91</td>\n",
       "      <td id=\"T_17d5d_row22_col13\" class=\"data row22 col13\" >0.51</td>\n",
       "      <td id=\"T_17d5d_row22_col14\" class=\"data row22 col14\" >-0.79</td>\n",
       "      <td id=\"T_17d5d_row22_col15\" class=\"data row22 col15\" >0.58</td>\n",
       "      <td id=\"T_17d5d_row22_col16\" class=\"data row22 col16\" >-0.83</td>\n",
       "      <td id=\"T_17d5d_row22_col17\" class=\"data row22 col17\" >0.64</td>\n",
       "      <td id=\"T_17d5d_row22_col18\" class=\"data row22 col18\" >0.82</td>\n",
       "      <td id=\"T_17d5d_row22_col19\" class=\"data row22 col19\" >-0.14</td>\n",
       "      <td id=\"T_17d5d_row22_col20\" class=\"data row22 col20\" >-0.30</td>\n",
       "      <td id=\"T_17d5d_row22_col21\" class=\"data row22 col21\" >0.85</td>\n",
       "      <td id=\"T_17d5d_row22_col22\" class=\"data row22 col22\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9d92ab0520>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = data[data['model']=='Hopfield'].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d0/l9cqdxf90hbg0dj97q8bs7kc0000gn/T/ipykernel_76447/4093997848.py:2: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "  corr.style.background_gradient(cmap='coolwarm').set_precision(2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_496a5_row0_col0, #T_496a5_row1_col1, #T_496a5_row2_col2, #T_496a5_row3_col3, #T_496a5_row4_col4, #T_496a5_row5_col5, #T_496a5_row6_col6, #T_496a5_row7_col7, #T_496a5_row8_col8, #T_496a5_row9_col9, #T_496a5_row10_col10, #T_496a5_row11_col11, #T_496a5_row12_col12, #T_496a5_row13_col13, #T_496a5_row14_col14, #T_496a5_row15_col15, #T_496a5_row16_col16, #T_496a5_row17_col17, #T_496a5_row18_col18, #T_496a5_row19_col19, #T_496a5_row20_col20, #T_496a5_row21_col21, #T_496a5_row22_col22 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row0_col1, #T_496a5_row10_col1, #T_496a5_row17_col0 {\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row0_col2, #T_496a5_row6_col11, #T_496a5_row20_col16 {\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row0_col3, #T_496a5_row4_col17, #T_496a5_row4_col21, #T_496a5_row8_col18, #T_496a5_row9_col13, #T_496a5_row9_col17, #T_496a5_row9_col21, #T_496a5_row10_col18, #T_496a5_row21_col11 {\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row0_col4, #T_496a5_row13_col9 {\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row0_col5 {\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row0_col6, #T_496a5_row3_col1 {\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row0_col7, #T_496a5_row10_col16 {\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row0_col8 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row0_col9, #T_496a5_row1_col20 {\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row0_col10, #T_496a5_row8_col15, #T_496a5_row13_col4, #T_496a5_row17_col4, #T_496a5_row22_col20 {\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row0_col11, #T_496a5_row0_col12, #T_496a5_row5_col17, #T_496a5_row11_col17, #T_496a5_row21_col4 {\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row0_col13, #T_496a5_row1_col18, #T_496a5_row4_col16, #T_496a5_row6_col5 {\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row0_col14, #T_496a5_row13_col14 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row0_col15, #T_496a5_row3_col14, #T_496a5_row17_col18 {\n",
       "  background-color: #ec8165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row0_col16 {\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row0_col17, #T_496a5_row2_col17, #T_496a5_row6_col19, #T_496a5_row19_col6 {\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row0_col18, #T_496a5_row4_col3 {\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row0_col19 {\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row0_col20, #T_496a5_row15_col6 {\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row0_col21, #T_496a5_row5_col4 {\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row0_col22, #T_496a5_row1_col22, #T_496a5_row4_col8, #T_496a5_row20_col11 {\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row1_col0, #T_496a5_row6_col9, #T_496a5_row7_col0, #T_496a5_row16_col10 {\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row1_col2, #T_496a5_row2_col1 {\n",
       "  background-color: #b8122a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row1_col3, #T_496a5_row19_col15 {\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row1_col4 {\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row1_col5, #T_496a5_row1_col19, #T_496a5_row4_col7, #T_496a5_row7_col10, #T_496a5_row12_col0, #T_496a5_row22_col4 {\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row1_col6, #T_496a5_row16_col21, #T_496a5_row21_col14 {\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row1_col7, #T_496a5_row16_col3, #T_496a5_row16_col20, #T_496a5_row19_col18 {\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row1_col8 {\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row1_col9, #T_496a5_row2_col9, #T_496a5_row7_col5, #T_496a5_row15_col8, #T_496a5_row16_col15, #T_496a5_row17_col10, #T_496a5_row18_col8, #T_496a5_row21_col10 {\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row1_col10, #T_496a5_row13_col20, #T_496a5_row20_col21 {\n",
       "  background-color: #ebd3c6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row1_col11, #T_496a5_row8_col2, #T_496a5_row14_col2 {\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row1_col12, #T_496a5_row1_col14, #T_496a5_row7_col3, #T_496a5_row8_col1, #T_496a5_row10_col13, #T_496a5_row10_col17 {\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row1_col13 {\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row1_col15 {\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row1_col16, #T_496a5_row11_col7, #T_496a5_row14_col7, #T_496a5_row14_col15 {\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row1_col17, #T_496a5_row6_col8, #T_496a5_row15_col13, #T_496a5_row16_col8 {\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row1_col21, #T_496a5_row12_col10, #T_496a5_row13_col18, #T_496a5_row15_col17, #T_496a5_row22_col2 {\n",
       "  background-color: #f59c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row2_col0 {\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row2_col3, #T_496a5_row11_col19 {\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row2_col4 {\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row2_col5, #T_496a5_row14_col21, #T_496a5_row21_col16 {\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row2_col6, #T_496a5_row16_col17, #T_496a5_row16_col18, #T_496a5_row21_col5, #T_496a5_row22_col3 {\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row2_col7, #T_496a5_row10_col9, #T_496a5_row18_col19 {\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row2_col8, #T_496a5_row3_col7, #T_496a5_row6_col20, #T_496a5_row8_col20, #T_496a5_row18_col3 {\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row2_col10, #T_496a5_row17_col2, #T_496a5_row19_col16 {\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row2_col11, #T_496a5_row2_col12, #T_496a5_row2_col14 {\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row2_col13, #T_496a5_row8_col19 {\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row2_col15, #T_496a5_row8_col5 {\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row2_col16, #T_496a5_row10_col19, #T_496a5_row16_col2 {\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row2_col18, #T_496a5_row5_col19, #T_496a5_row18_col0 {\n",
       "  background-color: #f7ba9f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row2_col19, #T_496a5_row5_col1, #T_496a5_row5_col2, #T_496a5_row5_col15, #T_496a5_row8_col13, #T_496a5_row8_col17, #T_496a5_row8_col21, #T_496a5_row11_col18, #T_496a5_row12_col7, #T_496a5_row13_col3, #T_496a5_row13_col8, #T_496a5_row14_col0, #T_496a5_row14_col22, #T_496a5_row15_col5, #T_496a5_row15_col9, #T_496a5_row15_col20, #T_496a5_row17_col3, #T_496a5_row18_col4, #T_496a5_row18_col10, #T_496a5_row18_col11, #T_496a5_row18_col12, #T_496a5_row21_col6, #T_496a5_row22_col14, #T_496a5_row22_col16 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row2_col20 {\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row2_col21, #T_496a5_row3_col4, #T_496a5_row9_col16, #T_496a5_row20_col4, #T_496a5_row20_col12 {\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row2_col22, #T_496a5_row12_col16 {\n",
       "  background-color: #f39577;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row3_col0, #T_496a5_row12_col17 {\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row3_col2, #T_496a5_row7_col6 {\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row3_col5, #T_496a5_row10_col3, #T_496a5_row12_col20 {\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row3_col6, #T_496a5_row5_col6, #T_496a5_row19_col5 {\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row3_col8, #T_496a5_row8_col3 {\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row3_col9, #T_496a5_row8_col16 {\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row3_col10, #T_496a5_row3_col16, #T_496a5_row12_col6, #T_496a5_row19_col13 {\n",
       "  background-color: #f1ccb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row3_col11, #T_496a5_row5_col20, #T_496a5_row7_col19, #T_496a5_row10_col2 {\n",
       "  background-color: #f7b497;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row3_col12 {\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row3_col13, #T_496a5_row3_col17, #T_496a5_row7_col12, #T_496a5_row12_col15, #T_496a5_row15_col12, #T_496a5_row18_col20 {\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row3_col15, #T_496a5_row6_col15 {\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row3_col18, #T_496a5_row6_col18 {\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row3_col19 {\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row3_col20, #T_496a5_row5_col0, #T_496a5_row8_col22, #T_496a5_row18_col5, #T_496a5_row19_col1 {\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row3_col21, #T_496a5_row18_col14, #T_496a5_row22_col11 {\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row3_col22, #T_496a5_row10_col7, #T_496a5_row17_col5, #T_496a5_row19_col0, #T_496a5_row21_col9 {\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row4_col0, #T_496a5_row7_col20, #T_496a5_row9_col0, #T_496a5_row9_col2, #T_496a5_row15_col4, #T_496a5_row17_col14, #T_496a5_row22_col6 {\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row4_col1 {\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row4_col2 {\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row4_col5, #T_496a5_row18_col13, #T_496a5_row21_col7 {\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row4_col6, #T_496a5_row9_col6 {\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row4_col9, #T_496a5_row11_col10, #T_496a5_row15_col0, #T_496a5_row21_col15 {\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row4_col10, #T_496a5_row9_col12, #T_496a5_row12_col9, #T_496a5_row14_col4 {\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row4_col11, #T_496a5_row10_col4, #T_496a5_row15_col18, #T_496a5_row18_col15, #T_496a5_row18_col22, #T_496a5_row22_col18 {\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row4_col12, #T_496a5_row12_col4 {\n",
       "  background-color: #cb3e38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row4_col13, #T_496a5_row6_col2, #T_496a5_row6_col22, #T_496a5_row15_col10 {\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row4_col14, #T_496a5_row11_col4, #T_496a5_row15_col22, #T_496a5_row22_col15 {\n",
       "  background-color: #c83836;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row4_col15, #T_496a5_row5_col7, #T_496a5_row5_col21, #T_496a5_row13_col12 {\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row4_col18, #T_496a5_row11_col0 {\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row4_col19, #T_496a5_row10_col0 {\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row4_col20, #T_496a5_row6_col14, #T_496a5_row8_col6, #T_496a5_row9_col20 {\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row4_col22, #T_496a5_row9_col22, #T_496a5_row14_col17 {\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row5_col3, #T_496a5_row14_col6 {\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row5_col8, #T_496a5_row10_col14 {\n",
       "  background-color: #ec7f63;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row5_col9, #T_496a5_row7_col18, #T_496a5_row9_col5, #T_496a5_row18_col7 {\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row5_col10 {\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row5_col11, #T_496a5_row5_col12, #T_496a5_row8_col12, #T_496a5_row11_col5, #T_496a5_row11_col9, #T_496a5_row12_col5 {\n",
       "  background-color: #d55042;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row5_col13, #T_496a5_row16_col7 {\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row5_col14, #T_496a5_row14_col5, #T_496a5_row17_col22 {\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row5_col16 {\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row5_col18, #T_496a5_row12_col21, #T_496a5_row15_col16, #T_496a5_row18_col16 {\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row5_col22, #T_496a5_row9_col7, #T_496a5_row17_col6, #T_496a5_row22_col5 {\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row6_col0, #T_496a5_row12_col19 {\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row6_col1, #T_496a5_row17_col16, #T_496a5_row21_col12 {\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row6_col3, #T_496a5_row21_col0, #T_496a5_row21_col2 {\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row6_col4, #T_496a5_row13_col19 {\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row6_col7, #T_496a5_row17_col19, #T_496a5_row19_col22 {\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row6_col10, #T_496a5_row13_col1, #T_496a5_row19_col14 {\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row6_col12, #T_496a5_row16_col19, #T_496a5_row18_col2 {\n",
       "  background-color: #f5c2aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row6_col13 {\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row6_col16, #T_496a5_row14_col8, #T_496a5_row16_col6 {\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row6_col17 {\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row6_col21, #T_496a5_row7_col9, #T_496a5_row7_col14, #T_496a5_row18_col9, #T_496a5_row22_col10 {\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row7_col1, #T_496a5_row20_col17 {\n",
       "  background-color: #f1cdba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row7_col2 {\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row7_col4, #T_496a5_row15_col14 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row7_col8, #T_496a5_row8_col7 {\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row7_col11, #T_496a5_row16_col22, #T_496a5_row22_col8 {\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row7_col13, #T_496a5_row13_col7 {\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row7_col15, #T_496a5_row15_col7, #T_496a5_row22_col17 {\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row7_col16, #T_496a5_row11_col2, #T_496a5_row13_col11 {\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row7_col17, #T_496a5_row10_col12 {\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row7_col21, #T_496a5_row20_col5 {\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row7_col22 {\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row8_col0 {\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row8_col4, #T_496a5_row14_col3, #T_496a5_row15_col2, #T_496a5_row16_col14, #T_496a5_row18_col17, #T_496a5_row21_col18 {\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row8_col9, #T_496a5_row9_col8 {\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row8_col10 {\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row8_col11, #T_496a5_row15_col1 {\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row8_col14, #T_496a5_row21_col22, #T_496a5_row22_col21 {\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row9_col1, #T_496a5_row12_col13, #T_496a5_row14_col13 {\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row9_col3, #T_496a5_row11_col3 {\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row9_col4, #T_496a5_row14_col10, #T_496a5_row15_col21, #T_496a5_row22_col0 {\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row9_col10 {\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row9_col11 {\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row9_col14, #T_496a5_row14_col9 {\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row9_col15, #T_496a5_row11_col15, #T_496a5_row12_col18, #T_496a5_row17_col8 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row9_col18, #T_496a5_row22_col9 {\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row9_col19 {\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row10_col5 {\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row10_col6 {\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row10_col8, #T_496a5_row20_col14 {\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row10_col11, #T_496a5_row11_col8, #T_496a5_row11_col16 {\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row10_col15, #T_496a5_row15_col3, #T_496a5_row21_col19 {\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row10_col20 {\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row10_col21 {\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row10_col22, #T_496a5_row11_col1 {\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row11_col6, #T_496a5_row14_col20 {\n",
       "  background-color: #f2c9b4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row11_col12, #T_496a5_row12_col11, #T_496a5_row14_col11 {\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row11_col13 {\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row11_col14 {\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row11_col20, #T_496a5_row13_col22 {\n",
       "  background-color: #f39475;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row11_col21 {\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row11_col22, #T_496a5_row21_col3 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row12_col1, #T_496a5_row16_col0 {\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row12_col2, #T_496a5_row18_col6 {\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row12_col3, #T_496a5_row22_col13 {\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row12_col8 {\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row12_col14, #T_496a5_row14_col12 {\n",
       "  background-color: #b50927;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row12_col22, #T_496a5_row15_col11, #T_496a5_row21_col8, #T_496a5_row22_col12 {\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row13_col0, #T_496a5_row17_col1 {\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row13_col2 {\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row13_col5, #T_496a5_row20_col1, #T_496a5_row20_col22 {\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row13_col6 {\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row13_col10 {\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row13_col15, #T_496a5_row18_col1 {\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row13_col16 {\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row13_col17, #T_496a5_row17_col13 {\n",
       "  background-color: #da5a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row13_col21, #T_496a5_row16_col11, #T_496a5_row21_col13 {\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row14_col1 {\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row14_col16 {\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row14_col18, #T_496a5_row19_col2, #T_496a5_row19_col10 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row14_col19 {\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row15_col19, #T_496a5_row20_col6 {\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row16_col1 {\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row16_col4 {\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row16_col5 {\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row16_col9 {\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row16_col12 {\n",
       "  background-color: #f18f71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row16_col13, #T_496a5_row19_col11 {\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row17_col7, #T_496a5_row18_col21 {\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row17_col9 {\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row17_col11, #T_496a5_row20_col3 {\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row17_col12 {\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row17_col15 {\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row17_col20, #T_496a5_row19_col8 {\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row17_col21, #T_496a5_row21_col17 {\n",
       "  background-color: #ba162b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row19_col3 {\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row19_col4 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row19_col7 {\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row19_col9 {\n",
       "  background-color: #ead5c9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row19_col12 {\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row19_col17 {\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row19_col20, #T_496a5_row20_col0 {\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row19_col21 {\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row20_col2 {\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row20_col7 {\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row20_col8 {\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row20_col9 {\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row20_col10 {\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row20_col13 {\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row20_col15 {\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row20_col18 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row20_col19, #T_496a5_row22_col19 {\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row21_col1 {\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row21_col20 {\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_496a5_row22_col1 {\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_496a5_row22_col7 {\n",
       "  background-color: #e16751;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_496a5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_496a5_level0_col0\" class=\"col_heading level0 col0\" >error</th>\n",
       "      <th id=\"T_496a5_level0_col1\" class=\"col_heading level0 col1\" >DN_HistogramMode_5</th>\n",
       "      <th id=\"T_496a5_level0_col2\" class=\"col_heading level0 col2\" >DN_HistogramMode_10</th>\n",
       "      <th id=\"T_496a5_level0_col3\" class=\"col_heading level0 col3\" >CO_f1ecac</th>\n",
       "      <th id=\"T_496a5_level0_col4\" class=\"col_heading level0 col4\" >CO_FirstMin_ac</th>\n",
       "      <th id=\"T_496a5_level0_col5\" class=\"col_heading level0 col5\" >CO_HistogramAMI_even_2_5</th>\n",
       "      <th id=\"T_496a5_level0_col6\" class=\"col_heading level0 col6\" >CO_trev_1_num</th>\n",
       "      <th id=\"T_496a5_level0_col7\" class=\"col_heading level0 col7\" >MD_hrv_classic_pnn40</th>\n",
       "      <th id=\"T_496a5_level0_col8\" class=\"col_heading level0 col8\" >SB_BinaryStats_mean_longstretch1</th>\n",
       "      <th id=\"T_496a5_level0_col9\" class=\"col_heading level0 col9\" >SB_TransitionMatrix_3ac_sumdiagcov</th>\n",
       "      <th id=\"T_496a5_level0_col10\" class=\"col_heading level0 col10\" >PD_PeriodicityWang_th0_01</th>\n",
       "      <th id=\"T_496a5_level0_col11\" class=\"col_heading level0 col11\" >CO_Embed2_Dist_tau_d_expfit_meandiff</th>\n",
       "      <th id=\"T_496a5_level0_col12\" class=\"col_heading level0 col12\" >IN_AutoMutualInfoStats_40_gaussian_fmmi</th>\n",
       "      <th id=\"T_496a5_level0_col13\" class=\"col_heading level0 col13\" >FC_LocalSimple_mean1_tauresrat</th>\n",
       "      <th id=\"T_496a5_level0_col14\" class=\"col_heading level0 col14\" >DN_OutlierInclude_p_001_mdrmd</th>\n",
       "      <th id=\"T_496a5_level0_col15\" class=\"col_heading level0 col15\" >DN_OutlierInclude_n_001_mdrmd</th>\n",
       "      <th id=\"T_496a5_level0_col16\" class=\"col_heading level0 col16\" >SP_Summaries_welch_rect_area_5_1</th>\n",
       "      <th id=\"T_496a5_level0_col17\" class=\"col_heading level0 col17\" >SB_BinaryStats_diff_longstretch0</th>\n",
       "      <th id=\"T_496a5_level0_col18\" class=\"col_heading level0 col18\" >SB_MotifThree_quantile_hh</th>\n",
       "      <th id=\"T_496a5_level0_col19\" class=\"col_heading level0 col19\" >SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1</th>\n",
       "      <th id=\"T_496a5_level0_col20\" class=\"col_heading level0 col20\" >SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1</th>\n",
       "      <th id=\"T_496a5_level0_col21\" class=\"col_heading level0 col21\" >SP_Summaries_welch_rect_centroid</th>\n",
       "      <th id=\"T_496a5_level0_col22\" class=\"col_heading level0 col22\" >FC_LocalSimple_mean3_stderr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row0\" class=\"row_heading level0 row0\" >error</th>\n",
       "      <td id=\"T_496a5_row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "      <td id=\"T_496a5_row0_col1\" class=\"data row0 col1\" >0.28</td>\n",
       "      <td id=\"T_496a5_row0_col2\" class=\"data row0 col2\" >0.35</td>\n",
       "      <td id=\"T_496a5_row0_col3\" class=\"data row0 col3\" >-0.54</td>\n",
       "      <td id=\"T_496a5_row0_col4\" class=\"data row0 col4\" >-0.53</td>\n",
       "      <td id=\"T_496a5_row0_col5\" class=\"data row0 col5\" >-0.56</td>\n",
       "      <td id=\"T_496a5_row0_col6\" class=\"data row0 col6\" >-0.06</td>\n",
       "      <td id=\"T_496a5_row0_col7\" class=\"data row0 col7\" >0.28</td>\n",
       "      <td id=\"T_496a5_row0_col8\" class=\"data row0 col8\" >-0.65</td>\n",
       "      <td id=\"T_496a5_row0_col9\" class=\"data row0 col9\" >-0.53</td>\n",
       "      <td id=\"T_496a5_row0_col10\" class=\"data row0 col10\" >-0.35</td>\n",
       "      <td id=\"T_496a5_row0_col11\" class=\"data row0 col11\" >-0.63</td>\n",
       "      <td id=\"T_496a5_row0_col12\" class=\"data row0 col12\" >-0.62</td>\n",
       "      <td id=\"T_496a5_row0_col13\" class=\"data row0 col13\" >0.46</td>\n",
       "      <td id=\"T_496a5_row0_col14\" class=\"data row0 col14\" >-0.70</td>\n",
       "      <td id=\"T_496a5_row0_col15\" class=\"data row0 col15\" >0.62</td>\n",
       "      <td id=\"T_496a5_row0_col16\" class=\"data row0 col16\" >-0.30</td>\n",
       "      <td id=\"T_496a5_row0_col17\" class=\"data row0 col17\" >0.34</td>\n",
       "      <td id=\"T_496a5_row0_col18\" class=\"data row0 col18\" >0.42</td>\n",
       "      <td id=\"T_496a5_row0_col19\" class=\"data row0 col19\" >-0.37</td>\n",
       "      <td id=\"T_496a5_row0_col20\" class=\"data row0 col20\" >-0.18</td>\n",
       "      <td id=\"T_496a5_row0_col21\" class=\"data row0 col21\" >0.49</td>\n",
       "      <td id=\"T_496a5_row0_col22\" class=\"data row0 col22\" >0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row1\" class=\"row_heading level0 row1\" >DN_HistogramMode_5</th>\n",
       "      <td id=\"T_496a5_row1_col0\" class=\"data row1 col0\" >0.28</td>\n",
       "      <td id=\"T_496a5_row1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "      <td id=\"T_496a5_row1_col2\" class=\"data row1 col2\" >0.98</td>\n",
       "      <td id=\"T_496a5_row1_col3\" class=\"data row1 col3\" >-0.11</td>\n",
       "      <td id=\"T_496a5_row1_col4\" class=\"data row1 col4\" >-0.04</td>\n",
       "      <td id=\"T_496a5_row1_col5\" class=\"data row1 col5\" >-0.85</td>\n",
       "      <td id=\"T_496a5_row1_col6\" class=\"data row1 col6\" >-0.62</td>\n",
       "      <td id=\"T_496a5_row1_col7\" class=\"data row1 col7\" >0.24</td>\n",
       "      <td id=\"T_496a5_row1_col8\" class=\"data row1 col8\" >-0.34</td>\n",
       "      <td id=\"T_496a5_row1_col9\" class=\"data row1 col9\" >-0.64</td>\n",
       "      <td id=\"T_496a5_row1_col10\" class=\"data row1 col10\" >0.29</td>\n",
       "      <td id=\"T_496a5_row1_col11\" class=\"data row1 col11\" >-0.45</td>\n",
       "      <td id=\"T_496a5_row1_col12\" class=\"data row1 col12\" >-0.42</td>\n",
       "      <td id=\"T_496a5_row1_col13\" class=\"data row1 col13\" >-0.00</td>\n",
       "      <td id=\"T_496a5_row1_col14\" class=\"data row1 col14\" >-0.41</td>\n",
       "      <td id=\"T_496a5_row1_col15\" class=\"data row1 col15\" >0.67</td>\n",
       "      <td id=\"T_496a5_row1_col16\" class=\"data row1 col16\" >-0.75</td>\n",
       "      <td id=\"T_496a5_row1_col17\" class=\"data row1 col17\" >0.41</td>\n",
       "      <td id=\"T_496a5_row1_col18\" class=\"data row1 col18\" >0.43</td>\n",
       "      <td id=\"T_496a5_row1_col19\" class=\"data row1 col19\" >-0.70</td>\n",
       "      <td id=\"T_496a5_row1_col20\" class=\"data row1 col20\" >-0.30</td>\n",
       "      <td id=\"T_496a5_row1_col21\" class=\"data row1 col21\" >0.52</td>\n",
       "      <td id=\"T_496a5_row1_col22\" class=\"data row1 col22\" >0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row2\" class=\"row_heading level0 row2\" >DN_HistogramMode_10</th>\n",
       "      <td id=\"T_496a5_row2_col0\" class=\"data row2 col0\" >0.35</td>\n",
       "      <td id=\"T_496a5_row2_col1\" class=\"data row2 col1\" >0.98</td>\n",
       "      <td id=\"T_496a5_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_496a5_row2_col3\" class=\"data row2 col3\" >-0.13</td>\n",
       "      <td id=\"T_496a5_row2_col4\" class=\"data row2 col4\" >0.06</td>\n",
       "      <td id=\"T_496a5_row2_col5\" class=\"data row2 col5\" >-0.83</td>\n",
       "      <td id=\"T_496a5_row2_col6\" class=\"data row2 col6\" >-0.50</td>\n",
       "      <td id=\"T_496a5_row2_col7\" class=\"data row2 col7\" >0.17</td>\n",
       "      <td id=\"T_496a5_row2_col8\" class=\"data row2 col8\" >-0.35</td>\n",
       "      <td id=\"T_496a5_row2_col9\" class=\"data row2 col9\" >-0.65</td>\n",
       "      <td id=\"T_496a5_row2_col10\" class=\"data row2 col10\" >0.41</td>\n",
       "      <td id=\"T_496a5_row2_col11\" class=\"data row2 col11\" >-0.37</td>\n",
       "      <td id=\"T_496a5_row2_col12\" class=\"data row2 col12\" >-0.36</td>\n",
       "      <td id=\"T_496a5_row2_col13\" class=\"data row2 col13\" >0.03</td>\n",
       "      <td id=\"T_496a5_row2_col14\" class=\"data row2 col14\" >-0.35</td>\n",
       "      <td id=\"T_496a5_row2_col15\" class=\"data row2 col15\" >0.64</td>\n",
       "      <td id=\"T_496a5_row2_col16\" class=\"data row2 col16\" >-0.62</td>\n",
       "      <td id=\"T_496a5_row2_col17\" class=\"data row2 col17\" >0.34</td>\n",
       "      <td id=\"T_496a5_row2_col18\" class=\"data row2 col18\" >0.33</td>\n",
       "      <td id=\"T_496a5_row2_col19\" class=\"data row2 col19\" >-0.78</td>\n",
       "      <td id=\"T_496a5_row2_col20\" class=\"data row2 col20\" >-0.22</td>\n",
       "      <td id=\"T_496a5_row2_col21\" class=\"data row2 col21\" >0.45</td>\n",
       "      <td id=\"T_496a5_row2_col22\" class=\"data row2 col22\" >0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row3\" class=\"row_heading level0 row3\" >CO_f1ecac</th>\n",
       "      <td id=\"T_496a5_row3_col0\" class=\"data row3 col0\" >-0.54</td>\n",
       "      <td id=\"T_496a5_row3_col1\" class=\"data row3 col1\" >-0.11</td>\n",
       "      <td id=\"T_496a5_row3_col2\" class=\"data row3 col2\" >-0.13</td>\n",
       "      <td id=\"T_496a5_row3_col3\" class=\"data row3 col3\" >1.00</td>\n",
       "      <td id=\"T_496a5_row3_col4\" class=\"data row3 col4\" >0.45</td>\n",
       "      <td id=\"T_496a5_row3_col5\" class=\"data row3 col5\" >0.32</td>\n",
       "      <td id=\"T_496a5_row3_col6\" class=\"data row3 col6\" >0.44</td>\n",
       "      <td id=\"T_496a5_row3_col7\" class=\"data row3 col7\" >-0.35</td>\n",
       "      <td id=\"T_496a5_row3_col8\" class=\"data row3 col8\" >0.91</td>\n",
       "      <td id=\"T_496a5_row3_col9\" class=\"data row3 col9\" >0.37</td>\n",
       "      <td id=\"T_496a5_row3_col10\" class=\"data row3 col10\" >0.35</td>\n",
       "      <td id=\"T_496a5_row3_col11\" class=\"data row3 col11\" >0.37</td>\n",
       "      <td id=\"T_496a5_row3_col12\" class=\"data row3 col12\" >0.55</td>\n",
       "      <td id=\"T_496a5_row3_col13\" class=\"data row3 col13\" >-0.87</td>\n",
       "      <td id=\"T_496a5_row3_col14\" class=\"data row3 col14\" >0.62</td>\n",
       "      <td id=\"T_496a5_row3_col15\" class=\"data row3 col15\" >-0.28</td>\n",
       "      <td id=\"T_496a5_row3_col16\" class=\"data row3 col16\" >0.26</td>\n",
       "      <td id=\"T_496a5_row3_col17\" class=\"data row3 col17\" >-0.86</td>\n",
       "      <td id=\"T_496a5_row3_col18\" class=\"data row3 col18\" >-0.33</td>\n",
       "      <td id=\"T_496a5_row3_col19\" class=\"data row3 col19\" >0.08</td>\n",
       "      <td id=\"T_496a5_row3_col20\" class=\"data row3 col20\" >-0.50</td>\n",
       "      <td id=\"T_496a5_row3_col21\" class=\"data row3 col21\" >-0.85</td>\n",
       "      <td id=\"T_496a5_row3_col22\" class=\"data row3 col22\" >-0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row4\" class=\"row_heading level0 row4\" >CO_FirstMin_ac</th>\n",
       "      <td id=\"T_496a5_row4_col0\" class=\"data row4 col0\" >-0.53</td>\n",
       "      <td id=\"T_496a5_row4_col1\" class=\"data row4 col1\" >-0.04</td>\n",
       "      <td id=\"T_496a5_row4_col2\" class=\"data row4 col2\" >0.06</td>\n",
       "      <td id=\"T_496a5_row4_col3\" class=\"data row4 col3\" >0.45</td>\n",
       "      <td id=\"T_496a5_row4_col4\" class=\"data row4 col4\" >1.00</td>\n",
       "      <td id=\"T_496a5_row4_col5\" class=\"data row4 col5\" >0.49</td>\n",
       "      <td id=\"T_496a5_row4_col6\" class=\"data row4 col6\" >0.18</td>\n",
       "      <td id=\"T_496a5_row4_col7\" class=\"data row4 col7\" >-0.82</td>\n",
       "      <td id=\"T_496a5_row4_col8\" class=\"data row4 col8\" >0.62</td>\n",
       "      <td id=\"T_496a5_row4_col9\" class=\"data row4 col9\" >0.57</td>\n",
       "      <td id=\"T_496a5_row4_col10\" class=\"data row4 col10\" >0.90</td>\n",
       "      <td id=\"T_496a5_row4_col11\" class=\"data row4 col11\" >0.90</td>\n",
       "      <td id=\"T_496a5_row4_col12\" class=\"data row4 col12\" >0.88</td>\n",
       "      <td id=\"T_496a5_row4_col13\" class=\"data row4 col13\" >-0.57</td>\n",
       "      <td id=\"T_496a5_row4_col14\" class=\"data row4 col14\" >0.89</td>\n",
       "      <td id=\"T_496a5_row4_col15\" class=\"data row4 col15\" >-0.69</td>\n",
       "      <td id=\"T_496a5_row4_col16\" class=\"data row4 col16\" >0.47</td>\n",
       "      <td id=\"T_496a5_row4_col17\" class=\"data row4 col17\" >-0.57</td>\n",
       "      <td id=\"T_496a5_row4_col18\" class=\"data row4 col18\" >-0.88</td>\n",
       "      <td id=\"T_496a5_row4_col19\" class=\"data row4 col19\" >-0.42</td>\n",
       "      <td id=\"T_496a5_row4_col20\" class=\"data row4 col20\" >0.45</td>\n",
       "      <td id=\"T_496a5_row4_col21\" class=\"data row4 col21\" >-0.56</td>\n",
       "      <td id=\"T_496a5_row4_col22\" class=\"data row4 col22\" >-0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row5\" class=\"row_heading level0 row5\" >CO_HistogramAMI_even_2_5</th>\n",
       "      <td id=\"T_496a5_row5_col0\" class=\"data row5 col0\" >-0.56</td>\n",
       "      <td id=\"T_496a5_row5_col1\" class=\"data row5 col1\" >-0.85</td>\n",
       "      <td id=\"T_496a5_row5_col2\" class=\"data row5 col2\" >-0.83</td>\n",
       "      <td id=\"T_496a5_row5_col3\" class=\"data row5 col3\" >0.32</td>\n",
       "      <td id=\"T_496a5_row5_col4\" class=\"data row5 col4\" >0.49</td>\n",
       "      <td id=\"T_496a5_row5_col5\" class=\"data row5 col5\" >1.00</td>\n",
       "      <td id=\"T_496a5_row5_col6\" class=\"data row5 col6\" >0.44</td>\n",
       "      <td id=\"T_496a5_row5_col7\" class=\"data row5 col7\" >-0.66</td>\n",
       "      <td id=\"T_496a5_row5_col8\" class=\"data row5 col8\" >0.64</td>\n",
       "      <td id=\"T_496a5_row5_col9\" class=\"data row5 col9\" >0.93</td>\n",
       "      <td id=\"T_496a5_row5_col10\" class=\"data row5 col10\" >0.09</td>\n",
       "      <td id=\"T_496a5_row5_col11\" class=\"data row5 col11\" >0.81</td>\n",
       "      <td id=\"T_496a5_row5_col12\" class=\"data row5 col12\" >0.81</td>\n",
       "      <td id=\"T_496a5_row5_col13\" class=\"data row5 col13\" >-0.37</td>\n",
       "      <td id=\"T_496a5_row5_col14\" class=\"data row5 col14\" >0.79</td>\n",
       "      <td id=\"T_496a5_row5_col15\" class=\"data row5 col15\" >-0.95</td>\n",
       "      <td id=\"T_496a5_row5_col16\" class=\"data row5 col16\" >0.71</td>\n",
       "      <td id=\"T_496a5_row5_col17\" class=\"data row5 col17\" >-0.58</td>\n",
       "      <td id=\"T_496a5_row5_col18\" class=\"data row5 col18\" >-0.78</td>\n",
       "      <td id=\"T_496a5_row5_col19\" class=\"data row5 col19\" >0.39</td>\n",
       "      <td id=\"T_496a5_row5_col20\" class=\"data row5 col20\" >0.48</td>\n",
       "      <td id=\"T_496a5_row5_col21\" class=\"data row5 col21\" >-0.64</td>\n",
       "      <td id=\"T_496a5_row5_col22\" class=\"data row5 col22\" >-0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row6\" class=\"row_heading level0 row6\" >CO_trev_1_num</th>\n",
       "      <td id=\"T_496a5_row6_col0\" class=\"data row6 col0\" >-0.06</td>\n",
       "      <td id=\"T_496a5_row6_col1\" class=\"data row6 col1\" >-0.62</td>\n",
       "      <td id=\"T_496a5_row6_col2\" class=\"data row6 col2\" >-0.50</td>\n",
       "      <td id=\"T_496a5_row6_col3\" class=\"data row6 col3\" >0.44</td>\n",
       "      <td id=\"T_496a5_row6_col4\" class=\"data row6 col4\" >0.18</td>\n",
       "      <td id=\"T_496a5_row6_col5\" class=\"data row6 col5\" >0.44</td>\n",
       "      <td id=\"T_496a5_row6_col6\" class=\"data row6 col6\" >1.00</td>\n",
       "      <td id=\"T_496a5_row6_col7\" class=\"data row6 col7\" >-0.10</td>\n",
       "      <td id=\"T_496a5_row6_col8\" class=\"data row6 col8\" >0.41</td>\n",
       "      <td id=\"T_496a5_row6_col9\" class=\"data row6 col9\" >0.19</td>\n",
       "      <td id=\"T_496a5_row6_col10\" class=\"data row6 col10\" >0.12</td>\n",
       "      <td id=\"T_496a5_row6_col11\" class=\"data row6 col11\" >0.30</td>\n",
       "      <td id=\"T_496a5_row6_col12\" class=\"data row6 col12\" >0.28</td>\n",
       "      <td id=\"T_496a5_row6_col13\" class=\"data row6 col13\" >-0.11</td>\n",
       "      <td id=\"T_496a5_row6_col14\" class=\"data row6 col14\" >0.35</td>\n",
       "      <td id=\"T_496a5_row6_col15\" class=\"data row6 col15\" >-0.28</td>\n",
       "      <td id=\"T_496a5_row6_col16\" class=\"data row6 col16\" >0.86</td>\n",
       "      <td id=\"T_496a5_row6_col17\" class=\"data row6 col17\" >-0.70</td>\n",
       "      <td id=\"T_496a5_row6_col18\" class=\"data row6 col18\" >-0.32</td>\n",
       "      <td id=\"T_496a5_row6_col19\" class=\"data row6 col19\" >0.39</td>\n",
       "      <td id=\"T_496a5_row6_col20\" class=\"data row6 col20\" >-0.16</td>\n",
       "      <td id=\"T_496a5_row6_col21\" class=\"data row6 col21\" >-0.78</td>\n",
       "      <td id=\"T_496a5_row6_col22\" class=\"data row6 col22\" >-0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row7\" class=\"row_heading level0 row7\" >MD_hrv_classic_pnn40</th>\n",
       "      <td id=\"T_496a5_row7_col0\" class=\"data row7 col0\" >0.28</td>\n",
       "      <td id=\"T_496a5_row7_col1\" class=\"data row7 col1\" >0.24</td>\n",
       "      <td id=\"T_496a5_row7_col2\" class=\"data row7 col2\" >0.17</td>\n",
       "      <td id=\"T_496a5_row7_col3\" class=\"data row7 col3\" >-0.35</td>\n",
       "      <td id=\"T_496a5_row7_col4\" class=\"data row7 col4\" >-0.82</td>\n",
       "      <td id=\"T_496a5_row7_col5\" class=\"data row7 col5\" >-0.66</td>\n",
       "      <td id=\"T_496a5_row7_col6\" class=\"data row7 col6\" >-0.10</td>\n",
       "      <td id=\"T_496a5_row7_col7\" class=\"data row7 col7\" >1.00</td>\n",
       "      <td id=\"T_496a5_row7_col8\" class=\"data row7 col8\" >-0.64</td>\n",
       "      <td id=\"T_496a5_row7_col9\" class=\"data row7 col9\" >-0.83</td>\n",
       "      <td id=\"T_496a5_row7_col10\" class=\"data row7 col10\" >-0.54</td>\n",
       "      <td id=\"T_496a5_row7_col11\" class=\"data row7 col11\" >-0.84</td>\n",
       "      <td id=\"T_496a5_row7_col12\" class=\"data row7 col12\" >-0.91</td>\n",
       "      <td id=\"T_496a5_row7_col13\" class=\"data row7 col13\" >0.66</td>\n",
       "      <td id=\"T_496a5_row7_col14\" class=\"data row7 col14\" >-0.84</td>\n",
       "      <td id=\"T_496a5_row7_col15\" class=\"data row7 col15\" >0.79</td>\n",
       "      <td id=\"T_496a5_row7_col16\" class=\"data row7 col16\" >-0.37</td>\n",
       "      <td id=\"T_496a5_row7_col17\" class=\"data row7 col17\" >0.60</td>\n",
       "      <td id=\"T_496a5_row7_col18\" class=\"data row7 col18\" >0.93</td>\n",
       "      <td id=\"T_496a5_row7_col19\" class=\"data row7 col19\" >0.42</td>\n",
       "      <td id=\"T_496a5_row7_col20\" class=\"data row7 col20\" >-0.47</td>\n",
       "      <td id=\"T_496a5_row7_col21\" class=\"data row7 col21\" >0.50</td>\n",
       "      <td id=\"T_496a5_row7_col22\" class=\"data row7 col22\" >0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row8\" class=\"row_heading level0 row8\" >SB_BinaryStats_mean_longstretch1</th>\n",
       "      <td id=\"T_496a5_row8_col0\" class=\"data row8 col0\" >-0.65</td>\n",
       "      <td id=\"T_496a5_row8_col1\" class=\"data row8 col1\" >-0.34</td>\n",
       "      <td id=\"T_496a5_row8_col2\" class=\"data row8 col2\" >-0.35</td>\n",
       "      <td id=\"T_496a5_row8_col3\" class=\"data row8 col3\" >0.91</td>\n",
       "      <td id=\"T_496a5_row8_col4\" class=\"data row8 col4\" >0.62</td>\n",
       "      <td id=\"T_496a5_row8_col5\" class=\"data row8 col5\" >0.64</td>\n",
       "      <td id=\"T_496a5_row8_col6\" class=\"data row8 col6\" >0.41</td>\n",
       "      <td id=\"T_496a5_row8_col7\" class=\"data row8 col7\" >-0.64</td>\n",
       "      <td id=\"T_496a5_row8_col8\" class=\"data row8 col8\" >1.00</td>\n",
       "      <td id=\"T_496a5_row8_col9\" class=\"data row8 col9\" >0.71</td>\n",
       "      <td id=\"T_496a5_row8_col10\" class=\"data row8 col10\" >0.37</td>\n",
       "      <td id=\"T_496a5_row8_col11\" class=\"data row8 col11\" >0.66</td>\n",
       "      <td id=\"T_496a5_row8_col12\" class=\"data row8 col12\" >0.81</td>\n",
       "      <td id=\"T_496a5_row8_col13\" class=\"data row8 col13\" >-0.91</td>\n",
       "      <td id=\"T_496a5_row8_col14\" class=\"data row8 col14\" >0.85</td>\n",
       "      <td id=\"T_496a5_row8_col15\" class=\"data row8 col15\" >-0.62</td>\n",
       "      <td id=\"T_496a5_row8_col16\" class=\"data row8 col16\" >0.41</td>\n",
       "      <td id=\"T_496a5_row8_col17\" class=\"data row8 col17\" >-0.90</td>\n",
       "      <td id=\"T_496a5_row8_col18\" class=\"data row8 col18\" >-0.62</td>\n",
       "      <td id=\"T_496a5_row8_col19\" class=\"data row8 col19\" >0.09</td>\n",
       "      <td id=\"T_496a5_row8_col20\" class=\"data row8 col20\" >-0.16</td>\n",
       "      <td id=\"T_496a5_row8_col21\" class=\"data row8 col21\" >-0.89</td>\n",
       "      <td id=\"T_496a5_row8_col22\" class=\"data row8 col22\" >-0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row9\" class=\"row_heading level0 row9\" >SB_TransitionMatrix_3ac_sumdiagcov</th>\n",
       "      <td id=\"T_496a5_row9_col0\" class=\"data row9 col0\" >-0.53</td>\n",
       "      <td id=\"T_496a5_row9_col1\" class=\"data row9 col1\" >-0.64</td>\n",
       "      <td id=\"T_496a5_row9_col2\" class=\"data row9 col2\" >-0.65</td>\n",
       "      <td id=\"T_496a5_row9_col3\" class=\"data row9 col3\" >0.37</td>\n",
       "      <td id=\"T_496a5_row9_col4\" class=\"data row9 col4\" >0.57</td>\n",
       "      <td id=\"T_496a5_row9_col5\" class=\"data row9 col5\" >0.93</td>\n",
       "      <td id=\"T_496a5_row9_col6\" class=\"data row9 col6\" >0.19</td>\n",
       "      <td id=\"T_496a5_row9_col7\" class=\"data row9 col7\" >-0.83</td>\n",
       "      <td id=\"T_496a5_row9_col8\" class=\"data row9 col8\" >0.71</td>\n",
       "      <td id=\"T_496a5_row9_col9\" class=\"data row9 col9\" >1.00</td>\n",
       "      <td id=\"T_496a5_row9_col10\" class=\"data row9 col10\" >0.15</td>\n",
       "      <td id=\"T_496a5_row9_col11\" class=\"data row9 col11\" >0.82</td>\n",
       "      <td id=\"T_496a5_row9_col12\" class=\"data row9 col12\" >0.88</td>\n",
       "      <td id=\"T_496a5_row9_col13\" class=\"data row9 col13\" >-0.58</td>\n",
       "      <td id=\"T_496a5_row9_col14\" class=\"data row9 col14\" >0.83</td>\n",
       "      <td id=\"T_496a5_row9_col15\" class=\"data row9 col15\" >-0.94</td>\n",
       "      <td id=\"T_496a5_row9_col16\" class=\"data row9 col16\" >0.47</td>\n",
       "      <td id=\"T_496a5_row9_col17\" class=\"data row9 col17\" >-0.57</td>\n",
       "      <td id=\"T_496a5_row9_col18\" class=\"data row9 col18\" >-0.82</td>\n",
       "      <td id=\"T_496a5_row9_col19\" class=\"data row9 col19\" >0.13</td>\n",
       "      <td id=\"T_496a5_row9_col20\" class=\"data row9 col20\" >0.45</td>\n",
       "      <td id=\"T_496a5_row9_col21\" class=\"data row9 col21\" >-0.56</td>\n",
       "      <td id=\"T_496a5_row9_col22\" class=\"data row9 col22\" >-0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row10\" class=\"row_heading level0 row10\" >PD_PeriodicityWang_th0_01</th>\n",
       "      <td id=\"T_496a5_row10_col0\" class=\"data row10 col0\" >-0.35</td>\n",
       "      <td id=\"T_496a5_row10_col1\" class=\"data row10 col1\" >0.29</td>\n",
       "      <td id=\"T_496a5_row10_col2\" class=\"data row10 col2\" >0.41</td>\n",
       "      <td id=\"T_496a5_row10_col3\" class=\"data row10 col3\" >0.35</td>\n",
       "      <td id=\"T_496a5_row10_col4\" class=\"data row10 col4\" >0.90</td>\n",
       "      <td id=\"T_496a5_row10_col5\" class=\"data row10 col5\" >0.09</td>\n",
       "      <td id=\"T_496a5_row10_col6\" class=\"data row10 col6\" >0.12</td>\n",
       "      <td id=\"T_496a5_row10_col7\" class=\"data row10 col7\" >-0.54</td>\n",
       "      <td id=\"T_496a5_row10_col8\" class=\"data row10 col8\" >0.37</td>\n",
       "      <td id=\"T_496a5_row10_col9\" class=\"data row10 col9\" >0.15</td>\n",
       "      <td id=\"T_496a5_row10_col10\" class=\"data row10 col10\" >1.00</td>\n",
       "      <td id=\"T_496a5_row10_col11\" class=\"data row10 col11\" >0.64</td>\n",
       "      <td id=\"T_496a5_row10_col12\" class=\"data row10 col12\" >0.59</td>\n",
       "      <td id=\"T_496a5_row10_col13\" class=\"data row10 col13\" >-0.38</td>\n",
       "      <td id=\"T_496a5_row10_col14\" class=\"data row10 col14\" >0.63</td>\n",
       "      <td id=\"T_496a5_row10_col15\" class=\"data row10 col15\" >-0.34</td>\n",
       "      <td id=\"T_496a5_row10_col16\" class=\"data row10 col16\" >0.32</td>\n",
       "      <td id=\"T_496a5_row10_col17\" class=\"data row10 col17\" >-0.38</td>\n",
       "      <td id=\"T_496a5_row10_col18\" class=\"data row10 col18\" >-0.62</td>\n",
       "      <td id=\"T_496a5_row10_col19\" class=\"data row10 col19\" >-0.58</td>\n",
       "      <td id=\"T_496a5_row10_col20\" class=\"data row10 col20\" >0.30</td>\n",
       "      <td id=\"T_496a5_row10_col21\" class=\"data row10 col21\" >-0.38</td>\n",
       "      <td id=\"T_496a5_row10_col22\" class=\"data row10 col22\" >-0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row11\" class=\"row_heading level0 row11\" >CO_Embed2_Dist_tau_d_expfit_meandiff</th>\n",
       "      <td id=\"T_496a5_row11_col0\" class=\"data row11 col0\" >-0.63</td>\n",
       "      <td id=\"T_496a5_row11_col1\" class=\"data row11 col1\" >-0.45</td>\n",
       "      <td id=\"T_496a5_row11_col2\" class=\"data row11 col2\" >-0.37</td>\n",
       "      <td id=\"T_496a5_row11_col3\" class=\"data row11 col3\" >0.37</td>\n",
       "      <td id=\"T_496a5_row11_col4\" class=\"data row11 col4\" >0.90</td>\n",
       "      <td id=\"T_496a5_row11_col5\" class=\"data row11 col5\" >0.81</td>\n",
       "      <td id=\"T_496a5_row11_col6\" class=\"data row11 col6\" >0.30</td>\n",
       "      <td id=\"T_496a5_row11_col7\" class=\"data row11 col7\" >-0.84</td>\n",
       "      <td id=\"T_496a5_row11_col8\" class=\"data row11 col8\" >0.66</td>\n",
       "      <td id=\"T_496a5_row11_col9\" class=\"data row11 col9\" >0.82</td>\n",
       "      <td id=\"T_496a5_row11_col10\" class=\"data row11 col10\" >0.64</td>\n",
       "      <td id=\"T_496a5_row11_col11\" class=\"data row11 col11\" >1.00</td>\n",
       "      <td id=\"T_496a5_row11_col12\" class=\"data row11 col12\" >0.96</td>\n",
       "      <td id=\"T_496a5_row11_col13\" class=\"data row11 col13\" >-0.48</td>\n",
       "      <td id=\"T_496a5_row11_col14\" class=\"data row11 col14\" >0.95</td>\n",
       "      <td id=\"T_496a5_row11_col15\" class=\"data row11 col15\" >-0.94</td>\n",
       "      <td id=\"T_496a5_row11_col16\" class=\"data row11 col16\" >0.67</td>\n",
       "      <td id=\"T_496a5_row11_col17\" class=\"data row11 col17\" >-0.58</td>\n",
       "      <td id=\"T_496a5_row11_col18\" class=\"data row11 col18\" >-0.96</td>\n",
       "      <td id=\"T_496a5_row11_col19\" class=\"data row11 col19\" >-0.07</td>\n",
       "      <td id=\"T_496a5_row11_col20\" class=\"data row11 col20\" >0.61</td>\n",
       "      <td id=\"T_496a5_row11_col21\" class=\"data row11 col21\" >-0.62</td>\n",
       "      <td id=\"T_496a5_row11_col22\" class=\"data row11 col22\" >-0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row12\" class=\"row_heading level0 row12\" >IN_AutoMutualInfoStats_40_gaussian_fmmi</th>\n",
       "      <td id=\"T_496a5_row12_col0\" class=\"data row12 col0\" >-0.62</td>\n",
       "      <td id=\"T_496a5_row12_col1\" class=\"data row12 col1\" >-0.42</td>\n",
       "      <td id=\"T_496a5_row12_col2\" class=\"data row12 col2\" >-0.36</td>\n",
       "      <td id=\"T_496a5_row12_col3\" class=\"data row12 col3\" >0.55</td>\n",
       "      <td id=\"T_496a5_row12_col4\" class=\"data row12 col4\" >0.88</td>\n",
       "      <td id=\"T_496a5_row12_col5\" class=\"data row12 col5\" >0.81</td>\n",
       "      <td id=\"T_496a5_row12_col6\" class=\"data row12 col6\" >0.28</td>\n",
       "      <td id=\"T_496a5_row12_col7\" class=\"data row12 col7\" >-0.91</td>\n",
       "      <td id=\"T_496a5_row12_col8\" class=\"data row12 col8\" >0.81</td>\n",
       "      <td id=\"T_496a5_row12_col9\" class=\"data row12 col9\" >0.88</td>\n",
       "      <td id=\"T_496a5_row12_col10\" class=\"data row12 col10\" >0.59</td>\n",
       "      <td id=\"T_496a5_row12_col11\" class=\"data row12 col11\" >0.96</td>\n",
       "      <td id=\"T_496a5_row12_col12\" class=\"data row12 col12\" >1.00</td>\n",
       "      <td id=\"T_496a5_row12_col13\" class=\"data row12 col13\" >-0.70</td>\n",
       "      <td id=\"T_496a5_row12_col14\" class=\"data row12 col14\" >0.99</td>\n",
       "      <td id=\"T_496a5_row12_col15\" class=\"data row12 col15\" >-0.91</td>\n",
       "      <td id=\"T_496a5_row12_col16\" class=\"data row12 col16\" >0.56</td>\n",
       "      <td id=\"T_496a5_row12_col17\" class=\"data row12 col17\" >-0.72</td>\n",
       "      <td id=\"T_496a5_row12_col18\" class=\"data row12 col18\" >-0.95</td>\n",
       "      <td id=\"T_496a5_row12_col19\" class=\"data row12 col19\" >-0.12</td>\n",
       "      <td id=\"T_496a5_row12_col20\" class=\"data row12 col20\" >0.43</td>\n",
       "      <td id=\"T_496a5_row12_col21\" class=\"data row12 col21\" >-0.71</td>\n",
       "      <td id=\"T_496a5_row12_col22\" class=\"data row12 col22\" >-0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row13\" class=\"row_heading level0 row13\" >FC_LocalSimple_mean1_tauresrat</th>\n",
       "      <td id=\"T_496a5_row13_col0\" class=\"data row13 col0\" >0.46</td>\n",
       "      <td id=\"T_496a5_row13_col1\" class=\"data row13 col1\" >-0.00</td>\n",
       "      <td id=\"T_496a5_row13_col2\" class=\"data row13 col2\" >0.03</td>\n",
       "      <td id=\"T_496a5_row13_col3\" class=\"data row13 col3\" >-0.87</td>\n",
       "      <td id=\"T_496a5_row13_col4\" class=\"data row13 col4\" >-0.57</td>\n",
       "      <td id=\"T_496a5_row13_col5\" class=\"data row13 col5\" >-0.37</td>\n",
       "      <td id=\"T_496a5_row13_col6\" class=\"data row13 col6\" >-0.11</td>\n",
       "      <td id=\"T_496a5_row13_col7\" class=\"data row13 col7\" >0.66</td>\n",
       "      <td id=\"T_496a5_row13_col8\" class=\"data row13 col8\" >-0.91</td>\n",
       "      <td id=\"T_496a5_row13_col9\" class=\"data row13 col9\" >-0.58</td>\n",
       "      <td id=\"T_496a5_row13_col10\" class=\"data row13 col10\" >-0.38</td>\n",
       "      <td id=\"T_496a5_row13_col11\" class=\"data row13 col11\" >-0.48</td>\n",
       "      <td id=\"T_496a5_row13_col12\" class=\"data row13 col12\" >-0.70</td>\n",
       "      <td id=\"T_496a5_row13_col13\" class=\"data row13 col13\" >1.00</td>\n",
       "      <td id=\"T_496a5_row13_col14\" class=\"data row13 col14\" >-0.70</td>\n",
       "      <td id=\"T_496a5_row13_col15\" class=\"data row13 col15\" >0.41</td>\n",
       "      <td id=\"T_496a5_row13_col16\" class=\"data row13 col16\" >-0.05</td>\n",
       "      <td id=\"T_496a5_row13_col17\" class=\"data row13 col17\" >0.78</td>\n",
       "      <td id=\"T_496a5_row13_col18\" class=\"data row13 col18\" >0.50</td>\n",
       "      <td id=\"T_496a5_row13_col19\" class=\"data row13 col19\" >0.23</td>\n",
       "      <td id=\"T_496a5_row13_col20\" class=\"data row13 col20\" >0.28</td>\n",
       "      <td id=\"T_496a5_row13_col21\" class=\"data row13 col21\" >0.68</td>\n",
       "      <td id=\"T_496a5_row13_col22\" class=\"data row13 col22\" >0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row14\" class=\"row_heading level0 row14\" >DN_OutlierInclude_p_001_mdrmd</th>\n",
       "      <td id=\"T_496a5_row14_col0\" class=\"data row14 col0\" >-0.70</td>\n",
       "      <td id=\"T_496a5_row14_col1\" class=\"data row14 col1\" >-0.41</td>\n",
       "      <td id=\"T_496a5_row14_col2\" class=\"data row14 col2\" >-0.35</td>\n",
       "      <td id=\"T_496a5_row14_col3\" class=\"data row14 col3\" >0.62</td>\n",
       "      <td id=\"T_496a5_row14_col4\" class=\"data row14 col4\" >0.89</td>\n",
       "      <td id=\"T_496a5_row14_col5\" class=\"data row14 col5\" >0.79</td>\n",
       "      <td id=\"T_496a5_row14_col6\" class=\"data row14 col6\" >0.35</td>\n",
       "      <td id=\"T_496a5_row14_col7\" class=\"data row14 col7\" >-0.84</td>\n",
       "      <td id=\"T_496a5_row14_col8\" class=\"data row14 col8\" >0.85</td>\n",
       "      <td id=\"T_496a5_row14_col9\" class=\"data row14 col9\" >0.83</td>\n",
       "      <td id=\"T_496a5_row14_col10\" class=\"data row14 col10\" >0.63</td>\n",
       "      <td id=\"T_496a5_row14_col11\" class=\"data row14 col11\" >0.95</td>\n",
       "      <td id=\"T_496a5_row14_col12\" class=\"data row14 col12\" >0.99</td>\n",
       "      <td id=\"T_496a5_row14_col13\" class=\"data row14 col13\" >-0.70</td>\n",
       "      <td id=\"T_496a5_row14_col14\" class=\"data row14 col14\" >1.00</td>\n",
       "      <td id=\"T_496a5_row14_col15\" class=\"data row14 col15\" >-0.88</td>\n",
       "      <td id=\"T_496a5_row14_col16\" class=\"data row14 col16\" >0.61</td>\n",
       "      <td id=\"T_496a5_row14_col17\" class=\"data row14 col17\" >-0.75</td>\n",
       "      <td id=\"T_496a5_row14_col18\" class=\"data row14 col18\" >-0.91</td>\n",
       "      <td id=\"T_496a5_row14_col19\" class=\"data row14 col19\" >-0.05</td>\n",
       "      <td id=\"T_496a5_row14_col20\" class=\"data row14 col20\" >0.36</td>\n",
       "      <td id=\"T_496a5_row14_col21\" class=\"data row14 col21\" >-0.77</td>\n",
       "      <td id=\"T_496a5_row14_col22\" class=\"data row14 col22\" >-0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row15\" class=\"row_heading level0 row15\" >DN_OutlierInclude_n_001_mdrmd</th>\n",
       "      <td id=\"T_496a5_row15_col0\" class=\"data row15 col0\" >0.62</td>\n",
       "      <td id=\"T_496a5_row15_col1\" class=\"data row15 col1\" >0.67</td>\n",
       "      <td id=\"T_496a5_row15_col2\" class=\"data row15 col2\" >0.64</td>\n",
       "      <td id=\"T_496a5_row15_col3\" class=\"data row15 col3\" >-0.28</td>\n",
       "      <td id=\"T_496a5_row15_col4\" class=\"data row15 col4\" >-0.69</td>\n",
       "      <td id=\"T_496a5_row15_col5\" class=\"data row15 col5\" >-0.95</td>\n",
       "      <td id=\"T_496a5_row15_col6\" class=\"data row15 col6\" >-0.28</td>\n",
       "      <td id=\"T_496a5_row15_col7\" class=\"data row15 col7\" >0.79</td>\n",
       "      <td id=\"T_496a5_row15_col8\" class=\"data row15 col8\" >-0.62</td>\n",
       "      <td id=\"T_496a5_row15_col9\" class=\"data row15 col9\" >-0.94</td>\n",
       "      <td id=\"T_496a5_row15_col10\" class=\"data row15 col10\" >-0.34</td>\n",
       "      <td id=\"T_496a5_row15_col11\" class=\"data row15 col11\" >-0.94</td>\n",
       "      <td id=\"T_496a5_row15_col12\" class=\"data row15 col12\" >-0.91</td>\n",
       "      <td id=\"T_496a5_row15_col13\" class=\"data row15 col13\" >0.41</td>\n",
       "      <td id=\"T_496a5_row15_col14\" class=\"data row15 col14\" >-0.88</td>\n",
       "      <td id=\"T_496a5_row15_col15\" class=\"data row15 col15\" >1.00</td>\n",
       "      <td id=\"T_496a5_row15_col16\" class=\"data row15 col16\" >-0.66</td>\n",
       "      <td id=\"T_496a5_row15_col17\" class=\"data row15 col17\" >0.51</td>\n",
       "      <td id=\"T_496a5_row15_col18\" class=\"data row15 col18\" >0.90</td>\n",
       "      <td id=\"T_496a5_row15_col19\" class=\"data row15 col19\" >-0.16</td>\n",
       "      <td id=\"T_496a5_row15_col20\" class=\"data row15 col20\" >-0.64</td>\n",
       "      <td id=\"T_496a5_row15_col21\" class=\"data row15 col21\" >0.57</td>\n",
       "      <td id=\"T_496a5_row15_col22\" class=\"data row15 col22\" >0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row16\" class=\"row_heading level0 row16\" >SP_Summaries_welch_rect_area_5_1</th>\n",
       "      <td id=\"T_496a5_row16_col0\" class=\"data row16 col0\" >-0.30</td>\n",
       "      <td id=\"T_496a5_row16_col1\" class=\"data row16 col1\" >-0.75</td>\n",
       "      <td id=\"T_496a5_row16_col2\" class=\"data row16 col2\" >-0.62</td>\n",
       "      <td id=\"T_496a5_row16_col3\" class=\"data row16 col3\" >0.26</td>\n",
       "      <td id=\"T_496a5_row16_col4\" class=\"data row16 col4\" >0.47</td>\n",
       "      <td id=\"T_496a5_row16_col5\" class=\"data row16 col5\" >0.71</td>\n",
       "      <td id=\"T_496a5_row16_col6\" class=\"data row16 col6\" >0.86</td>\n",
       "      <td id=\"T_496a5_row16_col7\" class=\"data row16 col7\" >-0.37</td>\n",
       "      <td id=\"T_496a5_row16_col8\" class=\"data row16 col8\" >0.41</td>\n",
       "      <td id=\"T_496a5_row16_col9\" class=\"data row16 col9\" >0.47</td>\n",
       "      <td id=\"T_496a5_row16_col10\" class=\"data row16 col10\" >0.32</td>\n",
       "      <td id=\"T_496a5_row16_col11\" class=\"data row16 col11\" >0.67</td>\n",
       "      <td id=\"T_496a5_row16_col12\" class=\"data row16 col12\" >0.56</td>\n",
       "      <td id=\"T_496a5_row16_col13\" class=\"data row16 col13\" >-0.05</td>\n",
       "      <td id=\"T_496a5_row16_col14\" class=\"data row16 col14\" >0.61</td>\n",
       "      <td id=\"T_496a5_row16_col15\" class=\"data row16 col15\" >-0.66</td>\n",
       "      <td id=\"T_496a5_row16_col16\" class=\"data row16 col16\" >1.00</td>\n",
       "      <td id=\"T_496a5_row16_col17\" class=\"data row16 col17\" >-0.60</td>\n",
       "      <td id=\"T_496a5_row16_col18\" class=\"data row16 col18\" >-0.65</td>\n",
       "      <td id=\"T_496a5_row16_col19\" class=\"data row16 col19\" >0.34</td>\n",
       "      <td id=\"T_496a5_row16_col20\" class=\"data row16 col20\" >0.35</td>\n",
       "      <td id=\"T_496a5_row16_col21\" class=\"data row16 col21\" >-0.72</td>\n",
       "      <td id=\"T_496a5_row16_col22\" class=\"data row16 col22\" >-0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row17\" class=\"row_heading level0 row17\" >SB_BinaryStats_diff_longstretch0</th>\n",
       "      <td id=\"T_496a5_row17_col0\" class=\"data row17 col0\" >0.34</td>\n",
       "      <td id=\"T_496a5_row17_col1\" class=\"data row17 col1\" >0.41</td>\n",
       "      <td id=\"T_496a5_row17_col2\" class=\"data row17 col2\" >0.34</td>\n",
       "      <td id=\"T_496a5_row17_col3\" class=\"data row17 col3\" >-0.86</td>\n",
       "      <td id=\"T_496a5_row17_col4\" class=\"data row17 col4\" >-0.57</td>\n",
       "      <td id=\"T_496a5_row17_col5\" class=\"data row17 col5\" >-0.58</td>\n",
       "      <td id=\"T_496a5_row17_col6\" class=\"data row17 col6\" >-0.70</td>\n",
       "      <td id=\"T_496a5_row17_col7\" class=\"data row17 col7\" >0.60</td>\n",
       "      <td id=\"T_496a5_row17_col8\" class=\"data row17 col8\" >-0.90</td>\n",
       "      <td id=\"T_496a5_row17_col9\" class=\"data row17 col9\" >-0.57</td>\n",
       "      <td id=\"T_496a5_row17_col10\" class=\"data row17 col10\" >-0.38</td>\n",
       "      <td id=\"T_496a5_row17_col11\" class=\"data row17 col11\" >-0.58</td>\n",
       "      <td id=\"T_496a5_row17_col12\" class=\"data row17 col12\" >-0.72</td>\n",
       "      <td id=\"T_496a5_row17_col13\" class=\"data row17 col13\" >0.78</td>\n",
       "      <td id=\"T_496a5_row17_col14\" class=\"data row17 col14\" >-0.75</td>\n",
       "      <td id=\"T_496a5_row17_col15\" class=\"data row17 col15\" >0.51</td>\n",
       "      <td id=\"T_496a5_row17_col16\" class=\"data row17 col16\" >-0.60</td>\n",
       "      <td id=\"T_496a5_row17_col17\" class=\"data row17 col17\" >1.00</td>\n",
       "      <td id=\"T_496a5_row17_col18\" class=\"data row17 col18\" >0.62</td>\n",
       "      <td id=\"T_496a5_row17_col19\" class=\"data row17 col19\" >-0.03</td>\n",
       "      <td id=\"T_496a5_row17_col20\" class=\"data row17 col20\" >0.23</td>\n",
       "      <td id=\"T_496a5_row17_col21\" class=\"data row17 col21\" >0.97</td>\n",
       "      <td id=\"T_496a5_row17_col22\" class=\"data row17 col22\" >0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row18\" class=\"row_heading level0 row18\" >SB_MotifThree_quantile_hh</th>\n",
       "      <td id=\"T_496a5_row18_col0\" class=\"data row18 col0\" >0.42</td>\n",
       "      <td id=\"T_496a5_row18_col1\" class=\"data row18 col1\" >0.43</td>\n",
       "      <td id=\"T_496a5_row18_col2\" class=\"data row18 col2\" >0.33</td>\n",
       "      <td id=\"T_496a5_row18_col3\" class=\"data row18 col3\" >-0.33</td>\n",
       "      <td id=\"T_496a5_row18_col4\" class=\"data row18 col4\" >-0.88</td>\n",
       "      <td id=\"T_496a5_row18_col5\" class=\"data row18 col5\" >-0.78</td>\n",
       "      <td id=\"T_496a5_row18_col6\" class=\"data row18 col6\" >-0.32</td>\n",
       "      <td id=\"T_496a5_row18_col7\" class=\"data row18 col7\" >0.93</td>\n",
       "      <td id=\"T_496a5_row18_col8\" class=\"data row18 col8\" >-0.62</td>\n",
       "      <td id=\"T_496a5_row18_col9\" class=\"data row18 col9\" >-0.82</td>\n",
       "      <td id=\"T_496a5_row18_col10\" class=\"data row18 col10\" >-0.62</td>\n",
       "      <td id=\"T_496a5_row18_col11\" class=\"data row18 col11\" >-0.96</td>\n",
       "      <td id=\"T_496a5_row18_col12\" class=\"data row18 col12\" >-0.95</td>\n",
       "      <td id=\"T_496a5_row18_col13\" class=\"data row18 col13\" >0.50</td>\n",
       "      <td id=\"T_496a5_row18_col14\" class=\"data row18 col14\" >-0.91</td>\n",
       "      <td id=\"T_496a5_row18_col15\" class=\"data row18 col15\" >0.90</td>\n",
       "      <td id=\"T_496a5_row18_col16\" class=\"data row18 col16\" >-0.65</td>\n",
       "      <td id=\"T_496a5_row18_col17\" class=\"data row18 col17\" >0.62</td>\n",
       "      <td id=\"T_496a5_row18_col18\" class=\"data row18 col18\" >1.00</td>\n",
       "      <td id=\"T_496a5_row18_col19\" class=\"data row18 col19\" >0.22</td>\n",
       "      <td id=\"T_496a5_row18_col20\" class=\"data row18 col20\" >-0.60</td>\n",
       "      <td id=\"T_496a5_row18_col21\" class=\"data row18 col21\" >0.61</td>\n",
       "      <td id=\"T_496a5_row18_col22\" class=\"data row18 col22\" >0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row19\" class=\"row_heading level0 row19\" >SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1</th>\n",
       "      <td id=\"T_496a5_row19_col0\" class=\"data row19 col0\" >-0.37</td>\n",
       "      <td id=\"T_496a5_row19_col1\" class=\"data row19 col1\" >-0.70</td>\n",
       "      <td id=\"T_496a5_row19_col2\" class=\"data row19 col2\" >-0.78</td>\n",
       "      <td id=\"T_496a5_row19_col3\" class=\"data row19 col3\" >0.08</td>\n",
       "      <td id=\"T_496a5_row19_col4\" class=\"data row19 col4\" >-0.42</td>\n",
       "      <td id=\"T_496a5_row19_col5\" class=\"data row19 col5\" >0.39</td>\n",
       "      <td id=\"T_496a5_row19_col6\" class=\"data row19 col6\" >0.39</td>\n",
       "      <td id=\"T_496a5_row19_col7\" class=\"data row19 col7\" >0.42</td>\n",
       "      <td id=\"T_496a5_row19_col8\" class=\"data row19 col8\" >0.09</td>\n",
       "      <td id=\"T_496a5_row19_col9\" class=\"data row19 col9\" >0.13</td>\n",
       "      <td id=\"T_496a5_row19_col10\" class=\"data row19 col10\" >-0.58</td>\n",
       "      <td id=\"T_496a5_row19_col11\" class=\"data row19 col11\" >-0.07</td>\n",
       "      <td id=\"T_496a5_row19_col12\" class=\"data row19 col12\" >-0.12</td>\n",
       "      <td id=\"T_496a5_row19_col13\" class=\"data row19 col13\" >0.23</td>\n",
       "      <td id=\"T_496a5_row19_col14\" class=\"data row19 col14\" >-0.05</td>\n",
       "      <td id=\"T_496a5_row19_col15\" class=\"data row19 col15\" >-0.16</td>\n",
       "      <td id=\"T_496a5_row19_col16\" class=\"data row19 col16\" >0.34</td>\n",
       "      <td id=\"T_496a5_row19_col17\" class=\"data row19 col17\" >-0.03</td>\n",
       "      <td id=\"T_496a5_row19_col18\" class=\"data row19 col18\" >0.22</td>\n",
       "      <td id=\"T_496a5_row19_col19\" class=\"data row19 col19\" >1.00</td>\n",
       "      <td id=\"T_496a5_row19_col20\" class=\"data row19 col20\" >-0.13</td>\n",
       "      <td id=\"T_496a5_row19_col21\" class=\"data row19 col21\" >-0.22</td>\n",
       "      <td id=\"T_496a5_row19_col22\" class=\"data row19 col22\" >-0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row20\" class=\"row_heading level0 row20\" >SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1</th>\n",
       "      <td id=\"T_496a5_row20_col0\" class=\"data row20 col0\" >-0.18</td>\n",
       "      <td id=\"T_496a5_row20_col1\" class=\"data row20 col1\" >-0.30</td>\n",
       "      <td id=\"T_496a5_row20_col2\" class=\"data row20 col2\" >-0.22</td>\n",
       "      <td id=\"T_496a5_row20_col3\" class=\"data row20 col3\" >-0.50</td>\n",
       "      <td id=\"T_496a5_row20_col4\" class=\"data row20 col4\" >0.45</td>\n",
       "      <td id=\"T_496a5_row20_col5\" class=\"data row20 col5\" >0.48</td>\n",
       "      <td id=\"T_496a5_row20_col6\" class=\"data row20 col6\" >-0.16</td>\n",
       "      <td id=\"T_496a5_row20_col7\" class=\"data row20 col7\" >-0.47</td>\n",
       "      <td id=\"T_496a5_row20_col8\" class=\"data row20 col8\" >-0.16</td>\n",
       "      <td id=\"T_496a5_row20_col9\" class=\"data row20 col9\" >0.45</td>\n",
       "      <td id=\"T_496a5_row20_col10\" class=\"data row20 col10\" >0.30</td>\n",
       "      <td id=\"T_496a5_row20_col11\" class=\"data row20 col11\" >0.61</td>\n",
       "      <td id=\"T_496a5_row20_col12\" class=\"data row20 col12\" >0.43</td>\n",
       "      <td id=\"T_496a5_row20_col13\" class=\"data row20 col13\" >0.28</td>\n",
       "      <td id=\"T_496a5_row20_col14\" class=\"data row20 col14\" >0.36</td>\n",
       "      <td id=\"T_496a5_row20_col15\" class=\"data row20 col15\" >-0.64</td>\n",
       "      <td id=\"T_496a5_row20_col16\" class=\"data row20 col16\" >0.35</td>\n",
       "      <td id=\"T_496a5_row20_col17\" class=\"data row20 col17\" >0.23</td>\n",
       "      <td id=\"T_496a5_row20_col18\" class=\"data row20 col18\" >-0.60</td>\n",
       "      <td id=\"T_496a5_row20_col19\" class=\"data row20 col19\" >-0.13</td>\n",
       "      <td id=\"T_496a5_row20_col20\" class=\"data row20 col20\" >1.00</td>\n",
       "      <td id=\"T_496a5_row20_col21\" class=\"data row20 col21\" >0.17</td>\n",
       "      <td id=\"T_496a5_row20_col22\" class=\"data row20 col22\" >-0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row21\" class=\"row_heading level0 row21\" >SP_Summaries_welch_rect_centroid</th>\n",
       "      <td id=\"T_496a5_row21_col0\" class=\"data row21 col0\" >0.49</td>\n",
       "      <td id=\"T_496a5_row21_col1\" class=\"data row21 col1\" >0.52</td>\n",
       "      <td id=\"T_496a5_row21_col2\" class=\"data row21 col2\" >0.45</td>\n",
       "      <td id=\"T_496a5_row21_col3\" class=\"data row21 col3\" >-0.85</td>\n",
       "      <td id=\"T_496a5_row21_col4\" class=\"data row21 col4\" >-0.56</td>\n",
       "      <td id=\"T_496a5_row21_col5\" class=\"data row21 col5\" >-0.64</td>\n",
       "      <td id=\"T_496a5_row21_col6\" class=\"data row21 col6\" >-0.78</td>\n",
       "      <td id=\"T_496a5_row21_col7\" class=\"data row21 col7\" >0.50</td>\n",
       "      <td id=\"T_496a5_row21_col8\" class=\"data row21 col8\" >-0.89</td>\n",
       "      <td id=\"T_496a5_row21_col9\" class=\"data row21 col9\" >-0.56</td>\n",
       "      <td id=\"T_496a5_row21_col10\" class=\"data row21 col10\" >-0.38</td>\n",
       "      <td id=\"T_496a5_row21_col11\" class=\"data row21 col11\" >-0.62</td>\n",
       "      <td id=\"T_496a5_row21_col12\" class=\"data row21 col12\" >-0.71</td>\n",
       "      <td id=\"T_496a5_row21_col13\" class=\"data row21 col13\" >0.68</td>\n",
       "      <td id=\"T_496a5_row21_col14\" class=\"data row21 col14\" >-0.77</td>\n",
       "      <td id=\"T_496a5_row21_col15\" class=\"data row21 col15\" >0.57</td>\n",
       "      <td id=\"T_496a5_row21_col16\" class=\"data row21 col16\" >-0.72</td>\n",
       "      <td id=\"T_496a5_row21_col17\" class=\"data row21 col17\" >0.97</td>\n",
       "      <td id=\"T_496a5_row21_col18\" class=\"data row21 col18\" >0.61</td>\n",
       "      <td id=\"T_496a5_row21_col19\" class=\"data row21 col19\" >-0.22</td>\n",
       "      <td id=\"T_496a5_row21_col20\" class=\"data row21 col20\" >0.17</td>\n",
       "      <td id=\"T_496a5_row21_col21\" class=\"data row21 col21\" >1.00</td>\n",
       "      <td id=\"T_496a5_row21_col22\" class=\"data row21 col22\" >0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_496a5_level0_row22\" class=\"row_heading level0 row22\" >FC_LocalSimple_mean3_stderr</th>\n",
       "      <td id=\"T_496a5_row22_col0\" class=\"data row22 col0\" >0.61</td>\n",
       "      <td id=\"T_496a5_row22_col1\" class=\"data row22 col1\" >0.62</td>\n",
       "      <td id=\"T_496a5_row22_col2\" class=\"data row22 col2\" >0.53</td>\n",
       "      <td id=\"T_496a5_row22_col3\" class=\"data row22 col3\" >-0.57</td>\n",
       "      <td id=\"T_496a5_row22_col4\" class=\"data row22 col4\" >-0.79</td>\n",
       "      <td id=\"T_496a5_row22_col5\" class=\"data row22 col5\" >-0.86</td>\n",
       "      <td id=\"T_496a5_row22_col6\" class=\"data row22 col6\" >-0.60</td>\n",
       "      <td id=\"T_496a5_row22_col7\" class=\"data row22 col7\" >0.74</td>\n",
       "      <td id=\"T_496a5_row22_col8\" class=\"data row22 col8\" >-0.79</td>\n",
       "      <td id=\"T_496a5_row22_col9\" class=\"data row22 col9\" >-0.79</td>\n",
       "      <td id=\"T_496a5_row22_col10\" class=\"data row22 col10\" >-0.53</td>\n",
       "      <td id=\"T_496a5_row22_col11\" class=\"data row22 col11\" >-0.93</td>\n",
       "      <td id=\"T_496a5_row22_col12\" class=\"data row22 col12\" >-0.92</td>\n",
       "      <td id=\"T_496a5_row22_col13\" class=\"data row22 col13\" >0.54</td>\n",
       "      <td id=\"T_496a5_row22_col14\" class=\"data row22 col14\" >-0.95</td>\n",
       "      <td id=\"T_496a5_row22_col15\" class=\"data row22 col15\" >0.89</td>\n",
       "      <td id=\"T_496a5_row22_col16\" class=\"data row22 col16\" >-0.82</td>\n",
       "      <td id=\"T_496a5_row22_col17\" class=\"data row22 col17\" >0.79</td>\n",
       "      <td id=\"T_496a5_row22_col18\" class=\"data row22 col18\" >0.90</td>\n",
       "      <td id=\"T_496a5_row22_col19\" class=\"data row22 col19\" >-0.13</td>\n",
       "      <td id=\"T_496a5_row22_col20\" class=\"data row22 col20\" >-0.36</td>\n",
       "      <td id=\"T_496a5_row22_col21\" class=\"data row22 col21\" >0.85</td>\n",
       "      <td id=\"T_496a5_row22_col22\" class=\"data row22 col22\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9d92b1aac0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = data[data['model']=='switch'].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d0/l9cqdxf90hbg0dj97q8bs7kc0000gn/T/ipykernel_76447/3231663438.py:2: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "  corr.style.background_gradient(cmap='coolwarm').set_precision(2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d9ffa_row0_col0, #T_d9ffa_row1_col1, #T_d9ffa_row2_col2, #T_d9ffa_row3_col3, #T_d9ffa_row4_col4, #T_d9ffa_row5_col5, #T_d9ffa_row6_col6, #T_d9ffa_row7_col7, #T_d9ffa_row8_col8, #T_d9ffa_row9_col9, #T_d9ffa_row10_col10, #T_d9ffa_row11_col11, #T_d9ffa_row12_col12, #T_d9ffa_row13_col13, #T_d9ffa_row14_col14, #T_d9ffa_row15_col15, #T_d9ffa_row16_col16, #T_d9ffa_row17_col17, #T_d9ffa_row18_col18, #T_d9ffa_row19_col19, #T_d9ffa_row20_col20, #T_d9ffa_row21_col21, #T_d9ffa_row22_col22 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row0_col1, #T_d9ffa_row15_col13, #T_d9ffa_row19_col3 {\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row0_col2, #T_d9ffa_row2_col10 {\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row0_col3, #T_d9ffa_row4_col0, #T_d9ffa_row8_col15, #T_d9ffa_row12_col17 {\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row0_col4, #T_d9ffa_row0_col11, #T_d9ffa_row10_col17, #T_d9ffa_row16_col7, #T_d9ffa_row20_col22 {\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row0_col5, #T_d9ffa_row0_col12, #T_d9ffa_row2_col11, #T_d9ffa_row2_col12, #T_d9ffa_row10_col21 {\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row0_col6, #T_d9ffa_row4_col2 {\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row0_col7 {\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row0_col8, #T_d9ffa_row16_col17 {\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row0_col9, #T_d9ffa_row14_col15 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row0_col10 {\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row0_col13 {\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row0_col14, #T_d9ffa_row11_col21, #T_d9ffa_row20_col7 {\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row0_col15, #T_d9ffa_row3_col5 {\n",
       "  background-color: #f7ba9f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row0_col16, #T_d9ffa_row7_col0, #T_d9ffa_row14_col20, #T_d9ffa_row19_col6 {\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row0_col17, #T_d9ffa_row7_col6, #T_d9ffa_row10_col1, #T_d9ffa_row13_col15, #T_d9ffa_row15_col17, #T_d9ffa_row17_col2 {\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row0_col18, #T_d9ffa_row1_col17 {\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row0_col19, #T_d9ffa_row10_col13, #T_d9ffa_row13_col6 {\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row0_col20 {\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row0_col21, #T_d9ffa_row7_col17, #T_d9ffa_row13_col0, #T_d9ffa_row21_col2 {\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row0_col22, #T_d9ffa_row22_col13 {\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row1_col0, #T_d9ffa_row9_col6 {\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row1_col2 {\n",
       "  background-color: #b8122a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row1_col3, #T_d9ffa_row13_col11 {\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row1_col4 {\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row1_col5, #T_d9ffa_row7_col12, #T_d9ffa_row8_col21, #T_d9ffa_row17_col3 {\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row1_col6, #T_d9ffa_row16_col0 {\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row1_col7, #T_d9ffa_row14_col3, #T_d9ffa_row18_col21, #T_d9ffa_row21_col1 {\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row1_col8, #T_d9ffa_row2_col8, #T_d9ffa_row13_col4, #T_d9ffa_row17_col10, #T_d9ffa_row21_col4, #T_d9ffa_row22_col20 {\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row1_col9, #T_d9ffa_row4_col15, #T_d9ffa_row9_col1, #T_d9ffa_row18_col16, #T_d9ffa_row19_col10 {\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row1_col10, #T_d9ffa_row2_col0, #T_d9ffa_row19_col11 {\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row1_col11, #T_d9ffa_row8_col2 {\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row1_col12, #T_d9ffa_row8_col1, #T_d9ffa_row22_col6 {\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row1_col13 {\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row1_col14, #T_d9ffa_row6_col22, #T_d9ffa_row19_col14 {\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row1_col15, #T_d9ffa_row14_col11 {\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row1_col16 {\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row1_col18, #T_d9ffa_row22_col2 {\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row1_col19, #T_d9ffa_row3_col21, #T_d9ffa_row22_col4 {\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row1_col20, #T_d9ffa_row11_col1, #T_d9ffa_row21_col12 {\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row1_col21, #T_d9ffa_row7_col1, #T_d9ffa_row13_col20 {\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row1_col22, #T_d9ffa_row5_col8, #T_d9ffa_row8_col4, #T_d9ffa_row20_col11 {\n",
       "  background-color: #ec7f63;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row2_col1 {\n",
       "  background-color: #b70d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row2_col3 {\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row2_col4, #T_d9ffa_row18_col19 {\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row2_col5, #T_d9ffa_row5_col22, #T_d9ffa_row7_col4, #T_d9ffa_row13_col14, #T_d9ffa_row18_col20, #T_d9ffa_row22_col9 {\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row2_col6, #T_d9ffa_row2_col14 {\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row2_col7, #T_d9ffa_row2_col21, #T_d9ffa_row5_col3, #T_d9ffa_row10_col2 {\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row2_col9 {\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row2_col13, #T_d9ffa_row4_col1 {\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row2_col15, #T_d9ffa_row13_col21, #T_d9ffa_row16_col11 {\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row2_col16, #T_d9ffa_row7_col5, #T_d9ffa_row12_col21 {\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row2_col17, #T_d9ffa_row8_col19 {\n",
       "  background-color: #ead5c9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row2_col18, #T_d9ffa_row3_col11, #T_d9ffa_row5_col20, #T_d9ffa_row10_col14 {\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row2_col19, #T_d9ffa_row5_col1, #T_d9ffa_row5_col2, #T_d9ffa_row8_col0, #T_d9ffa_row8_col13, #T_d9ffa_row11_col15, #T_d9ffa_row11_col18, #T_d9ffa_row11_col22, #T_d9ffa_row12_col7, #T_d9ffa_row12_col18, #T_d9ffa_row13_col3, #T_d9ffa_row14_col17, #T_d9ffa_row14_col21, #T_d9ffa_row15_col5, #T_d9ffa_row15_col9, #T_d9ffa_row15_col20, #T_d9ffa_row17_col14, #T_d9ffa_row18_col4, #T_d9ffa_row18_col10, #T_d9ffa_row18_col11, #T_d9ffa_row18_col12, #T_d9ffa_row21_col3, #T_d9ffa_row21_col6, #T_d9ffa_row21_col14, #T_d9ffa_row22_col8, #T_d9ffa_row22_col16 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row2_col20, #T_d9ffa_row11_col13, #T_d9ffa_row12_col2, #T_d9ffa_row17_col4, #T_d9ffa_row20_col1, #T_d9ffa_row21_col11 {\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row2_col22 {\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row3_col0, #T_d9ffa_row7_col9, #T_d9ffa_row8_col17, #T_d9ffa_row11_col7, #T_d9ffa_row18_col9 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row3_col1 {\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row3_col2, #T_d9ffa_row22_col19 {\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row3_col4, #T_d9ffa_row16_col14, #T_d9ffa_row20_col4, #T_d9ffa_row20_col5 {\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row3_col6, #T_d9ffa_row6_col3 {\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row3_col7, #T_d9ffa_row20_col2 {\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row3_col8, #T_d9ffa_row8_col3 {\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row3_col9, #T_d9ffa_row16_col8 {\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row3_col10, #T_d9ffa_row15_col21 {\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row3_col12, #T_d9ffa_row5_col14, #T_d9ffa_row8_col14, #T_d9ffa_row14_col8 {\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row3_col13, #T_d9ffa_row13_col8, #T_d9ffa_row15_col11, #T_d9ffa_row21_col8 {\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row3_col14, #T_d9ffa_row7_col13, #T_d9ffa_row8_col16, #T_d9ffa_row9_col20, #T_d9ffa_row14_col10, #T_d9ffa_row17_col18 {\n",
       "  background-color: #f7b497;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row3_col15, #T_d9ffa_row3_col18 {\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row3_col16 {\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row3_col17, #T_d9ffa_row4_col7, #T_d9ffa_row7_col11, #T_d9ffa_row16_col22, #T_d9ffa_row22_col10 {\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row3_col19, #T_d9ffa_row6_col18, #T_d9ffa_row19_col8 {\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row3_col20, #T_d9ffa_row14_col19 {\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row3_col22 {\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row4_col3, #T_d9ffa_row13_col7 {\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row4_col5, #T_d9ffa_row5_col4, #T_d9ffa_row18_col1 {\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row4_col6 {\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row4_col8, #T_d9ffa_row22_col1 {\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row4_col9, #T_d9ffa_row9_col4, #T_d9ffa_row16_col12 {\n",
       "  background-color: #f18f71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row4_col10, #T_d9ffa_row4_col12, #T_d9ffa_row12_col4 {\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row4_col11 {\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row4_col13, #T_d9ffa_row10_col18, #T_d9ffa_row16_col15 {\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row4_col14, #T_d9ffa_row10_col11, #T_d9ffa_row14_col9, #T_d9ffa_row15_col2, #T_d9ffa_row21_col13 {\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row4_col16, #T_d9ffa_row13_col22, #T_d9ffa_row16_col9 {\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row4_col17, #T_d9ffa_row13_col9, #T_d9ffa_row21_col9 {\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row4_col18, #T_d9ffa_row6_col17, #T_d9ffa_row6_col21, #T_d9ffa_row7_col10, #T_d9ffa_row17_col8 {\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row4_col19 {\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row4_col20 {\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row4_col21, #T_d9ffa_row5_col17, #T_d9ffa_row21_col5 {\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row4_col22, #T_d9ffa_row8_col22, #T_d9ffa_row9_col22 {\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row5_col0 {\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row5_col6 {\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row5_col7, #T_d9ffa_row5_col21, #T_d9ffa_row19_col0 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row5_col9, #T_d9ffa_row9_col5 {\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row5_col10, #T_d9ffa_row11_col19 {\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row5_col11, #T_d9ffa_row5_col12, #T_d9ffa_row9_col11, #T_d9ffa_row22_col15 {\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row5_col13, #T_d9ffa_row15_col19, #T_d9ffa_row17_col11 {\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row5_col15, #T_d9ffa_row22_col5 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row5_col16, #T_d9ffa_row8_col9, #T_d9ffa_row12_col14 {\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row5_col18 {\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row5_col19, #T_d9ffa_row18_col2 {\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row6_col0, #T_d9ffa_row19_col21 {\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row6_col1 {\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row6_col2, #T_d9ffa_row21_col19 {\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row6_col4, #T_d9ffa_row6_col19 {\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row6_col5 {\n",
       "  background-color: #ebd3c6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row6_col7, #T_d9ffa_row19_col13, #T_d9ffa_row20_col10 {\n",
       "  background-color: #f2c9b4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row6_col8, #T_d9ffa_row18_col6, #T_d9ffa_row20_col8 {\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row6_col9, #T_d9ffa_row6_col12, #T_d9ffa_row8_col20 {\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row6_col10, #T_d9ffa_row14_col1 {\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row6_col11, #T_d9ffa_row17_col0 {\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row6_col13, #T_d9ffa_row10_col15 {\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row6_col14, #T_d9ffa_row14_col16 {\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row6_col15, #T_d9ffa_row16_col10 {\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row6_col16 {\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row6_col20, #T_d9ffa_row8_col7, #T_d9ffa_row15_col16, #T_d9ffa_row16_col2, #T_d9ffa_row20_col18 {\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row7_col2, #T_d9ffa_row22_col0 {\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row7_col3, #T_d9ffa_row16_col18 {\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row7_col8, #T_d9ffa_row16_col21 {\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row7_col14, #T_d9ffa_row9_col17 {\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row7_col15, #T_d9ffa_row8_col12, #T_d9ffa_row15_col7, #T_d9ffa_row15_col22 {\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row7_col16 {\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row7_col18, #T_d9ffa_row18_col7 {\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row7_col19, #T_d9ffa_row9_col19 {\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row7_col20, #T_d9ffa_row21_col16 {\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row7_col21, #T_d9ffa_row13_col19, #T_d9ffa_row16_col20 {\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row7_col22, #T_d9ffa_row14_col12, #T_d9ffa_row22_col7 {\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row8_col5, #T_d9ffa_row11_col16, #T_d9ffa_row22_col17 {\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row8_col6, #T_d9ffa_row18_col0 {\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row8_col10, #T_d9ffa_row10_col20, #T_d9ffa_row13_col18 {\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row8_col11, #T_d9ffa_row11_col14 {\n",
       "  background-color: #e67259;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row8_col18 {\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row9_col0, #T_d9ffa_row15_col4 {\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row9_col2, #T_d9ffa_row20_col6 {\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row9_col3, #T_d9ffa_row17_col20, #T_d9ffa_row18_col17, #T_d9ffa_row21_col15 {\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row9_col7, #T_d9ffa_row16_col1, #T_d9ffa_row18_col5, #T_d9ffa_row19_col1 {\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row9_col8 {\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row9_col10, #T_d9ffa_row17_col19 {\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row9_col12, #T_d9ffa_row12_col9 {\n",
       "  background-color: #cb3e38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row9_col13 {\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row9_col14, #T_d9ffa_row11_col8 {\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row9_col15, #T_d9ffa_row14_col0, #T_d9ffa_row15_col12 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row9_col16 {\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row9_col18, #T_d9ffa_row12_col0, #T_d9ffa_row14_col22 {\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row9_col21, #T_d9ffa_row17_col16 {\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row10_col0, #T_d9ffa_row11_col2, #T_d9ffa_row14_col7, #T_d9ffa_row17_col5 {\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row10_col3, #T_d9ffa_row16_col19, #T_d9ffa_row19_col16, #T_d9ffa_row21_col7 {\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row10_col4, #T_d9ffa_row11_col4 {\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row10_col5, #T_d9ffa_row15_col6 {\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row10_col6, #T_d9ffa_row19_col22 {\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row10_col7, #T_d9ffa_row18_col3 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row10_col8 {\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row10_col9, #T_d9ffa_row19_col9 {\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row10_col12, #T_d9ffa_row14_col5 {\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row10_col16, #T_d9ffa_row20_col16 {\n",
       "  background-color: #f5c2aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row10_col19, #T_d9ffa_row10_col22, #T_d9ffa_row15_col3, #T_d9ffa_row17_col9, #T_d9ffa_row21_col10 {\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row11_col0 {\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row11_col3, #T_d9ffa_row17_col7 {\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row11_col5, #T_d9ffa_row12_col5, #T_d9ffa_row12_col8 {\n",
       "  background-color: #d55042;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row11_col6 {\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row11_col9 {\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row11_col10, #T_d9ffa_row11_col20 {\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row11_col12, #T_d9ffa_row12_col11 {\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row11_col17, #T_d9ffa_row15_col14 {\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row12_col1, #T_d9ffa_row13_col10 {\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row12_col3, #T_d9ffa_row12_col10, #T_d9ffa_row12_col16 {\n",
       "  background-color: #f39577;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row12_col6, #T_d9ffa_row13_col1 {\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row12_col13 {\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row12_col15, #T_d9ffa_row12_col22, #T_d9ffa_row17_col6, #T_d9ffa_row22_col14 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row12_col19 {\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row12_col20, #T_d9ffa_row14_col6, #T_d9ffa_row16_col4 {\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row13_col2, #T_d9ffa_row16_col13, #T_d9ffa_row20_col14 {\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row13_col5 {\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row13_col12, #T_d9ffa_row17_col12 {\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row13_col16 {\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row13_col17 {\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row14_col2 {\n",
       "  background-color: #b3cdfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row14_col4, #T_d9ffa_row17_col22 {\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row14_col13, #T_d9ffa_row19_col2, #T_d9ffa_row22_col11, #T_d9ffa_row22_col12 {\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row14_col18 {\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row15_col0, #T_d9ffa_row16_col3, #T_d9ffa_row21_col0 {\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row15_col1, #T_d9ffa_row16_col5 {\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row15_col8, #T_d9ffa_row22_col3 {\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row15_col10 {\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row15_col18, #T_d9ffa_row18_col15 {\n",
       "  background-color: #c32e31;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row16_col6 {\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row17_col1, #T_d9ffa_row18_col13, #T_d9ffa_row21_col20 {\n",
       "  background-color: #f1ccb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row17_col13 {\n",
       "  background-color: #da5a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row17_col15 {\n",
       "  background-color: #f1cdba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row17_col21, #T_d9ffa_row21_col17 {\n",
       "  background-color: #ba162b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row18_col8, #T_d9ffa_row20_col15 {\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row18_col14 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row18_col22, #T_d9ffa_row22_col18 {\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row19_col4 {\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row19_col5, #T_d9ffa_row21_col18 {\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row19_col7 {\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row19_col12, #T_d9ffa_row19_col17, #T_d9ffa_row19_col18 {\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row19_col15 {\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row19_col20 {\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row20_col0 {\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row20_col3 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row20_col9 {\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row20_col12 {\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row20_col13, #T_d9ffa_row20_col17 {\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row20_col19 {\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row20_col21 {\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9ffa_row21_col22 {\n",
       "  background-color: #dc5d4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9ffa_row22_col21 {\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d9ffa\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d9ffa_level0_col0\" class=\"col_heading level0 col0\" >error</th>\n",
       "      <th id=\"T_d9ffa_level0_col1\" class=\"col_heading level0 col1\" >DN_HistogramMode_5</th>\n",
       "      <th id=\"T_d9ffa_level0_col2\" class=\"col_heading level0 col2\" >DN_HistogramMode_10</th>\n",
       "      <th id=\"T_d9ffa_level0_col3\" class=\"col_heading level0 col3\" >CO_f1ecac</th>\n",
       "      <th id=\"T_d9ffa_level0_col4\" class=\"col_heading level0 col4\" >CO_FirstMin_ac</th>\n",
       "      <th id=\"T_d9ffa_level0_col5\" class=\"col_heading level0 col5\" >CO_HistogramAMI_even_2_5</th>\n",
       "      <th id=\"T_d9ffa_level0_col6\" class=\"col_heading level0 col6\" >CO_trev_1_num</th>\n",
       "      <th id=\"T_d9ffa_level0_col7\" class=\"col_heading level0 col7\" >MD_hrv_classic_pnn40</th>\n",
       "      <th id=\"T_d9ffa_level0_col8\" class=\"col_heading level0 col8\" >SB_BinaryStats_mean_longstretch1</th>\n",
       "      <th id=\"T_d9ffa_level0_col9\" class=\"col_heading level0 col9\" >SB_TransitionMatrix_3ac_sumdiagcov</th>\n",
       "      <th id=\"T_d9ffa_level0_col10\" class=\"col_heading level0 col10\" >PD_PeriodicityWang_th0_01</th>\n",
       "      <th id=\"T_d9ffa_level0_col11\" class=\"col_heading level0 col11\" >CO_Embed2_Dist_tau_d_expfit_meandiff</th>\n",
       "      <th id=\"T_d9ffa_level0_col12\" class=\"col_heading level0 col12\" >IN_AutoMutualInfoStats_40_gaussian_fmmi</th>\n",
       "      <th id=\"T_d9ffa_level0_col13\" class=\"col_heading level0 col13\" >FC_LocalSimple_mean1_tauresrat</th>\n",
       "      <th id=\"T_d9ffa_level0_col14\" class=\"col_heading level0 col14\" >DN_OutlierInclude_p_001_mdrmd</th>\n",
       "      <th id=\"T_d9ffa_level0_col15\" class=\"col_heading level0 col15\" >DN_OutlierInclude_n_001_mdrmd</th>\n",
       "      <th id=\"T_d9ffa_level0_col16\" class=\"col_heading level0 col16\" >SP_Summaries_welch_rect_area_5_1</th>\n",
       "      <th id=\"T_d9ffa_level0_col17\" class=\"col_heading level0 col17\" >SB_BinaryStats_diff_longstretch0</th>\n",
       "      <th id=\"T_d9ffa_level0_col18\" class=\"col_heading level0 col18\" >SB_MotifThree_quantile_hh</th>\n",
       "      <th id=\"T_d9ffa_level0_col19\" class=\"col_heading level0 col19\" >SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1</th>\n",
       "      <th id=\"T_d9ffa_level0_col20\" class=\"col_heading level0 col20\" >SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1</th>\n",
       "      <th id=\"T_d9ffa_level0_col21\" class=\"col_heading level0 col21\" >SP_Summaries_welch_rect_centroid</th>\n",
       "      <th id=\"T_d9ffa_level0_col22\" class=\"col_heading level0 col22\" >FC_LocalSimple_mean3_stderr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row0\" class=\"row_heading level0 row0\" >error</th>\n",
       "      <td id=\"T_d9ffa_row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row0_col1\" class=\"data row0 col1\" >0.12</td>\n",
       "      <td id=\"T_d9ffa_row0_col2\" class=\"data row0 col2\" >0.23</td>\n",
       "      <td id=\"T_d9ffa_row0_col3\" class=\"data row0 col3\" >-0.49</td>\n",
       "      <td id=\"T_d9ffa_row0_col4\" class=\"data row0 col4\" >-0.34</td>\n",
       "      <td id=\"T_d9ffa_row0_col5\" class=\"data row0 col5\" >-0.38</td>\n",
       "      <td id=\"T_d9ffa_row0_col6\" class=\"data row0 col6\" >0.04</td>\n",
       "      <td id=\"T_d9ffa_row0_col7\" class=\"data row0 col7\" >0.10</td>\n",
       "      <td id=\"T_d9ffa_row0_col8\" class=\"data row0 col8\" >-0.54</td>\n",
       "      <td id=\"T_d9ffa_row0_col9\" class=\"data row0 col9\" >-0.40</td>\n",
       "      <td id=\"T_d9ffa_row0_col10\" class=\"data row0 col10\" >-0.20</td>\n",
       "      <td id=\"T_d9ffa_row0_col11\" class=\"data row0 col11\" >-0.41</td>\n",
       "      <td id=\"T_d9ffa_row0_col12\" class=\"data row0 col12\" >-0.42</td>\n",
       "      <td id=\"T_d9ffa_row0_col13\" class=\"data row0 col13\" >0.44</td>\n",
       "      <td id=\"T_d9ffa_row0_col14\" class=\"data row0 col14\" >-0.51</td>\n",
       "      <td id=\"T_d9ffa_row0_col15\" class=\"data row0 col15\" >0.35</td>\n",
       "      <td id=\"T_d9ffa_row0_col16\" class=\"data row0 col16\" >-0.06</td>\n",
       "      <td id=\"T_d9ffa_row0_col17\" class=\"data row0 col17\" >0.22</td>\n",
       "      <td id=\"T_d9ffa_row0_col18\" class=\"data row0 col18\" >0.17</td>\n",
       "      <td id=\"T_d9ffa_row0_col19\" class=\"data row0 col19\" >-0.35</td>\n",
       "      <td id=\"T_d9ffa_row0_col20\" class=\"data row0 col20\" >0.01</td>\n",
       "      <td id=\"T_d9ffa_row0_col21\" class=\"data row0 col21\" >0.35</td>\n",
       "      <td id=\"T_d9ffa_row0_col22\" class=\"data row0 col22\" >0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row1\" class=\"row_heading level0 row1\" >DN_HistogramMode_5</th>\n",
       "      <td id=\"T_d9ffa_row1_col0\" class=\"data row1 col0\" >0.12</td>\n",
       "      <td id=\"T_d9ffa_row1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row1_col2\" class=\"data row1 col2\" >0.98</td>\n",
       "      <td id=\"T_d9ffa_row1_col3\" class=\"data row1 col3\" >-0.20</td>\n",
       "      <td id=\"T_d9ffa_row1_col4\" class=\"data row1 col4\" >-0.12</td>\n",
       "      <td id=\"T_d9ffa_row1_col5\" class=\"data row1 col5\" >-0.85</td>\n",
       "      <td id=\"T_d9ffa_row1_col6\" class=\"data row1 col6\" >-0.18</td>\n",
       "      <td id=\"T_d9ffa_row1_col7\" class=\"data row1 col7\" >0.36</td>\n",
       "      <td id=\"T_d9ffa_row1_col8\" class=\"data row1 col8\" >-0.41</td>\n",
       "      <td id=\"T_d9ffa_row1_col9\" class=\"data row1 col9\" >-0.65</td>\n",
       "      <td id=\"T_d9ffa_row1_col10\" class=\"data row1 col10\" >0.20</td>\n",
       "      <td id=\"T_d9ffa_row1_col11\" class=\"data row1 col11\" >-0.51</td>\n",
       "      <td id=\"T_d9ffa_row1_col12\" class=\"data row1 col12\" >-0.48</td>\n",
       "      <td id=\"T_d9ffa_row1_col13\" class=\"data row1 col13\" >-0.10</td>\n",
       "      <td id=\"T_d9ffa_row1_col14\" class=\"data row1 col14\" >-0.20</td>\n",
       "      <td id=\"T_d9ffa_row1_col15\" class=\"data row1 col15\" >0.72</td>\n",
       "      <td id=\"T_d9ffa_row1_col16\" class=\"data row1 col16\" >-0.74</td>\n",
       "      <td id=\"T_d9ffa_row1_col17\" class=\"data row1 col17\" >0.25</td>\n",
       "      <td id=\"T_d9ffa_row1_col18\" class=\"data row1 col18\" >0.52</td>\n",
       "      <td id=\"T_d9ffa_row1_col19\" class=\"data row1 col19\" >-0.74</td>\n",
       "      <td id=\"T_d9ffa_row1_col20\" class=\"data row1 col20\" >-0.44</td>\n",
       "      <td id=\"T_d9ffa_row1_col21\" class=\"data row1 col21\" >0.38</td>\n",
       "      <td id=\"T_d9ffa_row1_col22\" class=\"data row1 col22\" >0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row2\" class=\"row_heading level0 row2\" >DN_HistogramMode_10</th>\n",
       "      <td id=\"T_d9ffa_row2_col0\" class=\"data row2 col0\" >0.23</td>\n",
       "      <td id=\"T_d9ffa_row2_col1\" class=\"data row2 col1\" >0.98</td>\n",
       "      <td id=\"T_d9ffa_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row2_col3\" class=\"data row2 col3\" >-0.21</td>\n",
       "      <td id=\"T_d9ffa_row2_col4\" class=\"data row2 col4\" >-0.02</td>\n",
       "      <td id=\"T_d9ffa_row2_col5\" class=\"data row2 col5\" >-0.83</td>\n",
       "      <td id=\"T_d9ffa_row2_col6\" class=\"data row2 col6\" >-0.12</td>\n",
       "      <td id=\"T_d9ffa_row2_col7\" class=\"data row2 col7\" >0.29</td>\n",
       "      <td id=\"T_d9ffa_row2_col8\" class=\"data row2 col8\" >-0.41</td>\n",
       "      <td id=\"T_d9ffa_row2_col9\" class=\"data row2 col9\" >-0.65</td>\n",
       "      <td id=\"T_d9ffa_row2_col10\" class=\"data row2 col10\" >0.32</td>\n",
       "      <td id=\"T_d9ffa_row2_col11\" class=\"data row2 col11\" >-0.43</td>\n",
       "      <td id=\"T_d9ffa_row2_col12\" class=\"data row2 col12\" >-0.42</td>\n",
       "      <td id=\"T_d9ffa_row2_col13\" class=\"data row2 col13\" >-0.07</td>\n",
       "      <td id=\"T_d9ffa_row2_col14\" class=\"data row2 col14\" >-0.17</td>\n",
       "      <td id=\"T_d9ffa_row2_col15\" class=\"data row2 col15\" >0.68</td>\n",
       "      <td id=\"T_d9ffa_row2_col16\" class=\"data row2 col16\" >-0.61</td>\n",
       "      <td id=\"T_d9ffa_row2_col17\" class=\"data row2 col17\" >0.20</td>\n",
       "      <td id=\"T_d9ffa_row2_col18\" class=\"data row2 col18\" >0.42</td>\n",
       "      <td id=\"T_d9ffa_row2_col19\" class=\"data row2 col19\" >-0.81</td>\n",
       "      <td id=\"T_d9ffa_row2_col20\" class=\"data row2 col20\" >-0.37</td>\n",
       "      <td id=\"T_d9ffa_row2_col21\" class=\"data row2 col21\" >0.34</td>\n",
       "      <td id=\"T_d9ffa_row2_col22\" class=\"data row2 col22\" >0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row3\" class=\"row_heading level0 row3\" >CO_f1ecac</th>\n",
       "      <td id=\"T_d9ffa_row3_col0\" class=\"data row3 col0\" >-0.49</td>\n",
       "      <td id=\"T_d9ffa_row3_col1\" class=\"data row3 col1\" >-0.20</td>\n",
       "      <td id=\"T_d9ffa_row3_col2\" class=\"data row3 col2\" >-0.21</td>\n",
       "      <td id=\"T_d9ffa_row3_col3\" class=\"data row3 col3\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row3_col4\" class=\"data row3 col4\" >0.49</td>\n",
       "      <td id=\"T_d9ffa_row3_col5\" class=\"data row3 col5\" >0.36</td>\n",
       "      <td id=\"T_d9ffa_row3_col6\" class=\"data row3 col6\" >0.11</td>\n",
       "      <td id=\"T_d9ffa_row3_col7\" class=\"data row3 col7\" >-0.43</td>\n",
       "      <td id=\"T_d9ffa_row3_col8\" class=\"data row3 col8\" >0.92</td>\n",
       "      <td id=\"T_d9ffa_row3_col9\" class=\"data row3 col9\" >0.39</td>\n",
       "      <td id=\"T_d9ffa_row3_col10\" class=\"data row3 col10\" >0.38</td>\n",
       "      <td id=\"T_d9ffa_row3_col11\" class=\"data row3 col11\" >0.42</td>\n",
       "      <td id=\"T_d9ffa_row3_col12\" class=\"data row3 col12\" >0.59</td>\n",
       "      <td id=\"T_d9ffa_row3_col13\" class=\"data row3 col13\" >-0.72</td>\n",
       "      <td id=\"T_d9ffa_row3_col14\" class=\"data row3 col14\" >0.42</td>\n",
       "      <td id=\"T_d9ffa_row3_col15\" class=\"data row3 col15\" >-0.38</td>\n",
       "      <td id=\"T_d9ffa_row3_col16\" class=\"data row3 col16\" >0.28</td>\n",
       "      <td id=\"T_d9ffa_row3_col17\" class=\"data row3 col17\" >-0.69</td>\n",
       "      <td id=\"T_d9ffa_row3_col18\" class=\"data row3 col18\" >-0.41</td>\n",
       "      <td id=\"T_d9ffa_row3_col19\" class=\"data row3 col19\" >0.18</td>\n",
       "      <td id=\"T_d9ffa_row3_col20\" class=\"data row3 col20\" >-0.17</td>\n",
       "      <td id=\"T_d9ffa_row3_col21\" class=\"data row3 col21\" >-0.72</td>\n",
       "      <td id=\"T_d9ffa_row3_col22\" class=\"data row3 col22\" >-0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row4\" class=\"row_heading level0 row4\" >CO_FirstMin_ac</th>\n",
       "      <td id=\"T_d9ffa_row4_col0\" class=\"data row4 col0\" >-0.34</td>\n",
       "      <td id=\"T_d9ffa_row4_col1\" class=\"data row4 col1\" >-0.12</td>\n",
       "      <td id=\"T_d9ffa_row4_col2\" class=\"data row4 col2\" >-0.02</td>\n",
       "      <td id=\"T_d9ffa_row4_col3\" class=\"data row4 col3\" >0.49</td>\n",
       "      <td id=\"T_d9ffa_row4_col4\" class=\"data row4 col4\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row4_col5\" class=\"data row4 col5\" >0.51</td>\n",
       "      <td id=\"T_d9ffa_row4_col6\" class=\"data row4 col6\" >-0.03</td>\n",
       "      <td id=\"T_d9ffa_row4_col7\" class=\"data row4 col7\" >-0.81</td>\n",
       "      <td id=\"T_d9ffa_row4_col8\" class=\"data row4 col8\" >0.65</td>\n",
       "      <td id=\"T_d9ffa_row4_col9\" class=\"data row4 col9\" >0.58</td>\n",
       "      <td id=\"T_d9ffa_row4_col10\" class=\"data row4 col10\" >0.90</td>\n",
       "      <td id=\"T_d9ffa_row4_col11\" class=\"data row4 col11\" >0.90</td>\n",
       "      <td id=\"T_d9ffa_row4_col12\" class=\"data row4 col12\" >0.88</td>\n",
       "      <td id=\"T_d9ffa_row4_col13\" class=\"data row4 col13\" >-0.47</td>\n",
       "      <td id=\"T_d9ffa_row4_col14\" class=\"data row4 col14\" >0.69</td>\n",
       "      <td id=\"T_d9ffa_row4_col15\" class=\"data row4 col15\" >-0.69</td>\n",
       "      <td id=\"T_d9ffa_row4_col16\" class=\"data row4 col16\" >0.48</td>\n",
       "      <td id=\"T_d9ffa_row4_col17\" class=\"data row4 col17\" >-0.44</td>\n",
       "      <td id=\"T_d9ffa_row4_col18\" class=\"data row4 col18\" >-0.87</td>\n",
       "      <td id=\"T_d9ffa_row4_col19\" class=\"data row4 col19\" >-0.29</td>\n",
       "      <td id=\"T_d9ffa_row4_col20\" class=\"data row4 col20\" >0.48</td>\n",
       "      <td id=\"T_d9ffa_row4_col21\" class=\"data row4 col21\" >-0.47</td>\n",
       "      <td id=\"T_d9ffa_row4_col22\" class=\"data row4 col22\" >-0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row5\" class=\"row_heading level0 row5\" >CO_HistogramAMI_even_2_5</th>\n",
       "      <td id=\"T_d9ffa_row5_col0\" class=\"data row5 col0\" >-0.38</td>\n",
       "      <td id=\"T_d9ffa_row5_col1\" class=\"data row5 col1\" >-0.85</td>\n",
       "      <td id=\"T_d9ffa_row5_col2\" class=\"data row5 col2\" >-0.83</td>\n",
       "      <td id=\"T_d9ffa_row5_col3\" class=\"data row5 col3\" >0.36</td>\n",
       "      <td id=\"T_d9ffa_row5_col4\" class=\"data row5 col4\" >0.51</td>\n",
       "      <td id=\"T_d9ffa_row5_col5\" class=\"data row5 col5\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row5_col6\" class=\"data row5 col6\" >0.17</td>\n",
       "      <td id=\"T_d9ffa_row5_col7\" class=\"data row5 col7\" >-0.67</td>\n",
       "      <td id=\"T_d9ffa_row5_col8\" class=\"data row5 col8\" >0.66</td>\n",
       "      <td id=\"T_d9ffa_row5_col9\" class=\"data row5 col9\" >0.93</td>\n",
       "      <td id=\"T_d9ffa_row5_col10\" class=\"data row5 col10\" >0.13</td>\n",
       "      <td id=\"T_d9ffa_row5_col11\" class=\"data row5 col11\" >0.82</td>\n",
       "      <td id=\"T_d9ffa_row5_col12\" class=\"data row5 col12\" >0.82</td>\n",
       "      <td id=\"T_d9ffa_row5_col13\" class=\"data row5 col13\" >-0.29</td>\n",
       "      <td id=\"T_d9ffa_row5_col14\" class=\"data row5 col14\" >0.62</td>\n",
       "      <td id=\"T_d9ffa_row5_col15\" class=\"data row5 col15\" >-0.89</td>\n",
       "      <td id=\"T_d9ffa_row5_col16\" class=\"data row5 col16\" >0.72</td>\n",
       "      <td id=\"T_d9ffa_row5_col17\" class=\"data row5 col17\" >-0.47</td>\n",
       "      <td id=\"T_d9ffa_row5_col18\" class=\"data row5 col18\" >-0.77</td>\n",
       "      <td id=\"T_d9ffa_row5_col19\" class=\"data row5 col19\" >0.43</td>\n",
       "      <td id=\"T_d9ffa_row5_col20\" class=\"data row5 col20\" >0.48</td>\n",
       "      <td id=\"T_d9ffa_row5_col21\" class=\"data row5 col21\" >-0.56</td>\n",
       "      <td id=\"T_d9ffa_row5_col22\" class=\"data row5 col22\" >-0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row6\" class=\"row_heading level0 row6\" >CO_trev_1_num</th>\n",
       "      <td id=\"T_d9ffa_row6_col0\" class=\"data row6 col0\" >0.04</td>\n",
       "      <td id=\"T_d9ffa_row6_col1\" class=\"data row6 col1\" >-0.18</td>\n",
       "      <td id=\"T_d9ffa_row6_col2\" class=\"data row6 col2\" >-0.12</td>\n",
       "      <td id=\"T_d9ffa_row6_col3\" class=\"data row6 col3\" >0.11</td>\n",
       "      <td id=\"T_d9ffa_row6_col4\" class=\"data row6 col4\" >-0.03</td>\n",
       "      <td id=\"T_d9ffa_row6_col5\" class=\"data row6 col5\" >0.17</td>\n",
       "      <td id=\"T_d9ffa_row6_col6\" class=\"data row6 col6\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row6_col7\" class=\"data row6 col7\" >0.25</td>\n",
       "      <td id=\"T_d9ffa_row6_col8\" class=\"data row6 col8\" >0.08</td>\n",
       "      <td id=\"T_d9ffa_row6_col9\" class=\"data row6 col9\" >0.03</td>\n",
       "      <td id=\"T_d9ffa_row6_col10\" class=\"data row6 col10\" >-0.05</td>\n",
       "      <td id=\"T_d9ffa_row6_col11\" class=\"data row6 col11\" >0.01</td>\n",
       "      <td id=\"T_d9ffa_row6_col12\" class=\"data row6 col12\" >-0.02</td>\n",
       "      <td id=\"T_d9ffa_row6_col13\" class=\"data row6 col13\" >-0.27</td>\n",
       "      <td id=\"T_d9ffa_row6_col14\" class=\"data row6 col14\" >0.52</td>\n",
       "      <td id=\"T_d9ffa_row6_col15\" class=\"data row6 col15\" >0.22</td>\n",
       "      <td id=\"T_d9ffa_row6_col16\" class=\"data row6 col16\" >0.55</td>\n",
       "      <td id=\"T_d9ffa_row6_col17\" class=\"data row6 col17\" >-0.70</td>\n",
       "      <td id=\"T_d9ffa_row6_col18\" class=\"data row6 col18\" >0.12</td>\n",
       "      <td id=\"T_d9ffa_row6_col19\" class=\"data row6 col19\" >-0.00</td>\n",
       "      <td id=\"T_d9ffa_row6_col20\" class=\"data row6 col20\" >-0.54</td>\n",
       "      <td id=\"T_d9ffa_row6_col21\" class=\"data row6 col21\" >-0.71</td>\n",
       "      <td id=\"T_d9ffa_row6_col22\" class=\"data row6 col22\" >-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row7\" class=\"row_heading level0 row7\" >MD_hrv_classic_pnn40</th>\n",
       "      <td id=\"T_d9ffa_row7_col0\" class=\"data row7 col0\" >0.10</td>\n",
       "      <td id=\"T_d9ffa_row7_col1\" class=\"data row7 col1\" >0.36</td>\n",
       "      <td id=\"T_d9ffa_row7_col2\" class=\"data row7 col2\" >0.29</td>\n",
       "      <td id=\"T_d9ffa_row7_col3\" class=\"data row7 col3\" >-0.43</td>\n",
       "      <td id=\"T_d9ffa_row7_col4\" class=\"data row7 col4\" >-0.81</td>\n",
       "      <td id=\"T_d9ffa_row7_col5\" class=\"data row7 col5\" >-0.67</td>\n",
       "      <td id=\"T_d9ffa_row7_col6\" class=\"data row7 col6\" >0.25</td>\n",
       "      <td id=\"T_d9ffa_row7_col7\" class=\"data row7 col7\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row7_col8\" class=\"data row7 col8\" >-0.68</td>\n",
       "      <td id=\"T_d9ffa_row7_col9\" class=\"data row7 col9\" >-0.80</td>\n",
       "      <td id=\"T_d9ffa_row7_col10\" class=\"data row7 col10\" >-0.56</td>\n",
       "      <td id=\"T_d9ffa_row7_col11\" class=\"data row7 col11\" >-0.85</td>\n",
       "      <td id=\"T_d9ffa_row7_col12\" class=\"data row7 col12\" >-0.91</td>\n",
       "      <td id=\"T_d9ffa_row7_col13\" class=\"data row7 col13\" >0.43</td>\n",
       "      <td id=\"T_d9ffa_row7_col14\" class=\"data row7 col14\" >-0.49</td>\n",
       "      <td id=\"T_d9ffa_row7_col15\" class=\"data row7 col15\" >0.83</td>\n",
       "      <td id=\"T_d9ffa_row7_col16\" class=\"data row7 col16\" >-0.37</td>\n",
       "      <td id=\"T_d9ffa_row7_col17\" class=\"data row7 col17\" >0.36</td>\n",
       "      <td id=\"T_d9ffa_row7_col18\" class=\"data row7 col18\" >0.94</td>\n",
       "      <td id=\"T_d9ffa_row7_col19\" class=\"data row7 col19\" >0.18</td>\n",
       "      <td id=\"T_d9ffa_row7_col20\" class=\"data row7 col20\" >-0.62</td>\n",
       "      <td id=\"T_d9ffa_row7_col21\" class=\"data row7 col21\" >0.32</td>\n",
       "      <td id=\"T_d9ffa_row7_col22\" class=\"data row7 col22\" >0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row8\" class=\"row_heading level0 row8\" >SB_BinaryStats_mean_longstretch1</th>\n",
       "      <td id=\"T_d9ffa_row8_col0\" class=\"data row8 col0\" >-0.54</td>\n",
       "      <td id=\"T_d9ffa_row8_col1\" class=\"data row8 col1\" >-0.41</td>\n",
       "      <td id=\"T_d9ffa_row8_col2\" class=\"data row8 col2\" >-0.41</td>\n",
       "      <td id=\"T_d9ffa_row8_col3\" class=\"data row8 col3\" >0.92</td>\n",
       "      <td id=\"T_d9ffa_row8_col4\" class=\"data row8 col4\" >0.65</td>\n",
       "      <td id=\"T_d9ffa_row8_col5\" class=\"data row8 col5\" >0.66</td>\n",
       "      <td id=\"T_d9ffa_row8_col6\" class=\"data row8 col6\" >0.08</td>\n",
       "      <td id=\"T_d9ffa_row8_col7\" class=\"data row8 col7\" >-0.68</td>\n",
       "      <td id=\"T_d9ffa_row8_col8\" class=\"data row8 col8\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row8_col9\" class=\"data row8 col9\" >0.72</td>\n",
       "      <td id=\"T_d9ffa_row8_col10\" class=\"data row8 col10\" >0.41</td>\n",
       "      <td id=\"T_d9ffa_row8_col11\" class=\"data row8 col11\" >0.68</td>\n",
       "      <td id=\"T_d9ffa_row8_col12\" class=\"data row8 col12\" >0.83</td>\n",
       "      <td id=\"T_d9ffa_row8_col13\" class=\"data row8 col13\" >-0.75</td>\n",
       "      <td id=\"T_d9ffa_row8_col14\" class=\"data row8 col14\" >0.62</td>\n",
       "      <td id=\"T_d9ffa_row8_col15\" class=\"data row8 col15\" >-0.66</td>\n",
       "      <td id=\"T_d9ffa_row8_col16\" class=\"data row8 col16\" >0.41</td>\n",
       "      <td id=\"T_d9ffa_row8_col17\" class=\"data row8 col17\" >-0.72</td>\n",
       "      <td id=\"T_d9ffa_row8_col18\" class=\"data row8 col18\" >-0.66</td>\n",
       "      <td id=\"T_d9ffa_row8_col19\" class=\"data row8 col19\" >0.19</td>\n",
       "      <td id=\"T_d9ffa_row8_col20\" class=\"data row8 col20\" >0.08</td>\n",
       "      <td id=\"T_d9ffa_row8_col21\" class=\"data row8 col21\" >-0.75</td>\n",
       "      <td id=\"T_d9ffa_row8_col22\" class=\"data row8 col22\" >-0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row9\" class=\"row_heading level0 row9\" >SB_TransitionMatrix_3ac_sumdiagcov</th>\n",
       "      <td id=\"T_d9ffa_row9_col0\" class=\"data row9 col0\" >-0.40</td>\n",
       "      <td id=\"T_d9ffa_row9_col1\" class=\"data row9 col1\" >-0.65</td>\n",
       "      <td id=\"T_d9ffa_row9_col2\" class=\"data row9 col2\" >-0.65</td>\n",
       "      <td id=\"T_d9ffa_row9_col3\" class=\"data row9 col3\" >0.39</td>\n",
       "      <td id=\"T_d9ffa_row9_col4\" class=\"data row9 col4\" >0.58</td>\n",
       "      <td id=\"T_d9ffa_row9_col5\" class=\"data row9 col5\" >0.93</td>\n",
       "      <td id=\"T_d9ffa_row9_col6\" class=\"data row9 col6\" >0.03</td>\n",
       "      <td id=\"T_d9ffa_row9_col7\" class=\"data row9 col7\" >-0.80</td>\n",
       "      <td id=\"T_d9ffa_row9_col8\" class=\"data row9 col8\" >0.72</td>\n",
       "      <td id=\"T_d9ffa_row9_col9\" class=\"data row9 col9\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row9_col10\" class=\"data row9 col10\" >0.18</td>\n",
       "      <td id=\"T_d9ffa_row9_col11\" class=\"data row9 col11\" >0.82</td>\n",
       "      <td id=\"T_d9ffa_row9_col12\" class=\"data row9 col12\" >0.88</td>\n",
       "      <td id=\"T_d9ffa_row9_col13\" class=\"data row9 col13\" >-0.51</td>\n",
       "      <td id=\"T_d9ffa_row9_col14\" class=\"data row9 col14\" >0.68</td>\n",
       "      <td id=\"T_d9ffa_row9_col15\" class=\"data row9 col15\" >-0.85</td>\n",
       "      <td id=\"T_d9ffa_row9_col16\" class=\"data row9 col16\" >0.48</td>\n",
       "      <td id=\"T_d9ffa_row9_col17\" class=\"data row9 col17\" >-0.49</td>\n",
       "      <td id=\"T_d9ffa_row9_col18\" class=\"data row9 col18\" >-0.79</td>\n",
       "      <td id=\"T_d9ffa_row9_col19\" class=\"data row9 col19\" >0.18</td>\n",
       "      <td id=\"T_d9ffa_row9_col20\" class=\"data row9 col20\" >0.43</td>\n",
       "      <td id=\"T_d9ffa_row9_col21\" class=\"data row9 col21\" >-0.50</td>\n",
       "      <td id=\"T_d9ffa_row9_col22\" class=\"data row9 col22\" >-0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row10\" class=\"row_heading level0 row10\" >PD_PeriodicityWang_th0_01</th>\n",
       "      <td id=\"T_d9ffa_row10_col0\" class=\"data row10 col0\" >-0.20</td>\n",
       "      <td id=\"T_d9ffa_row10_col1\" class=\"data row10 col1\" >0.20</td>\n",
       "      <td id=\"T_d9ffa_row10_col2\" class=\"data row10 col2\" >0.32</td>\n",
       "      <td id=\"T_d9ffa_row10_col3\" class=\"data row10 col3\" >0.38</td>\n",
       "      <td id=\"T_d9ffa_row10_col4\" class=\"data row10 col4\" >0.90</td>\n",
       "      <td id=\"T_d9ffa_row10_col5\" class=\"data row10 col5\" >0.13</td>\n",
       "      <td id=\"T_d9ffa_row10_col6\" class=\"data row10 col6\" >-0.05</td>\n",
       "      <td id=\"T_d9ffa_row10_col7\" class=\"data row10 col7\" >-0.56</td>\n",
       "      <td id=\"T_d9ffa_row10_col8\" class=\"data row10 col8\" >0.41</td>\n",
       "      <td id=\"T_d9ffa_row10_col9\" class=\"data row10 col9\" >0.18</td>\n",
       "      <td id=\"T_d9ffa_row10_col10\" class=\"data row10 col10\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row10_col11\" class=\"data row10 col11\" >0.66</td>\n",
       "      <td id=\"T_d9ffa_row10_col12\" class=\"data row10 col12\" >0.61</td>\n",
       "      <td id=\"T_d9ffa_row10_col13\" class=\"data row10 col13\" >-0.30</td>\n",
       "      <td id=\"T_d9ffa_row10_col14\" class=\"data row10 col14\" >0.48</td>\n",
       "      <td id=\"T_d9ffa_row10_col15\" class=\"data row10 col15\" >-0.38</td>\n",
       "      <td id=\"T_d9ffa_row10_col16\" class=\"data row10 col16\" >0.33</td>\n",
       "      <td id=\"T_d9ffa_row10_col17\" class=\"data row10 col17\" >-0.29</td>\n",
       "      <td id=\"T_d9ffa_row10_col18\" class=\"data row10 col18\" >-0.63</td>\n",
       "      <td id=\"T_d9ffa_row10_col19\" class=\"data row10 col19\" >-0.45</td>\n",
       "      <td id=\"T_d9ffa_row10_col20\" class=\"data row10 col20\" >0.36</td>\n",
       "      <td id=\"T_d9ffa_row10_col21\" class=\"data row10 col21\" >-0.31</td>\n",
       "      <td id=\"T_d9ffa_row10_col22\" class=\"data row10 col22\" >-0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row11\" class=\"row_heading level0 row11\" >CO_Embed2_Dist_tau_d_expfit_meandiff</th>\n",
       "      <td id=\"T_d9ffa_row11_col0\" class=\"data row11 col0\" >-0.41</td>\n",
       "      <td id=\"T_d9ffa_row11_col1\" class=\"data row11 col1\" >-0.51</td>\n",
       "      <td id=\"T_d9ffa_row11_col2\" class=\"data row11 col2\" >-0.43</td>\n",
       "      <td id=\"T_d9ffa_row11_col3\" class=\"data row11 col3\" >0.42</td>\n",
       "      <td id=\"T_d9ffa_row11_col4\" class=\"data row11 col4\" >0.90</td>\n",
       "      <td id=\"T_d9ffa_row11_col5\" class=\"data row11 col5\" >0.82</td>\n",
       "      <td id=\"T_d9ffa_row11_col6\" class=\"data row11 col6\" >0.01</td>\n",
       "      <td id=\"T_d9ffa_row11_col7\" class=\"data row11 col7\" >-0.85</td>\n",
       "      <td id=\"T_d9ffa_row11_col8\" class=\"data row11 col8\" >0.68</td>\n",
       "      <td id=\"T_d9ffa_row11_col9\" class=\"data row11 col9\" >0.82</td>\n",
       "      <td id=\"T_d9ffa_row11_col10\" class=\"data row11 col10\" >0.66</td>\n",
       "      <td id=\"T_d9ffa_row11_col11\" class=\"data row11 col11\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row11_col12\" class=\"data row11 col12\" >0.96</td>\n",
       "      <td id=\"T_d9ffa_row11_col13\" class=\"data row11 col13\" >-0.36</td>\n",
       "      <td id=\"T_d9ffa_row11_col14\" class=\"data row11 col14\" >0.71</td>\n",
       "      <td id=\"T_d9ffa_row11_col15\" class=\"data row11 col15\" >-0.90</td>\n",
       "      <td id=\"T_d9ffa_row11_col16\" class=\"data row11 col16\" >0.67</td>\n",
       "      <td id=\"T_d9ffa_row11_col17\" class=\"data row11 col17\" >-0.43</td>\n",
       "      <td id=\"T_d9ffa_row11_col18\" class=\"data row11 col18\" >-0.95</td>\n",
       "      <td id=\"T_d9ffa_row11_col19\" class=\"data row11 col19\" >0.04</td>\n",
       "      <td id=\"T_d9ffa_row11_col20\" class=\"data row11 col20\" >0.63</td>\n",
       "      <td id=\"T_d9ffa_row11_col21\" class=\"data row11 col21\" >-0.51</td>\n",
       "      <td id=\"T_d9ffa_row11_col22\" class=\"data row11 col22\" >-0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row12\" class=\"row_heading level0 row12\" >IN_AutoMutualInfoStats_40_gaussian_fmmi</th>\n",
       "      <td id=\"T_d9ffa_row12_col0\" class=\"data row12 col0\" >-0.42</td>\n",
       "      <td id=\"T_d9ffa_row12_col1\" class=\"data row12 col1\" >-0.48</td>\n",
       "      <td id=\"T_d9ffa_row12_col2\" class=\"data row12 col2\" >-0.42</td>\n",
       "      <td id=\"T_d9ffa_row12_col3\" class=\"data row12 col3\" >0.59</td>\n",
       "      <td id=\"T_d9ffa_row12_col4\" class=\"data row12 col4\" >0.88</td>\n",
       "      <td id=\"T_d9ffa_row12_col5\" class=\"data row12 col5\" >0.82</td>\n",
       "      <td id=\"T_d9ffa_row12_col6\" class=\"data row12 col6\" >-0.02</td>\n",
       "      <td id=\"T_d9ffa_row12_col7\" class=\"data row12 col7\" >-0.91</td>\n",
       "      <td id=\"T_d9ffa_row12_col8\" class=\"data row12 col8\" >0.83</td>\n",
       "      <td id=\"T_d9ffa_row12_col9\" class=\"data row12 col9\" >0.88</td>\n",
       "      <td id=\"T_d9ffa_row12_col10\" class=\"data row12 col10\" >0.61</td>\n",
       "      <td id=\"T_d9ffa_row12_col11\" class=\"data row12 col11\" >0.96</td>\n",
       "      <td id=\"T_d9ffa_row12_col12\" class=\"data row12 col12\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row12_col13\" class=\"data row12 col13\" >-0.55</td>\n",
       "      <td id=\"T_d9ffa_row12_col14\" class=\"data row12 col14\" >0.72</td>\n",
       "      <td id=\"T_d9ffa_row12_col15\" class=\"data row12 col15\" >-0.89</td>\n",
       "      <td id=\"T_d9ffa_row12_col16\" class=\"data row12 col16\" >0.56</td>\n",
       "      <td id=\"T_d9ffa_row12_col17\" class=\"data row12 col17\" >-0.54</td>\n",
       "      <td id=\"T_d9ffa_row12_col18\" class=\"data row12 col18\" >-0.94</td>\n",
       "      <td id=\"T_d9ffa_row12_col19\" class=\"data row12 col19\" >0.01</td>\n",
       "      <td id=\"T_d9ffa_row12_col20\" class=\"data row12 col20\" >0.51</td>\n",
       "      <td id=\"T_d9ffa_row12_col21\" class=\"data row12 col21\" >-0.58</td>\n",
       "      <td id=\"T_d9ffa_row12_col22\" class=\"data row12 col22\" >-0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row13\" class=\"row_heading level0 row13\" >FC_LocalSimple_mean1_tauresrat</th>\n",
       "      <td id=\"T_d9ffa_row13_col0\" class=\"data row13 col0\" >0.44</td>\n",
       "      <td id=\"T_d9ffa_row13_col1\" class=\"data row13 col1\" >-0.10</td>\n",
       "      <td id=\"T_d9ffa_row13_col2\" class=\"data row13 col2\" >-0.07</td>\n",
       "      <td id=\"T_d9ffa_row13_col3\" class=\"data row13 col3\" >-0.72</td>\n",
       "      <td id=\"T_d9ffa_row13_col4\" class=\"data row13 col4\" >-0.47</td>\n",
       "      <td id=\"T_d9ffa_row13_col5\" class=\"data row13 col5\" >-0.29</td>\n",
       "      <td id=\"T_d9ffa_row13_col6\" class=\"data row13 col6\" >-0.27</td>\n",
       "      <td id=\"T_d9ffa_row13_col7\" class=\"data row13 col7\" >0.43</td>\n",
       "      <td id=\"T_d9ffa_row13_col8\" class=\"data row13 col8\" >-0.75</td>\n",
       "      <td id=\"T_d9ffa_row13_col9\" class=\"data row13 col9\" >-0.51</td>\n",
       "      <td id=\"T_d9ffa_row13_col10\" class=\"data row13 col10\" >-0.30</td>\n",
       "      <td id=\"T_d9ffa_row13_col11\" class=\"data row13 col11\" >-0.36</td>\n",
       "      <td id=\"T_d9ffa_row13_col12\" class=\"data row13 col12\" >-0.55</td>\n",
       "      <td id=\"T_d9ffa_row13_col13\" class=\"data row13 col13\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row13_col14\" class=\"data row13 col14\" >-0.73</td>\n",
       "      <td id=\"T_d9ffa_row13_col15\" class=\"data row13 col15\" >0.17</td>\n",
       "      <td id=\"T_d9ffa_row13_col16\" class=\"data row13 col16\" >-0.02</td>\n",
       "      <td id=\"T_d9ffa_row13_col17\" class=\"data row13 col17\" >0.80</td>\n",
       "      <td id=\"T_d9ffa_row13_col18\" class=\"data row13 col18\" >0.29</td>\n",
       "      <td id=\"T_d9ffa_row13_col19\" class=\"data row13 col19\" >0.31</td>\n",
       "      <td id=\"T_d9ffa_row13_col20\" class=\"data row13 col20\" >0.39</td>\n",
       "      <td id=\"T_d9ffa_row13_col21\" class=\"data row13 col21\" >0.70</td>\n",
       "      <td id=\"T_d9ffa_row13_col22\" class=\"data row13 col22\" >0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row14\" class=\"row_heading level0 row14\" >DN_OutlierInclude_p_001_mdrmd</th>\n",
       "      <td id=\"T_d9ffa_row14_col0\" class=\"data row14 col0\" >-0.51</td>\n",
       "      <td id=\"T_d9ffa_row14_col1\" class=\"data row14 col1\" >-0.20</td>\n",
       "      <td id=\"T_d9ffa_row14_col2\" class=\"data row14 col2\" >-0.17</td>\n",
       "      <td id=\"T_d9ffa_row14_col3\" class=\"data row14 col3\" >0.42</td>\n",
       "      <td id=\"T_d9ffa_row14_col4\" class=\"data row14 col4\" >0.69</td>\n",
       "      <td id=\"T_d9ffa_row14_col5\" class=\"data row14 col5\" >0.62</td>\n",
       "      <td id=\"T_d9ffa_row14_col6\" class=\"data row14 col6\" >0.52</td>\n",
       "      <td id=\"T_d9ffa_row14_col7\" class=\"data row14 col7\" >-0.49</td>\n",
       "      <td id=\"T_d9ffa_row14_col8\" class=\"data row14 col8\" >0.62</td>\n",
       "      <td id=\"T_d9ffa_row14_col9\" class=\"data row14 col9\" >0.68</td>\n",
       "      <td id=\"T_d9ffa_row14_col10\" class=\"data row14 col10\" >0.48</td>\n",
       "      <td id=\"T_d9ffa_row14_col11\" class=\"data row14 col11\" >0.71</td>\n",
       "      <td id=\"T_d9ffa_row14_col12\" class=\"data row14 col12\" >0.72</td>\n",
       "      <td id=\"T_d9ffa_row14_col13\" class=\"data row14 col13\" >-0.73</td>\n",
       "      <td id=\"T_d9ffa_row14_col14\" class=\"data row14 col14\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row14_col15\" class=\"data row14 col15\" >-0.44</td>\n",
       "      <td id=\"T_d9ffa_row14_col16\" class=\"data row14 col16\" >0.51</td>\n",
       "      <td id=\"T_d9ffa_row14_col17\" class=\"data row14 col17\" >-0.78</td>\n",
       "      <td id=\"T_d9ffa_row14_col18\" class=\"data row14 col18\" >-0.54</td>\n",
       "      <td id=\"T_d9ffa_row14_col19\" class=\"data row14 col19\" >-0.20</td>\n",
       "      <td id=\"T_d9ffa_row14_col20\" class=\"data row14 col20\" >-0.03</td>\n",
       "      <td id=\"T_d9ffa_row14_col21\" class=\"data row14 col21\" >-0.78</td>\n",
       "      <td id=\"T_d9ffa_row14_col22\" class=\"data row14 col22\" >-0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row15\" class=\"row_heading level0 row15\" >DN_OutlierInclude_n_001_mdrmd</th>\n",
       "      <td id=\"T_d9ffa_row15_col0\" class=\"data row15 col0\" >0.35</td>\n",
       "      <td id=\"T_d9ffa_row15_col1\" class=\"data row15 col1\" >0.72</td>\n",
       "      <td id=\"T_d9ffa_row15_col2\" class=\"data row15 col2\" >0.68</td>\n",
       "      <td id=\"T_d9ffa_row15_col3\" class=\"data row15 col3\" >-0.38</td>\n",
       "      <td id=\"T_d9ffa_row15_col4\" class=\"data row15 col4\" >-0.69</td>\n",
       "      <td id=\"T_d9ffa_row15_col5\" class=\"data row15 col5\" >-0.89</td>\n",
       "      <td id=\"T_d9ffa_row15_col6\" class=\"data row15 col6\" >0.22</td>\n",
       "      <td id=\"T_d9ffa_row15_col7\" class=\"data row15 col7\" >0.83</td>\n",
       "      <td id=\"T_d9ffa_row15_col8\" class=\"data row15 col8\" >-0.66</td>\n",
       "      <td id=\"T_d9ffa_row15_col9\" class=\"data row15 col9\" >-0.85</td>\n",
       "      <td id=\"T_d9ffa_row15_col10\" class=\"data row15 col10\" >-0.38</td>\n",
       "      <td id=\"T_d9ffa_row15_col11\" class=\"data row15 col11\" >-0.90</td>\n",
       "      <td id=\"T_d9ffa_row15_col12\" class=\"data row15 col12\" >-0.89</td>\n",
       "      <td id=\"T_d9ffa_row15_col13\" class=\"data row15 col13\" >0.17</td>\n",
       "      <td id=\"T_d9ffa_row15_col14\" class=\"data row15 col14\" >-0.44</td>\n",
       "      <td id=\"T_d9ffa_row15_col15\" class=\"data row15 col15\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row15_col16\" class=\"data row15 col16\" >-0.60</td>\n",
       "      <td id=\"T_d9ffa_row15_col17\" class=\"data row15 col17\" >0.23</td>\n",
       "      <td id=\"T_d9ffa_row15_col18\" class=\"data row15 col18\" >0.92</td>\n",
       "      <td id=\"T_d9ffa_row15_col19\" class=\"data row15 col19\" >-0.33</td>\n",
       "      <td id=\"T_d9ffa_row15_col20\" class=\"data row15 col20\" >-0.76</td>\n",
       "      <td id=\"T_d9ffa_row15_col21\" class=\"data row15 col21\" >0.32</td>\n",
       "      <td id=\"T_d9ffa_row15_col22\" class=\"data row15 col22\" >0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row16\" class=\"row_heading level0 row16\" >SP_Summaries_welch_rect_area_5_1</th>\n",
       "      <td id=\"T_d9ffa_row16_col0\" class=\"data row16 col0\" >-0.06</td>\n",
       "      <td id=\"T_d9ffa_row16_col1\" class=\"data row16 col1\" >-0.74</td>\n",
       "      <td id=\"T_d9ffa_row16_col2\" class=\"data row16 col2\" >-0.61</td>\n",
       "      <td id=\"T_d9ffa_row16_col3\" class=\"data row16 col3\" >0.28</td>\n",
       "      <td id=\"T_d9ffa_row16_col4\" class=\"data row16 col4\" >0.48</td>\n",
       "      <td id=\"T_d9ffa_row16_col5\" class=\"data row16 col5\" >0.72</td>\n",
       "      <td id=\"T_d9ffa_row16_col6\" class=\"data row16 col6\" >0.55</td>\n",
       "      <td id=\"T_d9ffa_row16_col7\" class=\"data row16 col7\" >-0.37</td>\n",
       "      <td id=\"T_d9ffa_row16_col8\" class=\"data row16 col8\" >0.41</td>\n",
       "      <td id=\"T_d9ffa_row16_col9\" class=\"data row16 col9\" >0.48</td>\n",
       "      <td id=\"T_d9ffa_row16_col10\" class=\"data row16 col10\" >0.33</td>\n",
       "      <td id=\"T_d9ffa_row16_col11\" class=\"data row16 col11\" >0.67</td>\n",
       "      <td id=\"T_d9ffa_row16_col12\" class=\"data row16 col12\" >0.56</td>\n",
       "      <td id=\"T_d9ffa_row16_col13\" class=\"data row16 col13\" >-0.02</td>\n",
       "      <td id=\"T_d9ffa_row16_col14\" class=\"data row16 col14\" >0.51</td>\n",
       "      <td id=\"T_d9ffa_row16_col15\" class=\"data row16 col15\" >-0.60</td>\n",
       "      <td id=\"T_d9ffa_row16_col16\" class=\"data row16 col16\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row16_col17\" class=\"data row16 col17\" >-0.53</td>\n",
       "      <td id=\"T_d9ffa_row16_col18\" class=\"data row16 col18\" >-0.62</td>\n",
       "      <td id=\"T_d9ffa_row16_col19\" class=\"data row16 col19\" >0.35</td>\n",
       "      <td id=\"T_d9ffa_row16_col20\" class=\"data row16 col20\" >0.33</td>\n",
       "      <td id=\"T_d9ffa_row16_col21\" class=\"data row16 col21\" >-0.67</td>\n",
       "      <td id=\"T_d9ffa_row16_col22\" class=\"data row16 col22\" >-0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row17\" class=\"row_heading level0 row17\" >SB_BinaryStats_diff_longstretch0</th>\n",
       "      <td id=\"T_d9ffa_row17_col0\" class=\"data row17 col0\" >0.22</td>\n",
       "      <td id=\"T_d9ffa_row17_col1\" class=\"data row17 col1\" >0.25</td>\n",
       "      <td id=\"T_d9ffa_row17_col2\" class=\"data row17 col2\" >0.20</td>\n",
       "      <td id=\"T_d9ffa_row17_col3\" class=\"data row17 col3\" >-0.69</td>\n",
       "      <td id=\"T_d9ffa_row17_col4\" class=\"data row17 col4\" >-0.44</td>\n",
       "      <td id=\"T_d9ffa_row17_col5\" class=\"data row17 col5\" >-0.47</td>\n",
       "      <td id=\"T_d9ffa_row17_col6\" class=\"data row17 col6\" >-0.70</td>\n",
       "      <td id=\"T_d9ffa_row17_col7\" class=\"data row17 col7\" >0.36</td>\n",
       "      <td id=\"T_d9ffa_row17_col8\" class=\"data row17 col8\" >-0.72</td>\n",
       "      <td id=\"T_d9ffa_row17_col9\" class=\"data row17 col9\" >-0.49</td>\n",
       "      <td id=\"T_d9ffa_row17_col10\" class=\"data row17 col10\" >-0.29</td>\n",
       "      <td id=\"T_d9ffa_row17_col11\" class=\"data row17 col11\" >-0.43</td>\n",
       "      <td id=\"T_d9ffa_row17_col12\" class=\"data row17 col12\" >-0.54</td>\n",
       "      <td id=\"T_d9ffa_row17_col13\" class=\"data row17 col13\" >0.80</td>\n",
       "      <td id=\"T_d9ffa_row17_col14\" class=\"data row17 col14\" >-0.78</td>\n",
       "      <td id=\"T_d9ffa_row17_col15\" class=\"data row17 col15\" >0.23</td>\n",
       "      <td id=\"T_d9ffa_row17_col16\" class=\"data row17 col16\" >-0.53</td>\n",
       "      <td id=\"T_d9ffa_row17_col17\" class=\"data row17 col17\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row17_col18\" class=\"data row17 col18\" >0.37</td>\n",
       "      <td id=\"T_d9ffa_row17_col19\" class=\"data row17 col19\" >0.09</td>\n",
       "      <td id=\"T_d9ffa_row17_col20\" class=\"data row17 col20\" >0.37</td>\n",
       "      <td id=\"T_d9ffa_row17_col21\" class=\"data row17 col21\" >0.97</td>\n",
       "      <td id=\"T_d9ffa_row17_col22\" class=\"data row17 col22\" >0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row18\" class=\"row_heading level0 row18\" >SB_MotifThree_quantile_hh</th>\n",
       "      <td id=\"T_d9ffa_row18_col0\" class=\"data row18 col0\" >0.17</td>\n",
       "      <td id=\"T_d9ffa_row18_col1\" class=\"data row18 col1\" >0.52</td>\n",
       "      <td id=\"T_d9ffa_row18_col2\" class=\"data row18 col2\" >0.42</td>\n",
       "      <td id=\"T_d9ffa_row18_col3\" class=\"data row18 col3\" >-0.41</td>\n",
       "      <td id=\"T_d9ffa_row18_col4\" class=\"data row18 col4\" >-0.87</td>\n",
       "      <td id=\"T_d9ffa_row18_col5\" class=\"data row18 col5\" >-0.77</td>\n",
       "      <td id=\"T_d9ffa_row18_col6\" class=\"data row18 col6\" >0.12</td>\n",
       "      <td id=\"T_d9ffa_row18_col7\" class=\"data row18 col7\" >0.94</td>\n",
       "      <td id=\"T_d9ffa_row18_col8\" class=\"data row18 col8\" >-0.66</td>\n",
       "      <td id=\"T_d9ffa_row18_col9\" class=\"data row18 col9\" >-0.79</td>\n",
       "      <td id=\"T_d9ffa_row18_col10\" class=\"data row18 col10\" >-0.63</td>\n",
       "      <td id=\"T_d9ffa_row18_col11\" class=\"data row18 col11\" >-0.95</td>\n",
       "      <td id=\"T_d9ffa_row18_col12\" class=\"data row18 col12\" >-0.94</td>\n",
       "      <td id=\"T_d9ffa_row18_col13\" class=\"data row18 col13\" >0.29</td>\n",
       "      <td id=\"T_d9ffa_row18_col14\" class=\"data row18 col14\" >-0.54</td>\n",
       "      <td id=\"T_d9ffa_row18_col15\" class=\"data row18 col15\" >0.92</td>\n",
       "      <td id=\"T_d9ffa_row18_col16\" class=\"data row18 col16\" >-0.62</td>\n",
       "      <td id=\"T_d9ffa_row18_col17\" class=\"data row18 col17\" >0.37</td>\n",
       "      <td id=\"T_d9ffa_row18_col18\" class=\"data row18 col18\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row18_col19\" class=\"data row18 col19\" >0.01</td>\n",
       "      <td id=\"T_d9ffa_row18_col20\" class=\"data row18 col20\" >-0.71</td>\n",
       "      <td id=\"T_d9ffa_row18_col21\" class=\"data row18 col21\" >0.41</td>\n",
       "      <td id=\"T_d9ffa_row18_col22\" class=\"data row18 col22\" >0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row19\" class=\"row_heading level0 row19\" >SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1</th>\n",
       "      <td id=\"T_d9ffa_row19_col0\" class=\"data row19 col0\" >-0.35</td>\n",
       "      <td id=\"T_d9ffa_row19_col1\" class=\"data row19 col1\" >-0.74</td>\n",
       "      <td id=\"T_d9ffa_row19_col2\" class=\"data row19 col2\" >-0.81</td>\n",
       "      <td id=\"T_d9ffa_row19_col3\" class=\"data row19 col3\" >0.18</td>\n",
       "      <td id=\"T_d9ffa_row19_col4\" class=\"data row19 col4\" >-0.29</td>\n",
       "      <td id=\"T_d9ffa_row19_col5\" class=\"data row19 col5\" >0.43</td>\n",
       "      <td id=\"T_d9ffa_row19_col6\" class=\"data row19 col6\" >-0.00</td>\n",
       "      <td id=\"T_d9ffa_row19_col7\" class=\"data row19 col7\" >0.18</td>\n",
       "      <td id=\"T_d9ffa_row19_col8\" class=\"data row19 col8\" >0.19</td>\n",
       "      <td id=\"T_d9ffa_row19_col9\" class=\"data row19 col9\" >0.18</td>\n",
       "      <td id=\"T_d9ffa_row19_col10\" class=\"data row19 col10\" >-0.45</td>\n",
       "      <td id=\"T_d9ffa_row19_col11\" class=\"data row19 col11\" >0.04</td>\n",
       "      <td id=\"T_d9ffa_row19_col12\" class=\"data row19 col12\" >0.01</td>\n",
       "      <td id=\"T_d9ffa_row19_col13\" class=\"data row19 col13\" >0.31</td>\n",
       "      <td id=\"T_d9ffa_row19_col14\" class=\"data row19 col14\" >-0.20</td>\n",
       "      <td id=\"T_d9ffa_row19_col15\" class=\"data row19 col15\" >-0.33</td>\n",
       "      <td id=\"T_d9ffa_row19_col16\" class=\"data row19 col16\" >0.35</td>\n",
       "      <td id=\"T_d9ffa_row19_col17\" class=\"data row19 col17\" >0.09</td>\n",
       "      <td id=\"T_d9ffa_row19_col18\" class=\"data row19 col18\" >0.01</td>\n",
       "      <td id=\"T_d9ffa_row19_col19\" class=\"data row19 col19\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row19_col20\" class=\"data row19 col20\" >0.16</td>\n",
       "      <td id=\"T_d9ffa_row19_col21\" class=\"data row19 col21\" >-0.11</td>\n",
       "      <td id=\"T_d9ffa_row19_col22\" class=\"data row19 col22\" >-0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row20\" class=\"row_heading level0 row20\" >SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1</th>\n",
       "      <td id=\"T_d9ffa_row20_col0\" class=\"data row20 col0\" >0.01</td>\n",
       "      <td id=\"T_d9ffa_row20_col1\" class=\"data row20 col1\" >-0.44</td>\n",
       "      <td id=\"T_d9ffa_row20_col2\" class=\"data row20 col2\" >-0.37</td>\n",
       "      <td id=\"T_d9ffa_row20_col3\" class=\"data row20 col3\" >-0.17</td>\n",
       "      <td id=\"T_d9ffa_row20_col4\" class=\"data row20 col4\" >0.48</td>\n",
       "      <td id=\"T_d9ffa_row20_col5\" class=\"data row20 col5\" >0.48</td>\n",
       "      <td id=\"T_d9ffa_row20_col6\" class=\"data row20 col6\" >-0.54</td>\n",
       "      <td id=\"T_d9ffa_row20_col7\" class=\"data row20 col7\" >-0.62</td>\n",
       "      <td id=\"T_d9ffa_row20_col8\" class=\"data row20 col8\" >0.08</td>\n",
       "      <td id=\"T_d9ffa_row20_col9\" class=\"data row20 col9\" >0.43</td>\n",
       "      <td id=\"T_d9ffa_row20_col10\" class=\"data row20 col10\" >0.36</td>\n",
       "      <td id=\"T_d9ffa_row20_col11\" class=\"data row20 col11\" >0.63</td>\n",
       "      <td id=\"T_d9ffa_row20_col12\" class=\"data row20 col12\" >0.51</td>\n",
       "      <td id=\"T_d9ffa_row20_col13\" class=\"data row20 col13\" >0.39</td>\n",
       "      <td id=\"T_d9ffa_row20_col14\" class=\"data row20 col14\" >-0.03</td>\n",
       "      <td id=\"T_d9ffa_row20_col15\" class=\"data row20 col15\" >-0.76</td>\n",
       "      <td id=\"T_d9ffa_row20_col16\" class=\"data row20 col16\" >0.33</td>\n",
       "      <td id=\"T_d9ffa_row20_col17\" class=\"data row20 col17\" >0.37</td>\n",
       "      <td id=\"T_d9ffa_row20_col18\" class=\"data row20 col18\" >-0.71</td>\n",
       "      <td id=\"T_d9ffa_row20_col19\" class=\"data row20 col19\" >0.16</td>\n",
       "      <td id=\"T_d9ffa_row20_col20\" class=\"data row20 col20\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row20_col21\" class=\"data row20 col21\" >0.28</td>\n",
       "      <td id=\"T_d9ffa_row20_col22\" class=\"data row20 col22\" >-0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row21\" class=\"row_heading level0 row21\" >SP_Summaries_welch_rect_centroid</th>\n",
       "      <td id=\"T_d9ffa_row21_col0\" class=\"data row21 col0\" >0.35</td>\n",
       "      <td id=\"T_d9ffa_row21_col1\" class=\"data row21 col1\" >0.38</td>\n",
       "      <td id=\"T_d9ffa_row21_col2\" class=\"data row21 col2\" >0.34</td>\n",
       "      <td id=\"T_d9ffa_row21_col3\" class=\"data row21 col3\" >-0.72</td>\n",
       "      <td id=\"T_d9ffa_row21_col4\" class=\"data row21 col4\" >-0.47</td>\n",
       "      <td id=\"T_d9ffa_row21_col5\" class=\"data row21 col5\" >-0.56</td>\n",
       "      <td id=\"T_d9ffa_row21_col6\" class=\"data row21 col6\" >-0.71</td>\n",
       "      <td id=\"T_d9ffa_row21_col7\" class=\"data row21 col7\" >0.32</td>\n",
       "      <td id=\"T_d9ffa_row21_col8\" class=\"data row21 col8\" >-0.75</td>\n",
       "      <td id=\"T_d9ffa_row21_col9\" class=\"data row21 col9\" >-0.50</td>\n",
       "      <td id=\"T_d9ffa_row21_col10\" class=\"data row21 col10\" >-0.31</td>\n",
       "      <td id=\"T_d9ffa_row21_col11\" class=\"data row21 col11\" >-0.51</td>\n",
       "      <td id=\"T_d9ffa_row21_col12\" class=\"data row21 col12\" >-0.58</td>\n",
       "      <td id=\"T_d9ffa_row21_col13\" class=\"data row21 col13\" >0.70</td>\n",
       "      <td id=\"T_d9ffa_row21_col14\" class=\"data row21 col14\" >-0.78</td>\n",
       "      <td id=\"T_d9ffa_row21_col15\" class=\"data row21 col15\" >0.32</td>\n",
       "      <td id=\"T_d9ffa_row21_col16\" class=\"data row21 col16\" >-0.67</td>\n",
       "      <td id=\"T_d9ffa_row21_col17\" class=\"data row21 col17\" >0.97</td>\n",
       "      <td id=\"T_d9ffa_row21_col18\" class=\"data row21 col18\" >0.41</td>\n",
       "      <td id=\"T_d9ffa_row21_col19\" class=\"data row21 col19\" >-0.11</td>\n",
       "      <td id=\"T_d9ffa_row21_col20\" class=\"data row21 col20\" >0.28</td>\n",
       "      <td id=\"T_d9ffa_row21_col21\" class=\"data row21 col21\" >1.00</td>\n",
       "      <td id=\"T_d9ffa_row21_col22\" class=\"data row21 col22\" >0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9ffa_level0_row22\" class=\"row_heading level0 row22\" >FC_LocalSimple_mean3_stderr</th>\n",
       "      <td id=\"T_d9ffa_row22_col0\" class=\"data row22 col0\" >0.40</td>\n",
       "      <td id=\"T_d9ffa_row22_col1\" class=\"data row22 col1\" >0.63</td>\n",
       "      <td id=\"T_d9ffa_row22_col2\" class=\"data row22 col2\" >0.55</td>\n",
       "      <td id=\"T_d9ffa_row22_col3\" class=\"data row22 col3\" >-0.59</td>\n",
       "      <td id=\"T_d9ffa_row22_col4\" class=\"data row22 col4\" >-0.80</td>\n",
       "      <td id=\"T_d9ffa_row22_col5\" class=\"data row22 col5\" >-0.87</td>\n",
       "      <td id=\"T_d9ffa_row22_col6\" class=\"data row22 col6\" >-0.30</td>\n",
       "      <td id=\"T_d9ffa_row22_col7\" class=\"data row22 col7\" >0.73</td>\n",
       "      <td id=\"T_d9ffa_row22_col8\" class=\"data row22 col8\" >-0.79</td>\n",
       "      <td id=\"T_d9ffa_row22_col9\" class=\"data row22 col9\" >-0.80</td>\n",
       "      <td id=\"T_d9ffa_row22_col10\" class=\"data row22 col10\" >-0.55</td>\n",
       "      <td id=\"T_d9ffa_row22_col11\" class=\"data row22 col11\" >-0.93</td>\n",
       "      <td id=\"T_d9ffa_row22_col12\" class=\"data row22 col12\" >-0.92</td>\n",
       "      <td id=\"T_d9ffa_row22_col13\" class=\"data row22 col13\" >0.46</td>\n",
       "      <td id=\"T_d9ffa_row22_col14\" class=\"data row22 col14\" >-0.77</td>\n",
       "      <td id=\"T_d9ffa_row22_col15\" class=\"data row22 col15\" >0.83</td>\n",
       "      <td id=\"T_d9ffa_row22_col16\" class=\"data row22 col16\" >-0.82</td>\n",
       "      <td id=\"T_d9ffa_row22_col17\" class=\"data row22 col17\" >0.68</td>\n",
       "      <td id=\"T_d9ffa_row22_col18\" class=\"data row22 col18\" >0.86</td>\n",
       "      <td id=\"T_d9ffa_row22_col19\" class=\"data row22 col19\" >-0.19</td>\n",
       "      <td id=\"T_d9ffa_row22_col20\" class=\"data row22 col20\" >-0.39</td>\n",
       "      <td id=\"T_d9ffa_row22_col21\" class=\"data row22 col21\" >0.77</td>\n",
       "      <td id=\"T_d9ffa_row22_col22\" class=\"data row22 col22\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9d92af8310>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = data[data['model']=='Informer'].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d0/l9cqdxf90hbg0dj97q8bs7kc0000gn/T/ipykernel_76447/97903053.py:2: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "  corr.style.background_gradient(cmap='coolwarm').set_precision(2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5b7a7_row0_col0, #T_5b7a7_row1_col1, #T_5b7a7_row2_col2, #T_5b7a7_row3_col3, #T_5b7a7_row4_col4, #T_5b7a7_row5_col5, #T_5b7a7_row6_col6, #T_5b7a7_row7_col7, #T_5b7a7_row8_col8, #T_5b7a7_row9_col9, #T_5b7a7_row10_col10, #T_5b7a7_row11_col11, #T_5b7a7_row12_col12, #T_5b7a7_row13_col13, #T_5b7a7_row14_col14, #T_5b7a7_row15_col15, #T_5b7a7_row16_col16, #T_5b7a7_row17_col17, #T_5b7a7_row18_col18, #T_5b7a7_row19_col19, #T_5b7a7_row20_col20, #T_5b7a7_row21_col21, #T_5b7a7_row22_col22 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row0_col1 {\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row0_col2, #T_5b7a7_row3_col5, #T_5b7a7_row4_col3, #T_5b7a7_row5_col14, #T_5b7a7_row10_col20, #T_5b7a7_row20_col10 {\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row0_col3, #T_5b7a7_row8_col22, #T_5b7a7_row14_col15 {\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row0_col4, #T_5b7a7_row2_col8, #T_5b7a7_row6_col9, #T_5b7a7_row10_col8, #T_5b7a7_row14_col1, #T_5b7a7_row17_col14 {\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row0_col5, #T_5b7a7_row0_col19, #T_5b7a7_row15_col16, #T_5b7a7_row16_col15 {\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row0_col6 {\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row0_col7, #T_5b7a7_row3_col10 {\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row0_col8 {\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row0_col9 {\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row0_col10, #T_5b7a7_row3_col11, #T_5b7a7_row14_col3, #T_5b7a7_row18_col2, #T_5b7a7_row19_col17 {\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row0_col11, #T_5b7a7_row14_col10, #T_5b7a7_row14_col22, #T_5b7a7_row15_col5, #T_5b7a7_row22_col6 {\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row0_col12, #T_5b7a7_row10_col11, #T_5b7a7_row14_col17, #T_5b7a7_row14_col18 {\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row0_col13 {\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row0_col14, #T_5b7a7_row22_col3 {\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row0_col15, #T_5b7a7_row20_col21 {\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row0_col16, #T_5b7a7_row5_col6 {\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row0_col17 {\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row0_col18, #T_5b7a7_row13_col7, #T_5b7a7_row21_col15 {\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row0_col20, #T_5b7a7_row17_col0 {\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row0_col21 {\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row0_col22, #T_5b7a7_row14_col8 {\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row1_col0 {\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row1_col2, #T_5b7a7_row10_col2 {\n",
       "  background-color: #f39577;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row1_col3, #T_5b7a7_row7_col5, #T_5b7a7_row11_col10, #T_5b7a7_row16_col18, #T_5b7a7_row19_col18, #T_5b7a7_row21_col12 {\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row1_col4, #T_5b7a7_row4_col1, #T_5b7a7_row16_col22 {\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row1_col5, #T_5b7a7_row1_col12, #T_5b7a7_row11_col22, #T_5b7a7_row13_col3, #T_5b7a7_row13_col8 {\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row1_col6, #T_5b7a7_row6_col15, #T_5b7a7_row10_col4, #T_5b7a7_row11_col2, #T_5b7a7_row11_col21, #T_5b7a7_row13_col9, #T_5b7a7_row18_col16, #T_5b7a7_row18_col19, #T_5b7a7_row19_col1 {\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row1_col7, #T_5b7a7_row20_col11 {\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row1_col8, #T_5b7a7_row4_col0, #T_5b7a7_row5_col17, #T_5b7a7_row19_col0, #T_5b7a7_row22_col14 {\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row1_col9, #T_5b7a7_row1_col20, #T_5b7a7_row4_col13, #T_5b7a7_row8_col15, #T_5b7a7_row12_col2, #T_5b7a7_row12_col10, #T_5b7a7_row17_col3 {\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row1_col10, #T_5b7a7_row6_col8, #T_5b7a7_row6_col20, #T_5b7a7_row10_col18, #T_5b7a7_row16_col20, #T_5b7a7_row19_col5 {\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row1_col11, #T_5b7a7_row12_col7, #T_5b7a7_row16_col1 {\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row1_col13, #T_5b7a7_row6_col1, #T_5b7a7_row7_col17, #T_5b7a7_row20_col0 {\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row1_col14 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row1_col15, #T_5b7a7_row8_col4, #T_5b7a7_row9_col11, #T_5b7a7_row17_col13, #T_5b7a7_row18_col22 {\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row1_col16, #T_5b7a7_row4_col7, #T_5b7a7_row5_col22, #T_5b7a7_row8_col0, #T_5b7a7_row8_col13, #T_5b7a7_row8_col21, #T_5b7a7_row9_col2, #T_5b7a7_row9_col10, #T_5b7a7_row9_col17, #T_5b7a7_row10_col9, #T_5b7a7_row11_col1, #T_5b7a7_row11_col18, #T_5b7a7_row15_col6, #T_5b7a7_row15_col14, #T_5b7a7_row15_col19, #T_5b7a7_row15_col20, #T_5b7a7_row18_col4, #T_5b7a7_row18_col11, #T_5b7a7_row18_col12, #T_5b7a7_row19_col15, #T_5b7a7_row21_col3, #T_5b7a7_row21_col8, #T_5b7a7_row22_col5, #T_5b7a7_row22_col8, #T_5b7a7_row22_col12 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row1_col17, #T_5b7a7_row9_col20 {\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row1_col18, #T_5b7a7_row18_col1 {\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row1_col19, #T_5b7a7_row8_col18, #T_5b7a7_row15_col17 {\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row1_col21, #T_5b7a7_row12_col3, #T_5b7a7_row14_col5, #T_5b7a7_row19_col8 {\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row1_col22, #T_5b7a7_row5_col4, #T_5b7a7_row5_col9, #T_5b7a7_row22_col1 {\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row2_col0, #T_5b7a7_row5_col19, #T_5b7a7_row14_col2, #T_5b7a7_row14_col20 {\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row2_col1, #T_5b7a7_row13_col20, #T_5b7a7_row14_col4 {\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row2_col3, #T_5b7a7_row6_col18 {\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row2_col4, #T_5b7a7_row2_col11, #T_5b7a7_row18_col3, #T_5b7a7_row19_col7 {\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row2_col5, #T_5b7a7_row8_col17 {\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row2_col6 {\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row2_col7, #T_5b7a7_row2_col14, #T_5b7a7_row9_col14 {\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row2_col9 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row2_col10, #T_5b7a7_row14_col19 {\n",
       "  background-color: #f39475;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row2_col12, #T_5b7a7_row10_col12, #T_5b7a7_row20_col1 {\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row2_col13, #T_5b7a7_row7_col13 {\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row2_col15, #T_5b7a7_row4_col6, #T_5b7a7_row17_col7 {\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row2_col16, #T_5b7a7_row9_col21 {\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row2_col17 {\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row2_col18, #T_5b7a7_row19_col4 {\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row2_col19 {\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row2_col20, #T_5b7a7_row7_col2, #T_5b7a7_row16_col3, #T_5b7a7_row20_col6 {\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row2_col21, #T_5b7a7_row3_col14, #T_5b7a7_row5_col20, #T_5b7a7_row13_col19 {\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row2_col22, #T_5b7a7_row22_col18, #T_5b7a7_row22_col21 {\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row3_col0, #T_5b7a7_row7_col8, #T_5b7a7_row11_col7, #T_5b7a7_row12_col22 {\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row3_col1 {\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row3_col2, #T_5b7a7_row6_col17, #T_5b7a7_row6_col22, #T_5b7a7_row15_col10 {\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row3_col4 {\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row3_col6, #T_5b7a7_row7_col10 {\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row3_col7, #T_5b7a7_row3_col15, #T_5b7a7_row21_col11 {\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row3_col8, #T_5b7a7_row8_col3 {\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row3_col9, #T_5b7a7_row3_col16, #T_5b7a7_row18_col10, #T_5b7a7_row18_col21, #T_5b7a7_row19_col13 {\n",
       "  background-color: #ead5c9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row3_col12, #T_5b7a7_row8_col14, #T_5b7a7_row22_col17 {\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row3_col13, #T_5b7a7_row12_col18, #T_5b7a7_row22_col9 {\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row3_col17, #T_5b7a7_row7_col14, #T_5b7a7_row18_col5, #T_5b7a7_row18_col14, #T_5b7a7_row20_col7 {\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row3_col18 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row3_col19, #T_5b7a7_row4_col16 {\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row3_col20, #T_5b7a7_row18_col13 {\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row3_col21, #T_5b7a7_row5_col1, #T_5b7a7_row5_col2, #T_5b7a7_row20_col15 {\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row3_col22, #T_5b7a7_row17_col5, #T_5b7a7_row17_col16 {\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row4_col2, #T_5b7a7_row16_col0, #T_5b7a7_row18_col6 {\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row4_col5, #T_5b7a7_row9_col5 {\n",
       "  background-color: #c83836;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row4_col8, #T_5b7a7_row22_col2 {\n",
       "  background-color: #e67259;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row4_col9, #T_5b7a7_row15_col7 {\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row4_col10, #T_5b7a7_row12_col17, #T_5b7a7_row13_col14, #T_5b7a7_row16_col2, #T_5b7a7_row18_col9 {\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row4_col11, #T_5b7a7_row11_col4 {\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row4_col12, #T_5b7a7_row12_col4 {\n",
       "  background-color: #b50927;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row4_col14, #T_5b7a7_row6_col2, #T_5b7a7_row22_col7, #T_5b7a7_row22_col15 {\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row4_col15, #T_5b7a7_row5_col18, #T_5b7a7_row7_col11 {\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row4_col17, #T_5b7a7_row5_col15, #T_5b7a7_row9_col7 {\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row4_col18, #T_5b7a7_row21_col14 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row4_col19 {\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row4_col20, #T_5b7a7_row9_col8, #T_5b7a7_row16_col4 {\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row4_col21, #T_5b7a7_row17_col8 {\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row4_col22, #T_5b7a7_row9_col13, #T_5b7a7_row15_col8 {\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row5_col0, #T_5b7a7_row7_col12 {\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row5_col3, #T_5b7a7_row14_col9, #T_5b7a7_row17_col1 {\n",
       "  background-color: #ebd3c6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row5_col7, #T_5b7a7_row6_col21, #T_5b7a7_row10_col5 {\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row5_col8 {\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row5_col10 {\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row5_col11, #T_5b7a7_row11_col5 {\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row5_col12, #T_5b7a7_row12_col5 {\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row5_col13, #T_5b7a7_row21_col5 {\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row5_col16 {\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row5_col21, #T_5b7a7_row7_col20, #T_5b7a7_row12_col15 {\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row6_col0 {\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row6_col3, #T_5b7a7_row11_col3 {\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row6_col4, #T_5b7a7_row8_col6 {\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row6_col5, #T_5b7a7_row13_col18 {\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row6_col7, #T_5b7a7_row16_col7 {\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row6_col10 {\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row6_col11, #T_5b7a7_row10_col1, #T_5b7a7_row16_col6 {\n",
       "  background-color: #f1cdba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row6_col12, #T_5b7a7_row13_col0 {\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row6_col13, #T_5b7a7_row13_col15 {\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row6_col14 {\n",
       "  background-color: #de614d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row6_col16, #T_5b7a7_row12_col20, #T_5b7a7_row13_col22, #T_5b7a7_row19_col3, #T_5b7a7_row22_col0 {\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row6_col19, #T_5b7a7_row11_col9, #T_5b7a7_row13_col17 {\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row7_col0, #T_5b7a7_row17_col4, #T_5b7a7_row19_col9 {\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row7_col1, #T_5b7a7_row8_col5 {\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row7_col3 {\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row7_col4, #T_5b7a7_row22_col11, #T_5b7a7_row22_col16 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row7_col6 {\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row7_col9, #T_5b7a7_row9_col1, #T_5b7a7_row9_col18, #T_5b7a7_row15_col3 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row7_col15, #T_5b7a7_row9_col4 {\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row7_col16, #T_5b7a7_row9_col19, #T_5b7a7_row15_col9, #T_5b7a7_row19_col22 {\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row7_col18, #T_5b7a7_row11_col12, #T_5b7a7_row12_col11 {\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row7_col19, #T_5b7a7_row21_col9 {\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row7_col21, #T_5b7a7_row11_col6 {\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row7_col22 {\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row8_col1 {\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row8_col2, #T_5b7a7_row8_col10, #T_5b7a7_row22_col19 {\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row8_col7, #T_5b7a7_row12_col13, #T_5b7a7_row16_col17 {\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row8_col9, #T_5b7a7_row10_col21, #T_5b7a7_row11_col19, #T_5b7a7_row16_col12, #T_5b7a7_row21_col1 {\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row8_col11 {\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row8_col12 {\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row8_col16 {\n",
       "  background-color: #f5c2aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row8_col19, #T_5b7a7_row12_col16 {\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row8_col20, #T_5b7a7_row15_col21, #T_5b7a7_row20_col14 {\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row9_col0, #T_5b7a7_row12_col21 {\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row9_col3 {\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row9_col6, #T_5b7a7_row21_col16 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row9_col12, #T_5b7a7_row12_col9 {\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row9_col15, #T_5b7a7_row13_col6, #T_5b7a7_row22_col20 {\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row9_col16, #T_5b7a7_row16_col19, #T_5b7a7_row19_col16 {\n",
       "  background-color: #f7ba9f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row9_col22, #T_5b7a7_row15_col4, #T_5b7a7_row20_col18 {\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row10_col0, #T_5b7a7_row13_col2, #T_5b7a7_row15_col0 {\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row10_col3, #T_5b7a7_row20_col22 {\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row10_col6 {\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row10_col7, #T_5b7a7_row21_col7 {\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row10_col13, #T_5b7a7_row14_col11, #T_5b7a7_row17_col22, #T_5b7a7_row22_col10 {\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row10_col14, #T_5b7a7_row14_col13, #T_5b7a7_row17_col9 {\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row10_col15 {\n",
       "  background-color: #c3d5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row10_col16 {\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row10_col17 {\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row10_col19, #T_5b7a7_row17_col19 {\n",
       "  background-color: #f7b497;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row10_col22, #T_5b7a7_row11_col16, #T_5b7a7_row20_col17 {\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row11_col0 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row11_col8, #T_5b7a7_row11_col20, #T_5b7a7_row21_col13 {\n",
       "  background-color: #f18f71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row11_col13, #T_5b7a7_row19_col21 {\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row11_col14, #T_5b7a7_row20_col13, #T_5b7a7_row21_col10 {\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row11_col15, #T_5b7a7_row22_col4 {\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row11_col17, #T_5b7a7_row13_col4 {\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row12_col0, #T_5b7a7_row12_col1, #T_5b7a7_row18_col8 {\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row12_col6, #T_5b7a7_row17_col11 {\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row12_col8 {\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row12_col14 {\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row12_col19, #T_5b7a7_row19_col12, #T_5b7a7_row20_col5, #T_5b7a7_row21_col2 {\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row13_col1 {\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row13_col5, #T_5b7a7_row18_col17 {\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row13_col10, #T_5b7a7_row16_col11 {\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row13_col11, #T_5b7a7_row15_col2 {\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row13_col12 {\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row13_col16 {\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row13_col21 {\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row14_col0 {\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row14_col6 {\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row14_col7 {\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row14_col12, #T_5b7a7_row15_col22 {\n",
       "  background-color: #f59c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row14_col16, #T_5b7a7_row16_col9, #T_5b7a7_row21_col20 {\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row14_col21, #T_5b7a7_row18_col20 {\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row15_col1 {\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row15_col11, #T_5b7a7_row21_col6 {\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row15_col12 {\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row15_col13, #T_5b7a7_row16_col10, #T_5b7a7_row17_col15 {\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row15_col18, #T_5b7a7_row18_col15 {\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row16_col5, #T_5b7a7_row17_col10 {\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row16_col8 {\n",
       "  background-color: #f1ccb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row16_col13 {\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row16_col14 {\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row16_col21 {\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row17_col2 {\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row17_col6 {\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row17_col12 {\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row17_col18, #T_5b7a7_row20_col9 {\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row17_col20 {\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row17_col21 {\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row18_col0 {\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row18_col7 {\n",
       "  background-color: #c32e31;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row19_col2, #T_5b7a7_row21_col0, #T_5b7a7_row21_col18 {\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row19_col6, #T_5b7a7_row19_col20 {\n",
       "  background-color: #ec7f63;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row19_col10, #T_5b7a7_row20_col12 {\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row19_col11, #T_5b7a7_row19_col14 {\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row20_col2 {\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row20_col3 {\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row20_col4 {\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row20_col8 {\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row20_col16 {\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row20_col19 {\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row21_col4 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row21_col17 {\n",
       "  background-color: #da5a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row21_col19 {\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5b7a7_row21_col22 {\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5b7a7_row22_col13 {\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5b7a7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5b7a7_level0_col0\" class=\"col_heading level0 col0\" >error</th>\n",
       "      <th id=\"T_5b7a7_level0_col1\" class=\"col_heading level0 col1\" >DN_HistogramMode_5</th>\n",
       "      <th id=\"T_5b7a7_level0_col2\" class=\"col_heading level0 col2\" >DN_HistogramMode_10</th>\n",
       "      <th id=\"T_5b7a7_level0_col3\" class=\"col_heading level0 col3\" >CO_f1ecac</th>\n",
       "      <th id=\"T_5b7a7_level0_col4\" class=\"col_heading level0 col4\" >CO_FirstMin_ac</th>\n",
       "      <th id=\"T_5b7a7_level0_col5\" class=\"col_heading level0 col5\" >CO_HistogramAMI_even_2_5</th>\n",
       "      <th id=\"T_5b7a7_level0_col6\" class=\"col_heading level0 col6\" >CO_trev_1_num</th>\n",
       "      <th id=\"T_5b7a7_level0_col7\" class=\"col_heading level0 col7\" >MD_hrv_classic_pnn40</th>\n",
       "      <th id=\"T_5b7a7_level0_col8\" class=\"col_heading level0 col8\" >SB_BinaryStats_mean_longstretch1</th>\n",
       "      <th id=\"T_5b7a7_level0_col9\" class=\"col_heading level0 col9\" >SB_TransitionMatrix_3ac_sumdiagcov</th>\n",
       "      <th id=\"T_5b7a7_level0_col10\" class=\"col_heading level0 col10\" >PD_PeriodicityWang_th0_01</th>\n",
       "      <th id=\"T_5b7a7_level0_col11\" class=\"col_heading level0 col11\" >CO_Embed2_Dist_tau_d_expfit_meandiff</th>\n",
       "      <th id=\"T_5b7a7_level0_col12\" class=\"col_heading level0 col12\" >IN_AutoMutualInfoStats_40_gaussian_fmmi</th>\n",
       "      <th id=\"T_5b7a7_level0_col13\" class=\"col_heading level0 col13\" >FC_LocalSimple_mean1_tauresrat</th>\n",
       "      <th id=\"T_5b7a7_level0_col14\" class=\"col_heading level0 col14\" >DN_OutlierInclude_p_001_mdrmd</th>\n",
       "      <th id=\"T_5b7a7_level0_col15\" class=\"col_heading level0 col15\" >DN_OutlierInclude_n_001_mdrmd</th>\n",
       "      <th id=\"T_5b7a7_level0_col16\" class=\"col_heading level0 col16\" >SP_Summaries_welch_rect_area_5_1</th>\n",
       "      <th id=\"T_5b7a7_level0_col17\" class=\"col_heading level0 col17\" >SB_BinaryStats_diff_longstretch0</th>\n",
       "      <th id=\"T_5b7a7_level0_col18\" class=\"col_heading level0 col18\" >SB_MotifThree_quantile_hh</th>\n",
       "      <th id=\"T_5b7a7_level0_col19\" class=\"col_heading level0 col19\" >SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1</th>\n",
       "      <th id=\"T_5b7a7_level0_col20\" class=\"col_heading level0 col20\" >SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1</th>\n",
       "      <th id=\"T_5b7a7_level0_col21\" class=\"col_heading level0 col21\" >SP_Summaries_welch_rect_centroid</th>\n",
       "      <th id=\"T_5b7a7_level0_col22\" class=\"col_heading level0 col22\" >FC_LocalSimple_mean3_stderr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row0\" class=\"row_heading level0 row0\" >error</th>\n",
       "      <td id=\"T_5b7a7_row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row0_col1\" class=\"data row0 col1\" >0.37</td>\n",
       "      <td id=\"T_5b7a7_row0_col2\" class=\"data row0 col2\" >0.33</td>\n",
       "      <td id=\"T_5b7a7_row0_col3\" class=\"data row0 col3\" >-0.44</td>\n",
       "      <td id=\"T_5b7a7_row0_col4\" class=\"data row0 col4\" >-0.40</td>\n",
       "      <td id=\"T_5b7a7_row0_col5\" class=\"data row0 col5\" >-0.47</td>\n",
       "      <td id=\"T_5b7a7_row0_col6\" class=\"data row0 col6\" >-0.09</td>\n",
       "      <td id=\"T_5b7a7_row0_col7\" class=\"data row0 col7\" >-0.01</td>\n",
       "      <td id=\"T_5b7a7_row0_col8\" class=\"data row0 col8\" >-0.51</td>\n",
       "      <td id=\"T_5b7a7_row0_col9\" class=\"data row0 col9\" >-0.34</td>\n",
       "      <td id=\"T_5b7a7_row0_col10\" class=\"data row0 col10\" >0.31</td>\n",
       "      <td id=\"T_5b7a7_row0_col11\" class=\"data row0 col11\" >-0.46</td>\n",
       "      <td id=\"T_5b7a7_row0_col12\" class=\"data row0 col12\" >-0.42</td>\n",
       "      <td id=\"T_5b7a7_row0_col13\" class=\"data row0 col13\" >0.26</td>\n",
       "      <td id=\"T_5b7a7_row0_col14\" class=\"data row0 col14\" >-0.42</td>\n",
       "      <td id=\"T_5b7a7_row0_col15\" class=\"data row0 col15\" >0.30</td>\n",
       "      <td id=\"T_5b7a7_row0_col16\" class=\"data row0 col16\" >-0.23</td>\n",
       "      <td id=\"T_5b7a7_row0_col17\" class=\"data row0 col17\" >0.15</td>\n",
       "      <td id=\"T_5b7a7_row0_col18\" class=\"data row0 col18\" >0.14</td>\n",
       "      <td id=\"T_5b7a7_row0_col19\" class=\"data row0 col19\" >-0.40</td>\n",
       "      <td id=\"T_5b7a7_row0_col20\" class=\"data row0 col20\" >-0.02</td>\n",
       "      <td id=\"T_5b7a7_row0_col21\" class=\"data row0 col21\" >0.40</td>\n",
       "      <td id=\"T_5b7a7_row0_col22\" class=\"data row0 col22\" >0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row1\" class=\"row_heading level0 row1\" >DN_HistogramMode_5</th>\n",
       "      <td id=\"T_5b7a7_row1_col0\" class=\"data row1 col0\" >0.37</td>\n",
       "      <td id=\"T_5b7a7_row1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row1_col2\" class=\"data row1 col2\" >0.57</td>\n",
       "      <td id=\"T_5b7a7_row1_col3\" class=\"data row1 col3\" >-0.33</td>\n",
       "      <td id=\"T_5b7a7_row1_col4\" class=\"data row1 col4\" >-0.75</td>\n",
       "      <td id=\"T_5b7a7_row1_col5\" class=\"data row1 col5\" >-0.85</td>\n",
       "      <td id=\"T_5b7a7_row1_col6\" class=\"data row1 col6\" >-0.27</td>\n",
       "      <td id=\"T_5b7a7_row1_col7\" class=\"data row1 col7\" >0.60</td>\n",
       "      <td id=\"T_5b7a7_row1_col8\" class=\"data row1 col8\" >-0.57</td>\n",
       "      <td id=\"T_5b7a7_row1_col9\" class=\"data row1 col9\" >-0.54</td>\n",
       "      <td id=\"T_5b7a7_row1_col10\" class=\"data row1 col10\" >0.23</td>\n",
       "      <td id=\"T_5b7a7_row1_col11\" class=\"data row1 col11\" >-0.89</td>\n",
       "      <td id=\"T_5b7a7_row1_col12\" class=\"data row1 col12\" >-0.78</td>\n",
       "      <td id=\"T_5b7a7_row1_col13\" class=\"data row1 col13\" >-0.09</td>\n",
       "      <td id=\"T_5b7a7_row1_col14\" class=\"data row1 col14\" >-0.40</td>\n",
       "      <td id=\"T_5b7a7_row1_col15\" class=\"data row1 col15\" >0.73</td>\n",
       "      <td id=\"T_5b7a7_row1_col16\" class=\"data row1 col16\" >-0.86</td>\n",
       "      <td id=\"T_5b7a7_row1_col17\" class=\"data row1 col17\" >0.17</td>\n",
       "      <td id=\"T_5b7a7_row1_col18\" class=\"data row1 col18\" >0.85</td>\n",
       "      <td id=\"T_5b7a7_row1_col19\" class=\"data row1 col19\" >-0.56</td>\n",
       "      <td id=\"T_5b7a7_row1_col20\" class=\"data row1 col20\" >-0.55</td>\n",
       "      <td id=\"T_5b7a7_row1_col21\" class=\"data row1 col21\" >0.47</td>\n",
       "      <td id=\"T_5b7a7_row1_col22\" class=\"data row1 col22\" >0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row2\" class=\"row_heading level0 row2\" >DN_HistogramMode_10</th>\n",
       "      <td id=\"T_5b7a7_row2_col0\" class=\"data row2 col0\" >0.33</td>\n",
       "      <td id=\"T_5b7a7_row2_col1\" class=\"data row2 col1\" >0.57</td>\n",
       "      <td id=\"T_5b7a7_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row2_col3\" class=\"data row2 col3\" >-0.09</td>\n",
       "      <td id=\"T_5b7a7_row2_col4\" class=\"data row2 col4\" >-0.47</td>\n",
       "      <td id=\"T_5b7a7_row2_col5\" class=\"data row2 col5\" >-0.78</td>\n",
       "      <td id=\"T_5b7a7_row2_col6\" class=\"data row2 col6\" >0.52</td>\n",
       "      <td id=\"T_5b7a7_row2_col7\" class=\"data row2 col7\" >0.09</td>\n",
       "      <td id=\"T_5b7a7_row2_col8\" class=\"data row2 col8\" >-0.25</td>\n",
       "      <td id=\"T_5b7a7_row2_col9\" class=\"data row2 col9\" >-0.81</td>\n",
       "      <td id=\"T_5b7a7_row2_col10\" class=\"data row2 col10\" >0.57</td>\n",
       "      <td id=\"T_5b7a7_row2_col11\" class=\"data row2 col11\" >-0.49</td>\n",
       "      <td id=\"T_5b7a7_row2_col12\" class=\"data row2 col12\" >-0.53</td>\n",
       "      <td id=\"T_5b7a7_row2_col13\" class=\"data row2 col13\" >0.17</td>\n",
       "      <td id=\"T_5b7a7_row2_col14\" class=\"data row2 col14\" >0.20</td>\n",
       "      <td id=\"T_5b7a7_row2_col15\" class=\"data row2 col15\" >-0.06</td>\n",
       "      <td id=\"T_5b7a7_row2_col16\" class=\"data row2 col16\" >-0.55</td>\n",
       "      <td id=\"T_5b7a7_row2_col17\" class=\"data row2 col17\" >0.55</td>\n",
       "      <td id=\"T_5b7a7_row2_col18\" class=\"data row2 col18\" >0.31</td>\n",
       "      <td id=\"T_5b7a7_row2_col19\" class=\"data row2 col19\" >0.29</td>\n",
       "      <td id=\"T_5b7a7_row2_col20\" class=\"data row2 col20\" >0.08</td>\n",
       "      <td id=\"T_5b7a7_row2_col21\" class=\"data row2 col21\" >0.34</td>\n",
       "      <td id=\"T_5b7a7_row2_col22\" class=\"data row2 col22\" >0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row3\" class=\"row_heading level0 row3\" >CO_f1ecac</th>\n",
       "      <td id=\"T_5b7a7_row3_col0\" class=\"data row3 col0\" >-0.44</td>\n",
       "      <td id=\"T_5b7a7_row3_col1\" class=\"data row3 col1\" >-0.33</td>\n",
       "      <td id=\"T_5b7a7_row3_col2\" class=\"data row3 col2\" >-0.09</td>\n",
       "      <td id=\"T_5b7a7_row3_col3\" class=\"data row3 col3\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row3_col4\" class=\"data row3 col4\" >0.38</td>\n",
       "      <td id=\"T_5b7a7_row3_col5\" class=\"data row3 col5\" >0.27</td>\n",
       "      <td id=\"T_5b7a7_row3_col6\" class=\"data row3 col6\" >0.28</td>\n",
       "      <td id=\"T_5b7a7_row3_col7\" class=\"data row3 col7\" >-0.35</td>\n",
       "      <td id=\"T_5b7a7_row3_col8\" class=\"data row3 col8\" >0.91</td>\n",
       "      <td id=\"T_5b7a7_row3_col9\" class=\"data row3 col9\" >0.19</td>\n",
       "      <td id=\"T_5b7a7_row3_col10\" class=\"data row3 col10\" >0.00</td>\n",
       "      <td id=\"T_5b7a7_row3_col11\" class=\"data row3 col11\" >0.27</td>\n",
       "      <td id=\"T_5b7a7_row3_col12\" class=\"data row3 col12\" >0.48</td>\n",
       "      <td id=\"T_5b7a7_row3_col13\" class=\"data row3 col13\" >-0.58</td>\n",
       "      <td id=\"T_5b7a7_row3_col14\" class=\"data row3 col14\" >0.37</td>\n",
       "      <td id=\"T_5b7a7_row3_col15\" class=\"data row3 col15\" >-0.36</td>\n",
       "      <td id=\"T_5b7a7_row3_col16\" class=\"data row3 col16\" >0.17</td>\n",
       "      <td id=\"T_5b7a7_row3_col17\" class=\"data row3 col17\" >-0.41</td>\n",
       "      <td id=\"T_5b7a7_row3_col18\" class=\"data row3 col18\" >-0.30</td>\n",
       "      <td id=\"T_5b7a7_row3_col19\" class=\"data row3 col19\" >0.44</td>\n",
       "      <td id=\"T_5b7a7_row3_col20\" class=\"data row3 col20\" >-0.13</td>\n",
       "      <td id=\"T_5b7a7_row3_col21\" class=\"data row3 col21\" >-0.66</td>\n",
       "      <td id=\"T_5b7a7_row3_col22\" class=\"data row3 col22\" >-0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row4\" class=\"row_heading level0 row4\" >CO_FirstMin_ac</th>\n",
       "      <td id=\"T_5b7a7_row4_col0\" class=\"data row4 col0\" >-0.40</td>\n",
       "      <td id=\"T_5b7a7_row4_col1\" class=\"data row4 col1\" >-0.75</td>\n",
       "      <td id=\"T_5b7a7_row4_col2\" class=\"data row4 col2\" >-0.47</td>\n",
       "      <td id=\"T_5b7a7_row4_col3\" class=\"data row4 col3\" >0.38</td>\n",
       "      <td id=\"T_5b7a7_row4_col4\" class=\"data row4 col4\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row4_col5\" class=\"data row4 col5\" >0.89</td>\n",
       "      <td id=\"T_5b7a7_row4_col6\" class=\"data row4 col6\" >0.12</td>\n",
       "      <td id=\"T_5b7a7_row4_col7\" class=\"data row4 col7\" >-0.84</td>\n",
       "      <td id=\"T_5b7a7_row4_col8\" class=\"data row4 col8\" >0.72</td>\n",
       "      <td id=\"T_5b7a7_row4_col9\" class=\"data row4 col9\" >0.82</td>\n",
       "      <td id=\"T_5b7a7_row4_col10\" class=\"data row4 col10\" >-0.56</td>\n",
       "      <td id=\"T_5b7a7_row4_col11\" class=\"data row4 col11\" >0.95</td>\n",
       "      <td id=\"T_5b7a7_row4_col12\" class=\"data row4 col12\" >0.99</td>\n",
       "      <td id=\"T_5b7a7_row4_col13\" class=\"data row4 col13\" >-0.37</td>\n",
       "      <td id=\"T_5b7a7_row4_col14\" class=\"data row4 col14\" >0.57</td>\n",
       "      <td id=\"T_5b7a7_row4_col15\" class=\"data row4 col15\" >-0.71</td>\n",
       "      <td id=\"T_5b7a7_row4_col16\" class=\"data row4 col16\" >0.44</td>\n",
       "      <td id=\"T_5b7a7_row4_col17\" class=\"data row4 col17\" >-0.26</td>\n",
       "      <td id=\"T_5b7a7_row4_col18\" class=\"data row4 col18\" >-0.89</td>\n",
       "      <td id=\"T_5b7a7_row4_col19\" class=\"data row4 col19\" >0.33</td>\n",
       "      <td id=\"T_5b7a7_row4_col20\" class=\"data row4 col20\" >0.45</td>\n",
       "      <td id=\"T_5b7a7_row4_col21\" class=\"data row4 col21\" >-0.42</td>\n",
       "      <td id=\"T_5b7a7_row4_col22\" class=\"data row4 col22\" >-0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row5\" class=\"row_heading level0 row5\" >CO_HistogramAMI_even_2_5</th>\n",
       "      <td id=\"T_5b7a7_row5_col0\" class=\"data row5 col0\" >-0.47</td>\n",
       "      <td id=\"T_5b7a7_row5_col1\" class=\"data row5 col1\" >-0.85</td>\n",
       "      <td id=\"T_5b7a7_row5_col2\" class=\"data row5 col2\" >-0.78</td>\n",
       "      <td id=\"T_5b7a7_row5_col3\" class=\"data row5 col3\" >0.27</td>\n",
       "      <td id=\"T_5b7a7_row5_col4\" class=\"data row5 col4\" >0.89</td>\n",
       "      <td id=\"T_5b7a7_row5_col5\" class=\"data row5 col5\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row5_col6\" class=\"data row5 col6\" >-0.02</td>\n",
       "      <td id=\"T_5b7a7_row5_col7\" class=\"data row5 col7\" >-0.57</td>\n",
       "      <td id=\"T_5b7a7_row5_col8\" class=\"data row5 col8\" >0.59</td>\n",
       "      <td id=\"T_5b7a7_row5_col9\" class=\"data row5 col9\" >0.89</td>\n",
       "      <td id=\"T_5b7a7_row5_col10\" class=\"data row5 col10\" >-0.66</td>\n",
       "      <td id=\"T_5b7a7_row5_col11\" class=\"data row5 col11\" >0.92</td>\n",
       "      <td id=\"T_5b7a7_row5_col12\" class=\"data row5 col12\" >0.91</td>\n",
       "      <td id=\"T_5b7a7_row5_col13\" class=\"data row5 col13\" >-0.27</td>\n",
       "      <td id=\"T_5b7a7_row5_col14\" class=\"data row5 col14\" >0.40</td>\n",
       "      <td id=\"T_5b7a7_row5_col15\" class=\"data row5 col15\" >-0.50</td>\n",
       "      <td id=\"T_5b7a7_row5_col16\" class=\"data row5 col16\" >0.69</td>\n",
       "      <td id=\"T_5b7a7_row5_col17\" class=\"data row5 col17\" >-0.45</td>\n",
       "      <td id=\"T_5b7a7_row5_col18\" class=\"data row5 col18\" >-0.76</td>\n",
       "      <td id=\"T_5b7a7_row5_col19\" class=\"data row5 col19\" >0.17</td>\n",
       "      <td id=\"T_5b7a7_row5_col20\" class=\"data row5 col20\" >0.29</td>\n",
       "      <td id=\"T_5b7a7_row5_col21\" class=\"data row5 col21\" >-0.53</td>\n",
       "      <td id=\"T_5b7a7_row5_col22\" class=\"data row5 col22\" >-0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row6\" class=\"row_heading level0 row6\" >CO_trev_1_num</th>\n",
       "      <td id=\"T_5b7a7_row6_col0\" class=\"data row6 col0\" >-0.09</td>\n",
       "      <td id=\"T_5b7a7_row6_col1\" class=\"data row6 col1\" >-0.27</td>\n",
       "      <td id=\"T_5b7a7_row6_col2\" class=\"data row6 col2\" >0.52</td>\n",
       "      <td id=\"T_5b7a7_row6_col3\" class=\"data row6 col3\" >0.28</td>\n",
       "      <td id=\"T_5b7a7_row6_col4\" class=\"data row6 col4\" >0.12</td>\n",
       "      <td id=\"T_5b7a7_row6_col5\" class=\"data row6 col5\" >-0.02</td>\n",
       "      <td id=\"T_5b7a7_row6_col6\" class=\"data row6 col6\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row6_col7\" class=\"data row6 col7\" >-0.22</td>\n",
       "      <td id=\"T_5b7a7_row6_col8\" class=\"data row6 col8\" >0.28</td>\n",
       "      <td id=\"T_5b7a7_row6_col9\" class=\"data row6 col9\" >-0.34</td>\n",
       "      <td id=\"T_5b7a7_row6_col10\" class=\"data row6 col10\" >0.13</td>\n",
       "      <td id=\"T_5b7a7_row6_col11\" class=\"data row6 col11\" >0.22</td>\n",
       "      <td id=\"T_5b7a7_row6_col12\" class=\"data row6 col12\" >0.09</td>\n",
       "      <td id=\"T_5b7a7_row6_col13\" class=\"data row6 col13\" >0.02</td>\n",
       "      <td id=\"T_5b7a7_row6_col14\" class=\"data row6 col14\" >0.79</td>\n",
       "      <td id=\"T_5b7a7_row6_col15\" class=\"data row6 col15\" >-0.54</td>\n",
       "      <td id=\"T_5b7a7_row6_col16\" class=\"data row6 col16\" >0.37</td>\n",
       "      <td id=\"T_5b7a7_row6_col17\" class=\"data row6 col17\" >0.06</td>\n",
       "      <td id=\"T_5b7a7_row6_col18\" class=\"data row6 col18\" >-0.25</td>\n",
       "      <td id=\"T_5b7a7_row6_col19\" class=\"data row6 col19\" >0.71</td>\n",
       "      <td id=\"T_5b7a7_row6_col20\" class=\"data row6 col20\" >0.23</td>\n",
       "      <td id=\"T_5b7a7_row6_col21\" class=\"data row6 col21\" >-0.44</td>\n",
       "      <td id=\"T_5b7a7_row6_col22\" class=\"data row6 col22\" >-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row7\" class=\"row_heading level0 row7\" >MD_hrv_classic_pnn40</th>\n",
       "      <td id=\"T_5b7a7_row7_col0\" class=\"data row7 col0\" >-0.01</td>\n",
       "      <td id=\"T_5b7a7_row7_col1\" class=\"data row7 col1\" >0.60</td>\n",
       "      <td id=\"T_5b7a7_row7_col2\" class=\"data row7 col2\" >0.09</td>\n",
       "      <td id=\"T_5b7a7_row7_col3\" class=\"data row7 col3\" >-0.35</td>\n",
       "      <td id=\"T_5b7a7_row7_col4\" class=\"data row7 col4\" >-0.84</td>\n",
       "      <td id=\"T_5b7a7_row7_col5\" class=\"data row7 col5\" >-0.57</td>\n",
       "      <td id=\"T_5b7a7_row7_col6\" class=\"data row7 col6\" >-0.22</td>\n",
       "      <td id=\"T_5b7a7_row7_col7\" class=\"data row7 col7\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row7_col8\" class=\"data row7 col8\" >-0.62</td>\n",
       "      <td id=\"T_5b7a7_row7_col9\" class=\"data row7 col9\" >-0.49</td>\n",
       "      <td id=\"T_5b7a7_row7_col10\" class=\"data row7 col10\" >0.15</td>\n",
       "      <td id=\"T_5b7a7_row7_col11\" class=\"data row7 col11\" >-0.76</td>\n",
       "      <td id=\"T_5b7a7_row7_col12\" class=\"data row7 col12\" >-0.81</td>\n",
       "      <td id=\"T_5b7a7_row7_col13\" class=\"data row7 col13\" >0.17</td>\n",
       "      <td id=\"T_5b7a7_row7_col14\" class=\"data row7 col14\" >-0.46</td>\n",
       "      <td id=\"T_5b7a7_row7_col15\" class=\"data row7 col15\" >0.81</td>\n",
       "      <td id=\"T_5b7a7_row7_col16\" class=\"data row7 col16\" >-0.22</td>\n",
       "      <td id=\"T_5b7a7_row7_col17\" class=\"data row7 col17\" >-0.05</td>\n",
       "      <td id=\"T_5b7a7_row7_col18\" class=\"data row7 col18\" >0.93</td>\n",
       "      <td id=\"T_5b7a7_row7_col19\" class=\"data row7 col19\" >-0.44</td>\n",
       "      <td id=\"T_5b7a7_row7_col20\" class=\"data row7 col20\" >-0.65</td>\n",
       "      <td id=\"T_5b7a7_row7_col21\" class=\"data row7 col21\" >0.15</td>\n",
       "      <td id=\"T_5b7a7_row7_col22\" class=\"data row7 col22\" >0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row8\" class=\"row_heading level0 row8\" >SB_BinaryStats_mean_longstretch1</th>\n",
       "      <td id=\"T_5b7a7_row8_col0\" class=\"data row8 col0\" >-0.51</td>\n",
       "      <td id=\"T_5b7a7_row8_col1\" class=\"data row8 col1\" >-0.57</td>\n",
       "      <td id=\"T_5b7a7_row8_col2\" class=\"data row8 col2\" >-0.25</td>\n",
       "      <td id=\"T_5b7a7_row8_col3\" class=\"data row8 col3\" >0.91</td>\n",
       "      <td id=\"T_5b7a7_row8_col4\" class=\"data row8 col4\" >0.72</td>\n",
       "      <td id=\"T_5b7a7_row8_col5\" class=\"data row8 col5\" >0.59</td>\n",
       "      <td id=\"T_5b7a7_row8_col6\" class=\"data row8 col6\" >0.28</td>\n",
       "      <td id=\"T_5b7a7_row8_col7\" class=\"data row8 col7\" >-0.62</td>\n",
       "      <td id=\"T_5b7a7_row8_col8\" class=\"data row8 col8\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row8_col9\" class=\"data row8 col9\" >0.49</td>\n",
       "      <td id=\"T_5b7a7_row8_col10\" class=\"data row8 col10\" >-0.26</td>\n",
       "      <td id=\"T_5b7a7_row8_col11\" class=\"data row8 col11\" >0.62</td>\n",
       "      <td id=\"T_5b7a7_row8_col12\" class=\"data row8 col12\" >0.79</td>\n",
       "      <td id=\"T_5b7a7_row8_col13\" class=\"data row8 col13\" >-0.61</td>\n",
       "      <td id=\"T_5b7a7_row8_col14\" class=\"data row8 col14\" >0.55</td>\n",
       "      <td id=\"T_5b7a7_row8_col15\" class=\"data row8 col15\" >-0.58</td>\n",
       "      <td id=\"T_5b7a7_row8_col16\" class=\"data row8 col16\" >0.32</td>\n",
       "      <td id=\"T_5b7a7_row8_col17\" class=\"data row8 col17\" >-0.43</td>\n",
       "      <td id=\"T_5b7a7_row8_col18\" class=\"data row8 col18\" >-0.60</td>\n",
       "      <td id=\"T_5b7a7_row8_col19\" class=\"data row8 col19\" >0.47</td>\n",
       "      <td id=\"T_5b7a7_row8_col20\" class=\"data row8 col20\" >0.09</td>\n",
       "      <td id=\"T_5b7a7_row8_col21\" class=\"data row8 col21\" >-0.69</td>\n",
       "      <td id=\"T_5b7a7_row8_col22\" class=\"data row8 col22\" >-0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row9\" class=\"row_heading level0 row9\" >SB_TransitionMatrix_3ac_sumdiagcov</th>\n",
       "      <td id=\"T_5b7a7_row9_col0\" class=\"data row9 col0\" >-0.34</td>\n",
       "      <td id=\"T_5b7a7_row9_col1\" class=\"data row9 col1\" >-0.54</td>\n",
       "      <td id=\"T_5b7a7_row9_col2\" class=\"data row9 col2\" >-0.81</td>\n",
       "      <td id=\"T_5b7a7_row9_col3\" class=\"data row9 col3\" >0.19</td>\n",
       "      <td id=\"T_5b7a7_row9_col4\" class=\"data row9 col4\" >0.82</td>\n",
       "      <td id=\"T_5b7a7_row9_col5\" class=\"data row9 col5\" >0.89</td>\n",
       "      <td id=\"T_5b7a7_row9_col6\" class=\"data row9 col6\" >-0.34</td>\n",
       "      <td id=\"T_5b7a7_row9_col7\" class=\"data row9 col7\" >-0.49</td>\n",
       "      <td id=\"T_5b7a7_row9_col8\" class=\"data row9 col8\" >0.49</td>\n",
       "      <td id=\"T_5b7a7_row9_col9\" class=\"data row9 col9\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row9_col10\" class=\"data row9 col10\" >-0.82</td>\n",
       "      <td id=\"T_5b7a7_row9_col11\" class=\"data row9 col11\" >0.72</td>\n",
       "      <td id=\"T_5b7a7_row9_col12\" class=\"data row9 col12\" >0.83</td>\n",
       "      <td id=\"T_5b7a7_row9_col13\" class=\"data row9 col13\" >-0.50</td>\n",
       "      <td id=\"T_5b7a7_row9_col14\" class=\"data row9 col14\" >0.20</td>\n",
       "      <td id=\"T_5b7a7_row9_col15\" class=\"data row9 col15\" >-0.19</td>\n",
       "      <td id=\"T_5b7a7_row9_col16\" class=\"data row9 col16\" >0.37</td>\n",
       "      <td id=\"T_5b7a7_row9_col17\" class=\"data row9 col17\" >-0.57</td>\n",
       "      <td id=\"T_5b7a7_row9_col18\" class=\"data row9 col18\" >-0.56</td>\n",
       "      <td id=\"T_5b7a7_row9_col19\" class=\"data row9 col19\" >-0.22</td>\n",
       "      <td id=\"T_5b7a7_row9_col20\" class=\"data row9 col20\" >0.03</td>\n",
       "      <td id=\"T_5b7a7_row9_col21\" class=\"data row9 col21\" >-0.41</td>\n",
       "      <td id=\"T_5b7a7_row9_col22\" class=\"data row9 col22\" >-0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row10\" class=\"row_heading level0 row10\" >PD_PeriodicityWang_th0_01</th>\n",
       "      <td id=\"T_5b7a7_row10_col0\" class=\"data row10 col0\" >0.31</td>\n",
       "      <td id=\"T_5b7a7_row10_col1\" class=\"data row10 col1\" >0.23</td>\n",
       "      <td id=\"T_5b7a7_row10_col2\" class=\"data row10 col2\" >0.57</td>\n",
       "      <td id=\"T_5b7a7_row10_col3\" class=\"data row10 col3\" >0.00</td>\n",
       "      <td id=\"T_5b7a7_row10_col4\" class=\"data row10 col4\" >-0.56</td>\n",
       "      <td id=\"T_5b7a7_row10_col5\" class=\"data row10 col5\" >-0.66</td>\n",
       "      <td id=\"T_5b7a7_row10_col6\" class=\"data row10 col6\" >0.13</td>\n",
       "      <td id=\"T_5b7a7_row10_col7\" class=\"data row10 col7\" >0.15</td>\n",
       "      <td id=\"T_5b7a7_row10_col8\" class=\"data row10 col8\" >-0.26</td>\n",
       "      <td id=\"T_5b7a7_row10_col9\" class=\"data row10 col9\" >-0.82</td>\n",
       "      <td id=\"T_5b7a7_row10_col10\" class=\"data row10 col10\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row10_col11\" class=\"data row10 col11\" >-0.46</td>\n",
       "      <td id=\"T_5b7a7_row10_col12\" class=\"data row10 col12\" >-0.54</td>\n",
       "      <td id=\"T_5b7a7_row10_col13\" class=\"data row10 col13\" >0.64</td>\n",
       "      <td id=\"T_5b7a7_row10_col14\" class=\"data row10 col14\" >-0.39</td>\n",
       "      <td id=\"T_5b7a7_row10_col15\" class=\"data row10 col15\" >-0.10</td>\n",
       "      <td id=\"T_5b7a7_row10_col16\" class=\"data row10 col16\" >-0.28</td>\n",
       "      <td id=\"T_5b7a7_row10_col17\" class=\"data row10 col17\" >0.72</td>\n",
       "      <td id=\"T_5b7a7_row10_col18\" class=\"data row10 col18\" >0.19</td>\n",
       "      <td id=\"T_5b7a7_row10_col19\" class=\"data row10 col19\" >0.40</td>\n",
       "      <td id=\"T_5b7a7_row10_col20\" class=\"data row10 col20\" >0.32</td>\n",
       "      <td id=\"T_5b7a7_row10_col21\" class=\"data row10 col21\" >0.53</td>\n",
       "      <td id=\"T_5b7a7_row10_col22\" class=\"data row10 col22\" >0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row11\" class=\"row_heading level0 row11\" >CO_Embed2_Dist_tau_d_expfit_meandiff</th>\n",
       "      <td id=\"T_5b7a7_row11_col0\" class=\"data row11 col0\" >-0.46</td>\n",
       "      <td id=\"T_5b7a7_row11_col1\" class=\"data row11 col1\" >-0.89</td>\n",
       "      <td id=\"T_5b7a7_row11_col2\" class=\"data row11 col2\" >-0.49</td>\n",
       "      <td id=\"T_5b7a7_row11_col3\" class=\"data row11 col3\" >0.27</td>\n",
       "      <td id=\"T_5b7a7_row11_col4\" class=\"data row11 col4\" >0.95</td>\n",
       "      <td id=\"T_5b7a7_row11_col5\" class=\"data row11 col5\" >0.92</td>\n",
       "      <td id=\"T_5b7a7_row11_col6\" class=\"data row11 col6\" >0.22</td>\n",
       "      <td id=\"T_5b7a7_row11_col7\" class=\"data row11 col7\" >-0.76</td>\n",
       "      <td id=\"T_5b7a7_row11_col8\" class=\"data row11 col8\" >0.62</td>\n",
       "      <td id=\"T_5b7a7_row11_col9\" class=\"data row11 col9\" >0.72</td>\n",
       "      <td id=\"T_5b7a7_row11_col10\" class=\"data row11 col10\" >-0.46</td>\n",
       "      <td id=\"T_5b7a7_row11_col11\" class=\"data row11 col11\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row11_col12\" class=\"data row11 col12\" >0.93</td>\n",
       "      <td id=\"T_5b7a7_row11_col13\" class=\"data row11 col13\" >-0.12</td>\n",
       "      <td id=\"T_5b7a7_row11_col14\" class=\"data row11 col14\" >0.58</td>\n",
       "      <td id=\"T_5b7a7_row11_col15\" class=\"data row11 col15\" >-0.79</td>\n",
       "      <td id=\"T_5b7a7_row11_col16\" class=\"data row11 col16\" >0.62</td>\n",
       "      <td id=\"T_5b7a7_row11_col17\" class=\"data row11 col17\" >-0.14</td>\n",
       "      <td id=\"T_5b7a7_row11_col18\" class=\"data row11 col18\" >-0.91</td>\n",
       "      <td id=\"T_5b7a7_row11_col19\" class=\"data row11 col19\" >0.48</td>\n",
       "      <td id=\"T_5b7a7_row11_col20\" class=\"data row11 col20\" >0.59</td>\n",
       "      <td id=\"T_5b7a7_row11_col21\" class=\"data row11 col21\" >-0.40</td>\n",
       "      <td id=\"T_5b7a7_row11_col22\" class=\"data row11 col22\" >-0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row12\" class=\"row_heading level0 row12\" >IN_AutoMutualInfoStats_40_gaussian_fmmi</th>\n",
       "      <td id=\"T_5b7a7_row12_col0\" class=\"data row12 col0\" >-0.42</td>\n",
       "      <td id=\"T_5b7a7_row12_col1\" class=\"data row12 col1\" >-0.78</td>\n",
       "      <td id=\"T_5b7a7_row12_col2\" class=\"data row12 col2\" >-0.53</td>\n",
       "      <td id=\"T_5b7a7_row12_col3\" class=\"data row12 col3\" >0.48</td>\n",
       "      <td id=\"T_5b7a7_row12_col4\" class=\"data row12 col4\" >0.99</td>\n",
       "      <td id=\"T_5b7a7_row12_col5\" class=\"data row12 col5\" >0.91</td>\n",
       "      <td id=\"T_5b7a7_row12_col6\" class=\"data row12 col6\" >0.09</td>\n",
       "      <td id=\"T_5b7a7_row12_col7\" class=\"data row12 col7\" >-0.81</td>\n",
       "      <td id=\"T_5b7a7_row12_col8\" class=\"data row12 col8\" >0.79</td>\n",
       "      <td id=\"T_5b7a7_row12_col9\" class=\"data row12 col9\" >0.83</td>\n",
       "      <td id=\"T_5b7a7_row12_col10\" class=\"data row12 col10\" >-0.54</td>\n",
       "      <td id=\"T_5b7a7_row12_col11\" class=\"data row12 col11\" >0.93</td>\n",
       "      <td id=\"T_5b7a7_row12_col12\" class=\"data row12 col12\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row12_col13\" class=\"data row12 col13\" >-0.42</td>\n",
       "      <td id=\"T_5b7a7_row12_col14\" class=\"data row12 col14\" >0.52</td>\n",
       "      <td id=\"T_5b7a7_row12_col15\" class=\"data row12 col15\" >-0.68</td>\n",
       "      <td id=\"T_5b7a7_row12_col16\" class=\"data row12 col16\" >0.48</td>\n",
       "      <td id=\"T_5b7a7_row12_col17\" class=\"data row12 col17\" >-0.34</td>\n",
       "      <td id=\"T_5b7a7_row12_col18\" class=\"data row12 col18\" >-0.87</td>\n",
       "      <td id=\"T_5b7a7_row12_col19\" class=\"data row12 col19\" >0.32</td>\n",
       "      <td id=\"T_5b7a7_row12_col20\" class=\"data row12 col20\" >0.38</td>\n",
       "      <td id=\"T_5b7a7_row12_col21\" class=\"data row12 col21\" >-0.50</td>\n",
       "      <td id=\"T_5b7a7_row12_col22\" class=\"data row12 col22\" >-0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row13\" class=\"row_heading level0 row13\" >FC_LocalSimple_mean1_tauresrat</th>\n",
       "      <td id=\"T_5b7a7_row13_col0\" class=\"data row13 col0\" >0.26</td>\n",
       "      <td id=\"T_5b7a7_row13_col1\" class=\"data row13 col1\" >-0.09</td>\n",
       "      <td id=\"T_5b7a7_row13_col2\" class=\"data row13 col2\" >0.17</td>\n",
       "      <td id=\"T_5b7a7_row13_col3\" class=\"data row13 col3\" >-0.58</td>\n",
       "      <td id=\"T_5b7a7_row13_col4\" class=\"data row13 col4\" >-0.37</td>\n",
       "      <td id=\"T_5b7a7_row13_col5\" class=\"data row13 col5\" >-0.27</td>\n",
       "      <td id=\"T_5b7a7_row13_col6\" class=\"data row13 col6\" >0.02</td>\n",
       "      <td id=\"T_5b7a7_row13_col7\" class=\"data row13 col7\" >0.17</td>\n",
       "      <td id=\"T_5b7a7_row13_col8\" class=\"data row13 col8\" >-0.61</td>\n",
       "      <td id=\"T_5b7a7_row13_col9\" class=\"data row13 col9\" >-0.50</td>\n",
       "      <td id=\"T_5b7a7_row13_col10\" class=\"data row13 col10\" >0.64</td>\n",
       "      <td id=\"T_5b7a7_row13_col11\" class=\"data row13 col11\" >-0.12</td>\n",
       "      <td id=\"T_5b7a7_row13_col12\" class=\"data row13 col12\" >-0.42</td>\n",
       "      <td id=\"T_5b7a7_row13_col13\" class=\"data row13 col13\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row13_col14\" class=\"data row13 col14\" >-0.39</td>\n",
       "      <td id=\"T_5b7a7_row13_col15\" class=\"data row13 col15\" >-0.14</td>\n",
       "      <td id=\"T_5b7a7_row13_col16\" class=\"data row13 col16\" >0.12</td>\n",
       "      <td id=\"T_5b7a7_row13_col17\" class=\"data row13 col17\" >0.76</td>\n",
       "      <td id=\"T_5b7a7_row13_col18\" class=\"data row13 col18\" >0.00</td>\n",
       "      <td id=\"T_5b7a7_row13_col19\" class=\"data row13 col19\" >0.28</td>\n",
       "      <td id=\"T_5b7a7_row13_col20\" class=\"data row13 col20\" >0.58</td>\n",
       "      <td id=\"T_5b7a7_row13_col21\" class=\"data row13 col21\" >0.64</td>\n",
       "      <td id=\"T_5b7a7_row13_col22\" class=\"data row13 col22\" >0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row14\" class=\"row_heading level0 row14\" >DN_OutlierInclude_p_001_mdrmd</th>\n",
       "      <td id=\"T_5b7a7_row14_col0\" class=\"data row14 col0\" >-0.42</td>\n",
       "      <td id=\"T_5b7a7_row14_col1\" class=\"data row14 col1\" >-0.40</td>\n",
       "      <td id=\"T_5b7a7_row14_col2\" class=\"data row14 col2\" >0.20</td>\n",
       "      <td id=\"T_5b7a7_row14_col3\" class=\"data row14 col3\" >0.37</td>\n",
       "      <td id=\"T_5b7a7_row14_col4\" class=\"data row14 col4\" >0.57</td>\n",
       "      <td id=\"T_5b7a7_row14_col5\" class=\"data row14 col5\" >0.40</td>\n",
       "      <td id=\"T_5b7a7_row14_col6\" class=\"data row14 col6\" >0.79</td>\n",
       "      <td id=\"T_5b7a7_row14_col7\" class=\"data row14 col7\" >-0.46</td>\n",
       "      <td id=\"T_5b7a7_row14_col8\" class=\"data row14 col8\" >0.55</td>\n",
       "      <td id=\"T_5b7a7_row14_col9\" class=\"data row14 col9\" >0.20</td>\n",
       "      <td id=\"T_5b7a7_row14_col10\" class=\"data row14 col10\" >-0.39</td>\n",
       "      <td id=\"T_5b7a7_row14_col11\" class=\"data row14 col11\" >0.58</td>\n",
       "      <td id=\"T_5b7a7_row14_col12\" class=\"data row14 col12\" >0.52</td>\n",
       "      <td id=\"T_5b7a7_row14_col13\" class=\"data row14 col13\" >-0.39</td>\n",
       "      <td id=\"T_5b7a7_row14_col14\" class=\"data row14 col14\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row14_col15\" class=\"data row14 col15\" >-0.62</td>\n",
       "      <td id=\"T_5b7a7_row14_col16\" class=\"data row14 col16\" >0.35</td>\n",
       "      <td id=\"T_5b7a7_row14_col17\" class=\"data row14 col17\" >-0.19</td>\n",
       "      <td id=\"T_5b7a7_row14_col18\" class=\"data row14 col18\" >-0.46</td>\n",
       "      <td id=\"T_5b7a7_row14_col19\" class=\"data row14 col19\" >0.56</td>\n",
       "      <td id=\"T_5b7a7_row14_col20\" class=\"data row14 col20\" >0.19</td>\n",
       "      <td id=\"T_5b7a7_row14_col21\" class=\"data row14 col21\" >-0.60</td>\n",
       "      <td id=\"T_5b7a7_row14_col22\" class=\"data row14 col22\" >-0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row15\" class=\"row_heading level0 row15\" >DN_OutlierInclude_n_001_mdrmd</th>\n",
       "      <td id=\"T_5b7a7_row15_col0\" class=\"data row15 col0\" >0.30</td>\n",
       "      <td id=\"T_5b7a7_row15_col1\" class=\"data row15 col1\" >0.73</td>\n",
       "      <td id=\"T_5b7a7_row15_col2\" class=\"data row15 col2\" >-0.06</td>\n",
       "      <td id=\"T_5b7a7_row15_col3\" class=\"data row15 col3\" >-0.36</td>\n",
       "      <td id=\"T_5b7a7_row15_col4\" class=\"data row15 col4\" >-0.71</td>\n",
       "      <td id=\"T_5b7a7_row15_col5\" class=\"data row15 col5\" >-0.50</td>\n",
       "      <td id=\"T_5b7a7_row15_col6\" class=\"data row15 col6\" >-0.54</td>\n",
       "      <td id=\"T_5b7a7_row15_col7\" class=\"data row15 col7\" >0.81</td>\n",
       "      <td id=\"T_5b7a7_row15_col8\" class=\"data row15 col8\" >-0.58</td>\n",
       "      <td id=\"T_5b7a7_row15_col9\" class=\"data row15 col9\" >-0.19</td>\n",
       "      <td id=\"T_5b7a7_row15_col10\" class=\"data row15 col10\" >-0.10</td>\n",
       "      <td id=\"T_5b7a7_row15_col11\" class=\"data row15 col11\" >-0.79</td>\n",
       "      <td id=\"T_5b7a7_row15_col12\" class=\"data row15 col12\" >-0.68</td>\n",
       "      <td id=\"T_5b7a7_row15_col13\" class=\"data row15 col13\" >-0.14</td>\n",
       "      <td id=\"T_5b7a7_row15_col14\" class=\"data row15 col14\" >-0.62</td>\n",
       "      <td id=\"T_5b7a7_row15_col15\" class=\"data row15 col15\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row15_col16\" class=\"data row15 col16\" >-0.40</td>\n",
       "      <td id=\"T_5b7a7_row15_col17\" class=\"data row15 col17\" >-0.31</td>\n",
       "      <td id=\"T_5b7a7_row15_col18\" class=\"data row15 col18\" >0.87</td>\n",
       "      <td id=\"T_5b7a7_row15_col19\" class=\"data row15 col19\" >-0.86</td>\n",
       "      <td id=\"T_5b7a7_row15_col20\" class=\"data row15 col20\" >-0.83</td>\n",
       "      <td id=\"T_5b7a7_row15_col21\" class=\"data row15 col21\" >0.16</td>\n",
       "      <td id=\"T_5b7a7_row15_col22\" class=\"data row15 col22\" >0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row16\" class=\"row_heading level0 row16\" >SP_Summaries_welch_rect_area_5_1</th>\n",
       "      <td id=\"T_5b7a7_row16_col0\" class=\"data row16 col0\" >-0.23</td>\n",
       "      <td id=\"T_5b7a7_row16_col1\" class=\"data row16 col1\" >-0.86</td>\n",
       "      <td id=\"T_5b7a7_row16_col2\" class=\"data row16 col2\" >-0.55</td>\n",
       "      <td id=\"T_5b7a7_row16_col3\" class=\"data row16 col3\" >0.17</td>\n",
       "      <td id=\"T_5b7a7_row16_col4\" class=\"data row16 col4\" >0.44</td>\n",
       "      <td id=\"T_5b7a7_row16_col5\" class=\"data row16 col5\" >0.69</td>\n",
       "      <td id=\"T_5b7a7_row16_col6\" class=\"data row16 col6\" >0.37</td>\n",
       "      <td id=\"T_5b7a7_row16_col7\" class=\"data row16 col7\" >-0.22</td>\n",
       "      <td id=\"T_5b7a7_row16_col8\" class=\"data row16 col8\" >0.32</td>\n",
       "      <td id=\"T_5b7a7_row16_col9\" class=\"data row16 col9\" >0.37</td>\n",
       "      <td id=\"T_5b7a7_row16_col10\" class=\"data row16 col10\" >-0.28</td>\n",
       "      <td id=\"T_5b7a7_row16_col11\" class=\"data row16 col11\" >0.62</td>\n",
       "      <td id=\"T_5b7a7_row16_col12\" class=\"data row16 col12\" >0.48</td>\n",
       "      <td id=\"T_5b7a7_row16_col13\" class=\"data row16 col13\" >0.12</td>\n",
       "      <td id=\"T_5b7a7_row16_col14\" class=\"data row16 col14\" >0.35</td>\n",
       "      <td id=\"T_5b7a7_row16_col15\" class=\"data row16 col15\" >-0.40</td>\n",
       "      <td id=\"T_5b7a7_row16_col16\" class=\"data row16 col16\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row16_col17\" class=\"data row16 col17\" >-0.38</td>\n",
       "      <td id=\"T_5b7a7_row16_col18\" class=\"data row16 col18\" >-0.53</td>\n",
       "      <td id=\"T_5b7a7_row16_col19\" class=\"data row16 col19\" >0.36</td>\n",
       "      <td id=\"T_5b7a7_row16_col20\" class=\"data row16 col20\" >0.22</td>\n",
       "      <td id=\"T_5b7a7_row16_col21\" class=\"data row16 col21\" >-0.62</td>\n",
       "      <td id=\"T_5b7a7_row16_col22\" class=\"data row16 col22\" >-0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row17\" class=\"row_heading level0 row17\" >SB_BinaryStats_diff_longstretch0</th>\n",
       "      <td id=\"T_5b7a7_row17_col0\" class=\"data row17 col0\" >0.15</td>\n",
       "      <td id=\"T_5b7a7_row17_col1\" class=\"data row17 col1\" >0.17</td>\n",
       "      <td id=\"T_5b7a7_row17_col2\" class=\"data row17 col2\" >0.55</td>\n",
       "      <td id=\"T_5b7a7_row17_col3\" class=\"data row17 col3\" >-0.41</td>\n",
       "      <td id=\"T_5b7a7_row17_col4\" class=\"data row17 col4\" >-0.26</td>\n",
       "      <td id=\"T_5b7a7_row17_col5\" class=\"data row17 col5\" >-0.45</td>\n",
       "      <td id=\"T_5b7a7_row17_col6\" class=\"data row17 col6\" >0.06</td>\n",
       "      <td id=\"T_5b7a7_row17_col7\" class=\"data row17 col7\" >-0.05</td>\n",
       "      <td id=\"T_5b7a7_row17_col8\" class=\"data row17 col8\" >-0.43</td>\n",
       "      <td id=\"T_5b7a7_row17_col9\" class=\"data row17 col9\" >-0.57</td>\n",
       "      <td id=\"T_5b7a7_row17_col10\" class=\"data row17 col10\" >0.72</td>\n",
       "      <td id=\"T_5b7a7_row17_col11\" class=\"data row17 col11\" >-0.14</td>\n",
       "      <td id=\"T_5b7a7_row17_col12\" class=\"data row17 col12\" >-0.34</td>\n",
       "      <td id=\"T_5b7a7_row17_col13\" class=\"data row17 col13\" >0.76</td>\n",
       "      <td id=\"T_5b7a7_row17_col14\" class=\"data row17 col14\" >-0.19</td>\n",
       "      <td id=\"T_5b7a7_row17_col15\" class=\"data row17 col15\" >-0.31</td>\n",
       "      <td id=\"T_5b7a7_row17_col16\" class=\"data row17 col16\" >-0.38</td>\n",
       "      <td id=\"T_5b7a7_row17_col17\" class=\"data row17 col17\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row17_col18\" class=\"data row17 col18\" >-0.02</td>\n",
       "      <td id=\"T_5b7a7_row17_col19\" class=\"data row17 col19\" >0.40</td>\n",
       "      <td id=\"T_5b7a7_row17_col20\" class=\"data row17 col20\" >0.68</td>\n",
       "      <td id=\"T_5b7a7_row17_col21\" class=\"data row17 col21\" >0.82</td>\n",
       "      <td id=\"T_5b7a7_row17_col22\" class=\"data row17 col22\" >0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row18\" class=\"row_heading level0 row18\" >SB_MotifThree_quantile_hh</th>\n",
       "      <td id=\"T_5b7a7_row18_col0\" class=\"data row18 col0\" >0.14</td>\n",
       "      <td id=\"T_5b7a7_row18_col1\" class=\"data row18 col1\" >0.85</td>\n",
       "      <td id=\"T_5b7a7_row18_col2\" class=\"data row18 col2\" >0.31</td>\n",
       "      <td id=\"T_5b7a7_row18_col3\" class=\"data row18 col3\" >-0.30</td>\n",
       "      <td id=\"T_5b7a7_row18_col4\" class=\"data row18 col4\" >-0.89</td>\n",
       "      <td id=\"T_5b7a7_row18_col5\" class=\"data row18 col5\" >-0.76</td>\n",
       "      <td id=\"T_5b7a7_row18_col6\" class=\"data row18 col6\" >-0.25</td>\n",
       "      <td id=\"T_5b7a7_row18_col7\" class=\"data row18 col7\" >0.93</td>\n",
       "      <td id=\"T_5b7a7_row18_col8\" class=\"data row18 col8\" >-0.60</td>\n",
       "      <td id=\"T_5b7a7_row18_col9\" class=\"data row18 col9\" >-0.56</td>\n",
       "      <td id=\"T_5b7a7_row18_col10\" class=\"data row18 col10\" >0.19</td>\n",
       "      <td id=\"T_5b7a7_row18_col11\" class=\"data row18 col11\" >-0.91</td>\n",
       "      <td id=\"T_5b7a7_row18_col12\" class=\"data row18 col12\" >-0.87</td>\n",
       "      <td id=\"T_5b7a7_row18_col13\" class=\"data row18 col13\" >0.00</td>\n",
       "      <td id=\"T_5b7a7_row18_col14\" class=\"data row18 col14\" >-0.46</td>\n",
       "      <td id=\"T_5b7a7_row18_col15\" class=\"data row18 col15\" >0.87</td>\n",
       "      <td id=\"T_5b7a7_row18_col16\" class=\"data row18 col16\" >-0.53</td>\n",
       "      <td id=\"T_5b7a7_row18_col17\" class=\"data row18 col17\" >-0.02</td>\n",
       "      <td id=\"T_5b7a7_row18_col18\" class=\"data row18 col18\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row18_col19\" class=\"data row18 col19\" >-0.53</td>\n",
       "      <td id=\"T_5b7a7_row18_col20\" class=\"data row18 col20\" >-0.73</td>\n",
       "      <td id=\"T_5b7a7_row18_col21\" class=\"data row18 col21\" >0.24</td>\n",
       "      <td id=\"T_5b7a7_row18_col22\" class=\"data row18 col22\" >0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row19\" class=\"row_heading level0 row19\" >SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1</th>\n",
       "      <td id=\"T_5b7a7_row19_col0\" class=\"data row19 col0\" >-0.40</td>\n",
       "      <td id=\"T_5b7a7_row19_col1\" class=\"data row19 col1\" >-0.56</td>\n",
       "      <td id=\"T_5b7a7_row19_col2\" class=\"data row19 col2\" >0.29</td>\n",
       "      <td id=\"T_5b7a7_row19_col3\" class=\"data row19 col3\" >0.44</td>\n",
       "      <td id=\"T_5b7a7_row19_col4\" class=\"data row19 col4\" >0.33</td>\n",
       "      <td id=\"T_5b7a7_row19_col5\" class=\"data row19 col5\" >0.17</td>\n",
       "      <td id=\"T_5b7a7_row19_col6\" class=\"data row19 col6\" >0.71</td>\n",
       "      <td id=\"T_5b7a7_row19_col7\" class=\"data row19 col7\" >-0.44</td>\n",
       "      <td id=\"T_5b7a7_row19_col8\" class=\"data row19 col8\" >0.47</td>\n",
       "      <td id=\"T_5b7a7_row19_col9\" class=\"data row19 col9\" >-0.22</td>\n",
       "      <td id=\"T_5b7a7_row19_col10\" class=\"data row19 col10\" >0.40</td>\n",
       "      <td id=\"T_5b7a7_row19_col11\" class=\"data row19 col11\" >0.48</td>\n",
       "      <td id=\"T_5b7a7_row19_col12\" class=\"data row19 col12\" >0.32</td>\n",
       "      <td id=\"T_5b7a7_row19_col13\" class=\"data row19 col13\" >0.28</td>\n",
       "      <td id=\"T_5b7a7_row19_col14\" class=\"data row19 col14\" >0.56</td>\n",
       "      <td id=\"T_5b7a7_row19_col15\" class=\"data row19 col15\" >-0.86</td>\n",
       "      <td id=\"T_5b7a7_row19_col16\" class=\"data row19 col16\" >0.36</td>\n",
       "      <td id=\"T_5b7a7_row19_col17\" class=\"data row19 col17\" >0.40</td>\n",
       "      <td id=\"T_5b7a7_row19_col18\" class=\"data row19 col18\" >-0.53</td>\n",
       "      <td id=\"T_5b7a7_row19_col19\" class=\"data row19 col19\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row19_col20\" class=\"data row19 col20\" >0.66</td>\n",
       "      <td id=\"T_5b7a7_row19_col21\" class=\"data row19 col21\" >-0.18</td>\n",
       "      <td id=\"T_5b7a7_row19_col22\" class=\"data row19 col22\" >-0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row20\" class=\"row_heading level0 row20\" >SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1</th>\n",
       "      <td id=\"T_5b7a7_row20_col0\" class=\"data row20 col0\" >-0.02</td>\n",
       "      <td id=\"T_5b7a7_row20_col1\" class=\"data row20 col1\" >-0.55</td>\n",
       "      <td id=\"T_5b7a7_row20_col2\" class=\"data row20 col2\" >0.08</td>\n",
       "      <td id=\"T_5b7a7_row20_col3\" class=\"data row20 col3\" >-0.13</td>\n",
       "      <td id=\"T_5b7a7_row20_col4\" class=\"data row20 col4\" >0.45</td>\n",
       "      <td id=\"T_5b7a7_row20_col5\" class=\"data row20 col5\" >0.29</td>\n",
       "      <td id=\"T_5b7a7_row20_col6\" class=\"data row20 col6\" >0.23</td>\n",
       "      <td id=\"T_5b7a7_row20_col7\" class=\"data row20 col7\" >-0.65</td>\n",
       "      <td id=\"T_5b7a7_row20_col8\" class=\"data row20 col8\" >0.09</td>\n",
       "      <td id=\"T_5b7a7_row20_col9\" class=\"data row20 col9\" >0.03</td>\n",
       "      <td id=\"T_5b7a7_row20_col10\" class=\"data row20 col10\" >0.32</td>\n",
       "      <td id=\"T_5b7a7_row20_col11\" class=\"data row20 col11\" >0.59</td>\n",
       "      <td id=\"T_5b7a7_row20_col12\" class=\"data row20 col12\" >0.38</td>\n",
       "      <td id=\"T_5b7a7_row20_col13\" class=\"data row20 col13\" >0.58</td>\n",
       "      <td id=\"T_5b7a7_row20_col14\" class=\"data row20 col14\" >0.19</td>\n",
       "      <td id=\"T_5b7a7_row20_col15\" class=\"data row20 col15\" >-0.83</td>\n",
       "      <td id=\"T_5b7a7_row20_col16\" class=\"data row20 col16\" >0.22</td>\n",
       "      <td id=\"T_5b7a7_row20_col17\" class=\"data row20 col17\" >0.68</td>\n",
       "      <td id=\"T_5b7a7_row20_col18\" class=\"data row20 col18\" >-0.73</td>\n",
       "      <td id=\"T_5b7a7_row20_col19\" class=\"data row20 col19\" >0.66</td>\n",
       "      <td id=\"T_5b7a7_row20_col20\" class=\"data row20 col20\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row20_col21\" class=\"data row20 col21\" >0.36</td>\n",
       "      <td id=\"T_5b7a7_row20_col22\" class=\"data row20 col22\" >-0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row21\" class=\"row_heading level0 row21\" >SP_Summaries_welch_rect_centroid</th>\n",
       "      <td id=\"T_5b7a7_row21_col0\" class=\"data row21 col0\" >0.40</td>\n",
       "      <td id=\"T_5b7a7_row21_col1\" class=\"data row21 col1\" >0.47</td>\n",
       "      <td id=\"T_5b7a7_row21_col2\" class=\"data row21 col2\" >0.34</td>\n",
       "      <td id=\"T_5b7a7_row21_col3\" class=\"data row21 col3\" >-0.66</td>\n",
       "      <td id=\"T_5b7a7_row21_col4\" class=\"data row21 col4\" >-0.42</td>\n",
       "      <td id=\"T_5b7a7_row21_col5\" class=\"data row21 col5\" >-0.53</td>\n",
       "      <td id=\"T_5b7a7_row21_col6\" class=\"data row21 col6\" >-0.44</td>\n",
       "      <td id=\"T_5b7a7_row21_col7\" class=\"data row21 col7\" >0.15</td>\n",
       "      <td id=\"T_5b7a7_row21_col8\" class=\"data row21 col8\" >-0.69</td>\n",
       "      <td id=\"T_5b7a7_row21_col9\" class=\"data row21 col9\" >-0.41</td>\n",
       "      <td id=\"T_5b7a7_row21_col10\" class=\"data row21 col10\" >0.53</td>\n",
       "      <td id=\"T_5b7a7_row21_col11\" class=\"data row21 col11\" >-0.40</td>\n",
       "      <td id=\"T_5b7a7_row21_col12\" class=\"data row21 col12\" >-0.50</td>\n",
       "      <td id=\"T_5b7a7_row21_col13\" class=\"data row21 col13\" >0.64</td>\n",
       "      <td id=\"T_5b7a7_row21_col14\" class=\"data row21 col14\" >-0.60</td>\n",
       "      <td id=\"T_5b7a7_row21_col15\" class=\"data row21 col15\" >0.16</td>\n",
       "      <td id=\"T_5b7a7_row21_col16\" class=\"data row21 col16\" >-0.62</td>\n",
       "      <td id=\"T_5b7a7_row21_col17\" class=\"data row21 col17\" >0.82</td>\n",
       "      <td id=\"T_5b7a7_row21_col18\" class=\"data row21 col18\" >0.24</td>\n",
       "      <td id=\"T_5b7a7_row21_col19\" class=\"data row21 col19\" >-0.18</td>\n",
       "      <td id=\"T_5b7a7_row21_col20\" class=\"data row21 col20\" >0.36</td>\n",
       "      <td id=\"T_5b7a7_row21_col21\" class=\"data row21 col21\" >1.00</td>\n",
       "      <td id=\"T_5b7a7_row21_col22\" class=\"data row21 col22\" >0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b7a7_level0_row22\" class=\"row_heading level0 row22\" >FC_LocalSimple_mean3_stderr</th>\n",
       "      <td id=\"T_5b7a7_row22_col0\" class=\"data row22 col0\" >0.49</td>\n",
       "      <td id=\"T_5b7a7_row22_col1\" class=\"data row22 col1\" >0.89</td>\n",
       "      <td id=\"T_5b7a7_row22_col2\" class=\"data row22 col2\" >0.71</td>\n",
       "      <td id=\"T_5b7a7_row22_col3\" class=\"data row22 col3\" >-0.46</td>\n",
       "      <td id=\"T_5b7a7_row22_col4\" class=\"data row22 col4\" >-0.82</td>\n",
       "      <td id=\"T_5b7a7_row22_col5\" class=\"data row22 col5\" >-0.95</td>\n",
       "      <td id=\"T_5b7a7_row22_col6\" class=\"data row22 col6\" >-0.18</td>\n",
       "      <td id=\"T_5b7a7_row22_col7\" class=\"data row22 col7\" >0.51</td>\n",
       "      <td id=\"T_5b7a7_row22_col8\" class=\"data row22 col8\" >-0.70</td>\n",
       "      <td id=\"T_5b7a7_row22_col9\" class=\"data row22 col9\" >-0.77</td>\n",
       "      <td id=\"T_5b7a7_row22_col10\" class=\"data row22 col10\" >0.60</td>\n",
       "      <td id=\"T_5b7a7_row22_col11\" class=\"data row22 col11\" >-0.86</td>\n",
       "      <td id=\"T_5b7a7_row22_col12\" class=\"data row22 col12\" >-0.86</td>\n",
       "      <td id=\"T_5b7a7_row22_col13\" class=\"data row22 col13\" >0.34</td>\n",
       "      <td id=\"T_5b7a7_row22_col14\" class=\"data row22 col14\" >-0.49</td>\n",
       "      <td id=\"T_5b7a7_row22_col15\" class=\"data row22 col15\" >0.50</td>\n",
       "      <td id=\"T_5b7a7_row22_col16\" class=\"data row22 col16\" >-0.81</td>\n",
       "      <td id=\"T_5b7a7_row22_col17\" class=\"data row22 col17\" >0.57</td>\n",
       "      <td id=\"T_5b7a7_row22_col18\" class=\"data row22 col18\" >0.71</td>\n",
       "      <td id=\"T_5b7a7_row22_col19\" class=\"data row22 col19\" >-0.28</td>\n",
       "      <td id=\"T_5b7a7_row22_col20\" class=\"data row22 col20\" >-0.17</td>\n",
       "      <td id=\"T_5b7a7_row22_col21\" class=\"data row22 col21\" >0.74</td>\n",
       "      <td id=\"T_5b7a7_row22_col22\" class=\"data row22 col22\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9d727a1d60>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = data[data['model']=='etsformer'].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = pd.get_dummies(data['dataset'])\n",
    "# data = data.merge(dataset, how='outer',left_index=True, right_index=True)\n",
    "data = data.drop(['dataset'], axis=1)\n",
    "data.model = pd.Categorical(data.model)\n",
    "data['code'] = data.model.cat.codes\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "sss.get_n_splits(data.drop(['model'], axis=1), data['code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seen data, seen model-- not possible, ideally would be same data point except that we perfrom straified split with respect to model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set: seen model, seen dataset(other model type has seen the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.451e-02, tolerance: 1.365e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in sss.split(data.drop(['model'], axis=1), data['code']):\n",
    "    model_type =  pd.get_dummies(data['model'])\n",
    "    data_temp = data.merge(model_type, how='outer',left_index=True, right_index=True)\n",
    "    data_temp = data_temp.drop(['model'], axis=1)\n",
    "    X = np.array(data_temp.drop(['error','code'], axis=1))[train_index]\n",
    "    y = np.array(data_temp['error'])[train_index]\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    clf = linear_model.Lasso(alpha=0.01).fit(X, y)\n",
    "    elastic_net = ElasticNet(alpha=0.04, l1_ratio=0)\n",
    "    #lasso, elastic net,gridsearch on hyperparameter, more statistics, remove onehot encoding(dataset), add ett dataset \n",
    "    #4 quadrants of testing(unseen data, unseen model)\n",
    "    #have some sparsity(lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.912e-02, tolerance: 1.224e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.234e-02, tolerance: 1.339e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.572e-02, tolerance: 1.207e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.709e-02, tolerance: 1.333e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.667e-02, tolerance: 1.263e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.412e-02, tolerance: 1.339e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e-01, tolerance: 1.236e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.907e-02, tolerance: 1.236e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e-01, tolerance: 1.201e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.459e-02, tolerance: 7.734e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e-01, tolerance: 1.325e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e-01, tolerance: 1.314e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.843e-02, tolerance: 7.772e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.419e-02, tolerance: 1.298e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e-01, tolerance: 1.344e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.860e-02, tolerance: 1.297e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.645e-02, tolerance: 1.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e-01, tolerance: 1.347e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e-01, tolerance: 1.338e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.562e-02, tolerance: 1.141e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e-01, tolerance: 1.216e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.768e-02, tolerance: 1.301e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.362e-02, tolerance: 1.339e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.182e-02, tolerance: 1.301e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.114e-02, tolerance: 1.306e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.430e-02, tolerance: 1.185e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e-01, tolerance: 1.328e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.649e-02, tolerance: 1.295e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.051e-01, tolerance: 1.302e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.247e-02, tolerance: 6.800e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    }
   ],
   "source": [
    "temp=pd.DataFrame()\n",
    "temp_test = pd.DataFrame()\n",
    "for i in list(train_index):\n",
    "    temp = temp.append(data.iloc[i,:])\n",
    "for i in list(test_index):\n",
    "    temp_test = temp_test.append(data.iloc[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 31)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "mse prediction: 0.003066365369053558\n",
      "R2 score prediction 0.8598253361568046\n",
      "train\n",
      "mse prediction: 0.0047031640791162154\n",
      "R2 score prediction 0.8415053563768448\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array(data_temp.drop(['error','code'], axis=1))[test_index]\n",
    "y_test = np.array(data_temp['error'])[test_index]\n",
    "y_pred = reg.predict(X_test)\n",
    "y_pred_train = reg.predict(X)\n",
    "print('test')\n",
    "print('mse prediction:',mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 score prediction\", r2_score(y_test, y_pred))\n",
    "print(\"train\")\n",
    "print('mse prediction:',mean_squared_error(y, y_pred_train))\n",
    "print(\"R2 score prediction\", r2_score(y, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse prediction: 0.01121495784816972\n",
      "R2 score prediction 0.6220606558705508\n",
      "test\n",
      "mse prediction: 0.003843848741411195\n",
      "R2 score prediction 0.8242837560620803\n"
     ]
    }
   ],
   "source": [
    "print('mse prediction:',mean_squared_error(y, clf.predict(X)))\n",
    "print(\"R2 score prediction\", r2_score(y, clf.predict(X)))\n",
    "print('test')\n",
    "print('mse prediction:',mean_squared_error(y_test, clf.predict(X_test)))\n",
    "print(\"R2 score prediction\", r2_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DN_HistogramMode_5</td>\n",
       "      <td>0.043583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DN_HistogramMode_10</td>\n",
       "      <td>0.042452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CO_f1ecac</td>\n",
       "      <td>0.047038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CO_FirstMin_ac</td>\n",
       "      <td>0.001108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CO_HistogramAMI_even_2_5</td>\n",
       "      <td>-0.124186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CO_trev_1_num</td>\n",
       "      <td>-0.007017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MD_hrv_classic_pnn40</td>\n",
       "      <td>-0.129038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SB_BinaryStats_mean_longstretch1</td>\n",
       "      <td>-0.021580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SB_TransitionMatrix_3ac_sumdiagcov</td>\n",
       "      <td>-0.008356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PD_PeriodicityWang_th0_01</td>\n",
       "      <td>0.002133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CO_Embed2_Dist_tau_d_expfit_meandiff</td>\n",
       "      <td>-0.188962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IN_AutoMutualInfoStats_40_gaussian_fmmi</td>\n",
       "      <td>-0.021402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FC_LocalSimple_mean1_tauresrat</td>\n",
       "      <td>-0.019408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DN_OutlierInclude_p_001_mdrmd</td>\n",
       "      <td>-0.143741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DN_OutlierInclude_n_001_mdrmd</td>\n",
       "      <td>0.135496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SP_Summaries_welch_rect_area_5_1</td>\n",
       "      <td>0.002466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SB_BinaryStats_diff_longstretch0</td>\n",
       "      <td>-0.022325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SB_MotifThree_quantile_hh</td>\n",
       "      <td>-0.039951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1</td>\n",
       "      <td>-0.068258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1</td>\n",
       "      <td>0.088382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SP_Summaries_welch_rect_centroid</td>\n",
       "      <td>0.005234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FC_LocalSimple_mean3_stderr</td>\n",
       "      <td>0.058855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hopfield</td>\n",
       "      <td>-0.009654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Informer</td>\n",
       "      <td>-0.034336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>etsformer</td>\n",
       "      <td>-0.028966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>favor</td>\n",
       "      <td>0.181248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>linformer</td>\n",
       "      <td>-0.022466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nystorm</td>\n",
       "      <td>0.003766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>switch</td>\n",
       "      <td>-0.056322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>transformer</td>\n",
       "      <td>-0.036966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>xformer</td>\n",
       "      <td>0.003696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       features  coefficient\n",
       "0                            DN_HistogramMode_5     0.043583\n",
       "1                           DN_HistogramMode_10     0.042452\n",
       "2                                     CO_f1ecac     0.047038\n",
       "3                                CO_FirstMin_ac     0.001108\n",
       "4                      CO_HistogramAMI_even_2_5    -0.124186\n",
       "5                                 CO_trev_1_num    -0.007017\n",
       "6                          MD_hrv_classic_pnn40    -0.129038\n",
       "7              SB_BinaryStats_mean_longstretch1    -0.021580\n",
       "8            SB_TransitionMatrix_3ac_sumdiagcov    -0.008356\n",
       "9                     PD_PeriodicityWang_th0_01     0.002133\n",
       "10         CO_Embed2_Dist_tau_d_expfit_meandiff    -0.188962\n",
       "11      IN_AutoMutualInfoStats_40_gaussian_fmmi    -0.021402\n",
       "12               FC_LocalSimple_mean1_tauresrat    -0.019408\n",
       "13                DN_OutlierInclude_p_001_mdrmd    -0.143741\n",
       "14                DN_OutlierInclude_n_001_mdrmd     0.135496\n",
       "15             SP_Summaries_welch_rect_area_5_1     0.002466\n",
       "16             SB_BinaryStats_diff_longstretch0    -0.022325\n",
       "17                    SB_MotifThree_quantile_hh    -0.039951\n",
       "18  SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1    -0.068258\n",
       "19       SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1     0.088382\n",
       "20             SP_Summaries_welch_rect_centroid     0.005234\n",
       "21                  FC_LocalSimple_mean3_stderr     0.058855\n",
       "22                                     Hopfield    -0.009654\n",
       "23                                     Informer    -0.034336\n",
       "24                                    etsformer    -0.028966\n",
       "25                                        favor     0.181248\n",
       "26                                    linformer    -0.022466\n",
       "27                                      nystorm     0.003766\n",
       "28                                       switch    -0.056322\n",
       "29                                  transformer    -0.036966\n",
       "30                                      xformer     0.003696"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame()\n",
    "temp['features'] = list(data_temp.drop(['error','code'], axis=1).columns)\n",
    "temp['coefficient'] = reg.coef_\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'predicted value')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y, y_pred_train)\n",
    "plt.xlabel(\"true value\")\n",
    "plt.ylabel(\"predicted value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'predicted value')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"true value\")\n",
    "plt.ylabel(\"predicted value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set: seen model, unseen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type =  pd.get_dummies(data['model'])\n",
    "data_temp = data.merge(model_type, how='outer',left_index=True, right_index=True)\n",
    "test_data = data_temp[(data_temp['dataset']=='m4_monthly') | (data_temp['dataset']=='solar-energy')].reset_index(drop=True).drop(['model', 'dataset'], axis=1)\n",
    "train_data = data_temp[(data_temp['dataset']!='m4_monthly') & (data_temp['dataset']!='solar-energy')].reset_index(drop=True).drop(['model', 'dataset'], axis=1)\n",
    "reg = LinearRegression().fit(train_data.drop(['error'], axis=1), train_data['error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop(['error'], axis=1)\n",
    "y_test = test_data['error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "y_pred_train = reg.predict(train_data.drop(['error'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse prediction: 0.02077158427613918\n",
      "R2 score prediction 0.30000638039537475\n"
     ]
    }
   ],
   "source": [
    "# print('mse prediction:',mean_squared_error(y, clf.predict(X)))\n",
    "# print(\"R2 score prediction\", r2_score(y, clf.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.11665734437567268\n",
      "R2 score: -1.1167135021320829\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('MSE:',mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.003070154474850132\n",
      "R2 score: 0.7042720034313935\n"
     ]
    }
   ],
   "source": [
    "print('MSE:',mean_squared_error(train_data['error'], y_pred_train))\n",
    "print(\"R2 score:\", r2_score(train_data['error'], y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DN_HistogramMode_5</td>\n",
       "      <td>0.007171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DN_HistogramMode_10</td>\n",
       "      <td>0.011753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CO_f1ecac</td>\n",
       "      <td>-0.049178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CO_FirstMin_ac</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CO_HistogramAMI_even_2_5</td>\n",
       "      <td>-0.009272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CO_trev_1_num</td>\n",
       "      <td>-0.002056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MD_hrv_classic_pnn40</td>\n",
       "      <td>-0.002764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SB_BinaryStats_mean_longstretch1</td>\n",
       "      <td>0.020809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SB_TransitionMatrix_3ac_sumdiagcov</td>\n",
       "      <td>0.000865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PD_PeriodicityWang_th0_01</td>\n",
       "      <td>-0.001315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CO_Embed2_Dist_tau_d_expfit_meandiff</td>\n",
       "      <td>-0.016240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IN_AutoMutualInfoStats_40_gaussian_fmmi</td>\n",
       "      <td>0.013898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FC_LocalSimple_mean1_tauresrat</td>\n",
       "      <td>-0.012343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DN_OutlierInclude_p_001_mdrmd</td>\n",
       "      <td>-0.001450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DN_OutlierInclude_n_001_mdrmd</td>\n",
       "      <td>0.003348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SP_Summaries_welch_rect_area_5_1</td>\n",
       "      <td>-0.004477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SB_BinaryStats_diff_longstretch0</td>\n",
       "      <td>-0.006025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SB_MotifThree_quantile_hh</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1</td>\n",
       "      <td>0.001858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1</td>\n",
       "      <td>0.003005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SP_Summaries_welch_rect_centroid</td>\n",
       "      <td>-0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FC_LocalSimple_mean3_stderr</td>\n",
       "      <td>0.004829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hopfield</td>\n",
       "      <td>-0.013057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Informer</td>\n",
       "      <td>-0.049202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>etsformer</td>\n",
       "      <td>-0.039128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>favor</td>\n",
       "      <td>0.152350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>linformer</td>\n",
       "      <td>-0.025881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nystorm</td>\n",
       "      <td>0.025539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>switch</td>\n",
       "      <td>-0.035053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>transformer</td>\n",
       "      <td>-0.022323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>xformer</td>\n",
       "      <td>0.006755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       features  coefficient\n",
       "0                            DN_HistogramMode_5     0.007171\n",
       "1                           DN_HistogramMode_10     0.011753\n",
       "2                                     CO_f1ecac    -0.049178\n",
       "3                                CO_FirstMin_ac     0.000387\n",
       "4                      CO_HistogramAMI_even_2_5    -0.009272\n",
       "5                                 CO_trev_1_num    -0.002056\n",
       "6                          MD_hrv_classic_pnn40    -0.002764\n",
       "7              SB_BinaryStats_mean_longstretch1     0.020809\n",
       "8            SB_TransitionMatrix_3ac_sumdiagcov     0.000865\n",
       "9                     PD_PeriodicityWang_th0_01    -0.001315\n",
       "10         CO_Embed2_Dist_tau_d_expfit_meandiff    -0.016240\n",
       "11      IN_AutoMutualInfoStats_40_gaussian_fmmi     0.013898\n",
       "12               FC_LocalSimple_mean1_tauresrat    -0.012343\n",
       "13                DN_OutlierInclude_p_001_mdrmd    -0.001450\n",
       "14                DN_OutlierInclude_n_001_mdrmd     0.003348\n",
       "15             SP_Summaries_welch_rect_area_5_1    -0.004477\n",
       "16             SB_BinaryStats_diff_longstretch0    -0.006025\n",
       "17                    SB_MotifThree_quantile_hh     0.000713\n",
       "18  SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1     0.001858\n",
       "19       SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1     0.003005\n",
       "20             SP_Summaries_welch_rect_centroid    -0.000022\n",
       "21                  FC_LocalSimple_mean3_stderr     0.004829\n",
       "22                                     Hopfield    -0.013057\n",
       "23                                     Informer    -0.049202\n",
       "24                                    etsformer    -0.039128\n",
       "25                                        favor     0.152350\n",
       "26                                    linformer    -0.025881\n",
       "27                                      nystorm     0.025539\n",
       "28                                       switch    -0.035053\n",
       "29                                  transformer    -0.022323\n",
       "30                                      xformer     0.006755"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame()\n",
    "temp['features'] = list(train_data.drop(['error'], axis=1).columns)\n",
    "temp['coefficient'] = reg.coef_\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'predicted value')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(train_data['error'], y_pred_train)\n",
    "plt.xlabel(\"true value\")\n",
    "plt.ylabel(\"predicted value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'predicted value')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"true value\")\n",
    "plt.ylabel(\"predicted value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### seen data, unseen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df.csv\")\n",
    "catch22 = pd.read_csv(\"catch22.csv\")\n",
    "data = df.merge(catch22, how='left', on=\"dataset\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data[(data['model']=='linformer')|(data['model']=='Informer')].reset_index(drop=True).drop(['model', 'dataset'], axis=1)\n",
    "train_data = data[(data['model']!='linformer')&(data['model']!='Informer')].reset_index(drop=True).drop(['model', 'dataset'], axis=1)\n",
    "reg = LinearRegression().fit(train_data.drop(['error'], axis=1), train_data['error'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = test_data.drop(['error'], axis=1)\n",
    "y_test = test_data['error']\n",
    "y_pred = reg.predict(X_test)\n",
    "y_pred_train = reg.predict(train_data.drop(['error'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data\n",
      "MSE: 0.0025537650570267665\n",
      "R2 score: 0.8655729155435347\n",
      "Train data\n",
      "MSE: 0.009593137161819719\n",
      "R2 score: 0.6779386154457354\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Test data\")\n",
    "print('MSE:',mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred))\n",
    "print(\"Train data\")\n",
    "print('MSE:',mean_squared_error(train_data['error'], y_pred_train))\n",
    "print(\"R2 score:\", r2_score(train_data['error'], y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'predicted value')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(train_data['error'], y_pred_train)\n",
    "plt.xlabel(\"true value\")\n",
    "plt.ylabel(\"predicted value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'predicted value')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"true value\")\n",
    "plt.ylabel(\"predicted value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unseen data, unseen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data\n",
      "mse prediction: 161.0154794494701\n",
      "R2 score prediction -228523.05479390873\n",
      "Train data\n",
      "mse prediction: 0.00494470582917459\n",
      "R2 score prediction 0.8728741011675101\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"df.csv\")\n",
    "catch22 = pd.read_csv(\"catch22.csv\")\n",
    "data = df.merge(catch22, how='left', on=\"dataset\")\n",
    "model_type =  pd.get_dummies(data['model'])\n",
    "data_temp = data.merge(model_type, how='outer',left_index=True, right_index=True)\n",
    "test_data = data_temp[((data_temp['model']=='linformer')|(data_temp['model']=='Informer') | (data_temp['model']=='nystorm')) & ((data_temp['dataset']=='m4_quarterly') | (data_temp['dataset']=='m4_weekly') | (data_temp['dataset']=='m4_daily'))].reset_index(drop=True).drop(['model', 'dataset'], axis=1)\n",
    "train_data = data_temp[(data_temp['model']!='linformer')&(data_temp['model']!='Informer')&(data_temp['model']!='nystorm')&(data_temp['dataset']!='m4_quarterly')& (data_temp['dataset']!='m4_weekly') & (data_temp['dataset']!='m4_daily')].reset_index(drop=True).drop(['model', 'dataset'], axis=1)\n",
    "\n",
    "train_x = train_data.drop(['error'],axis=1)\n",
    "train_y = train_data['error']\n",
    "test_x = test_data.drop(['error'], axis=1)\n",
    "test_y = test_data['error']\n",
    "\n",
    "\n",
    "reg = LinearRegression().fit(train_x, train_y)\n",
    "y_pred = reg.predict(test_x)\n",
    "y_pred_train = reg.predict(train_x)\n",
    "print(\"Test data\")\n",
    "print('mse prediction:',mean_squared_error(test_y, y_pred))\n",
    "print(\"R2 score prediction\", r2_score(test_y, y_pred))\n",
    "print(\"Train data\")\n",
    "print('mse prediction:',mean_squared_error(train_y, y_pred_train))\n",
    "print(\"R2 score prediction\", r2_score(train_y, y_pred_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 31)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>error</th>\n",
       "      <th>dataset</th>\n",
       "      <th>DN_HistogramMode_5</th>\n",
       "      <th>DN_HistogramMode_10</th>\n",
       "      <th>CO_f1ecac</th>\n",
       "      <th>CO_FirstMin_ac</th>\n",
       "      <th>CO_HistogramAMI_even_2_5</th>\n",
       "      <th>CO_trev_1_num</th>\n",
       "      <th>MD_hrv_classic_pnn40</th>\n",
       "      <th>...</th>\n",
       "      <th>FC_LocalSimple_mean3_stderr</th>\n",
       "      <th>Hopfield</th>\n",
       "      <th>Informer</th>\n",
       "      <th>etsformer</th>\n",
       "      <th>favor</th>\n",
       "      <th>linformer</th>\n",
       "      <th>nystorm</th>\n",
       "      <th>switch</th>\n",
       "      <th>transformer</th>\n",
       "      <th>xformer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Informer</td>\n",
       "      <td>0.031202</td>\n",
       "      <td>m4_daily</td>\n",
       "      <td>-0.172686</td>\n",
       "      <td>-0.206331</td>\n",
       "      <td>290.202151</td>\n",
       "      <td>720.344689</td>\n",
       "      <td>1.074898</td>\n",
       "      <td>-0.029044</td>\n",
       "      <td>0.434763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124719</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Informer</td>\n",
       "      <td>0.060738</td>\n",
       "      <td>m4_weekly</td>\n",
       "      <td>-0.377490</td>\n",
       "      <td>-0.441451</td>\n",
       "      <td>126.895132</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.796780</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>0.532645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296566</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nystorm</td>\n",
       "      <td>0.061235</td>\n",
       "      <td>m4_weekly</td>\n",
       "      <td>-0.377490</td>\n",
       "      <td>-0.441451</td>\n",
       "      <td>126.895132</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.796780</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>0.532645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nystorm</td>\n",
       "      <td>0.101569</td>\n",
       "      <td>m4_quarterly</td>\n",
       "      <td>-0.297725</td>\n",
       "      <td>-0.318503</td>\n",
       "      <td>14.149457</td>\n",
       "      <td>35.428250</td>\n",
       "      <td>0.760510</td>\n",
       "      <td>-0.010422</td>\n",
       "      <td>0.755289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linformer</td>\n",
       "      <td>0.025571</td>\n",
       "      <td>m4_daily</td>\n",
       "      <td>-0.172686</td>\n",
       "      <td>-0.206331</td>\n",
       "      <td>290.202151</td>\n",
       "      <td>720.344689</td>\n",
       "      <td>1.074898</td>\n",
       "      <td>-0.029044</td>\n",
       "      <td>0.434763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124719</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>linformer</td>\n",
       "      <td>0.060072</td>\n",
       "      <td>m4_weekly</td>\n",
       "      <td>-0.377490</td>\n",
       "      <td>-0.441451</td>\n",
       "      <td>126.895132</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.796780</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>0.532645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>linformer</td>\n",
       "      <td>0.094941</td>\n",
       "      <td>m4_quarterly</td>\n",
       "      <td>-0.297725</td>\n",
       "      <td>-0.318503</td>\n",
       "      <td>14.149457</td>\n",
       "      <td>35.428250</td>\n",
       "      <td>0.760510</td>\n",
       "      <td>-0.010422</td>\n",
       "      <td>0.755289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model     error       dataset  DN_HistogramMode_5  DN_HistogramMode_10  \\\n",
       "0   Informer  0.031202      m4_daily           -0.172686            -0.206331   \n",
       "1   Informer  0.060738     m4_weekly           -0.377490            -0.441451   \n",
       "2    nystorm  0.061235     m4_weekly           -0.377490            -0.441451   \n",
       "3    nystorm  0.101569  m4_quarterly           -0.297725            -0.318503   \n",
       "4  linformer  0.025571      m4_daily           -0.172686            -0.206331   \n",
       "5  linformer  0.060072     m4_weekly           -0.377490            -0.441451   \n",
       "6  linformer  0.094941  m4_quarterly           -0.297725            -0.318503   \n",
       "\n",
       "    CO_f1ecac  CO_FirstMin_ac  CO_HistogramAMI_even_2_5  CO_trev_1_num  \\\n",
       "0  290.202151      720.344689                  1.074898      -0.029044   \n",
       "1  126.895132      326.000000                  0.796780       0.008714   \n",
       "2  126.895132      326.000000                  0.796780       0.008714   \n",
       "3   14.149457       35.428250                  0.760510      -0.010422   \n",
       "4  290.202151      720.344689                  1.074898      -0.029044   \n",
       "5  126.895132      326.000000                  0.796780       0.008714   \n",
       "6   14.149457       35.428250                  0.760510      -0.010422   \n",
       "\n",
       "   MD_hrv_classic_pnn40  ...  FC_LocalSimple_mean3_stderr  Hopfield  Informer  \\\n",
       "0              0.434763  ...                     0.124719         0         1   \n",
       "1              0.532645  ...                     0.296566         0         1   \n",
       "2              0.532645  ...                     0.296566         0         0   \n",
       "3              0.755289  ...                     0.386407         0         0   \n",
       "4              0.434763  ...                     0.124719         0         0   \n",
       "5              0.532645  ...                     0.296566         0         0   \n",
       "6              0.755289  ...                     0.386407         0         0   \n",
       "\n",
       "   etsformer  favor  linformer  nystorm  switch  transformer  xformer  \n",
       "0          0      0          0        0       0            0        0  \n",
       "1          0      0          0        0       0            0        0  \n",
       "2          0      0          0        1       0            0        0  \n",
       "3          0      0          0        1       0            0        0  \n",
       "4          0      0          1        0       0            0        0  \n",
       "5          0      0          1        0       0            0        0  \n",
       "6          0      0          1        0       0            0        0  \n",
       "\n",
       "[7 rows x 34 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temp[((data_temp['model']=='linformer')|(data_temp['model']=='Informer') | (data_temp['model']=='nystorm')) & ((data_temp['dataset']=='m4_quarterly') | (data_temp['dataset']=='m4_weekly') | (data_temp['dataset']=='m4_daily'))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -0.01101\n",
      "Config: {'alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in sss.split(data.drop(['model'], axis=1), data['code']):\n",
    "     model_type =  pd.get_dummies(data['model'])\n",
    "     data_temp = data.merge(model_type, how='outer',left_index=True, right_index=True)\n",
    "     data_temp = data_temp.drop(['model'], axis=1)\n",
    "     X = np.array(data_temp.drop(['error','code'], axis=1))[train_index]\n",
    "     y = np.array(data_temp['error'])[train_index]\n",
    "     \n",
    "\n",
    "     sc = StandardScaler()\n",
    "     X_scaled = sc.fit_transform(X)\n",
    "     # X_scaled = pd.DataFrame(data = X_scaled, columns = X.columns)\n",
    "     cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "     lasso_alphas = np.linspace(0, 0.2, 21)\n",
    "     lasso = Lasso()\n",
    "     grid = dict()\n",
    "     grid['alpha'] = lasso_alphas\n",
    "     gscv = GridSearchCV( lasso, grid, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "     results = gscv.fit(X_scaled, y)\n",
    "     print('MSE: %.5f' % results.best_score_)\n",
    "     print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.189e-02, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.197e-02, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.852e-02, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.198e-02, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.096e-02, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.189e-02, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.197e-02, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.852e-02, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.198e-02, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.096e-02, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.189e-02, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.197e-02, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.852e-02, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.198e-02, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.096e-02, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.189e-02, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.197e-02, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.852e-02, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.198e-02, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.096e-02, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.189e-02, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.197e-02, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.852e-02, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.198e-02, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.096e-02, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.718e-02, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.615e-01, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e-01, tolerance: 6.256e-05\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.441e-01, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.354e-01, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e-01, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.081e-03, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.585e-02, tolerance: 6.256e-05\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.684e-04, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e-01, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.540e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.033e-02, tolerance: 6.256e-05\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.758e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.868e-02, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.844e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.423e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.776e-02, tolerance: 6.256e-05\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.367e-02, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.333e-02, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.567e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.392e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.743e-02, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.559e-02, tolerance: 6.256e-05\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.707e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.290e-04, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.227e-02, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.990e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.700e-02, tolerance: 6.256e-05\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.877e-02, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.194e-02, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.445e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.310e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.269e-03, tolerance: 6.256e-05\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.328e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.295e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.444e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.943e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.727e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.360e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.861e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.535e-02, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.508e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.403e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.916e-02, tolerance: 6.256e-05\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.532e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.089e-04, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.349e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.710e-03, tolerance: 6.256e-05\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.543e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.055e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.224e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.061e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.574e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.098e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.021e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.568e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.250e-02, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.682e-02, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.642e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.643e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.522e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.060e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.781e-02, tolerance: 6.256e-05\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.656e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.620e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.614e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.532e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.566e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.127e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.721e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e-01, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.436e-04, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.296e-04, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.764e-04, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.735e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.756e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.632e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.727e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.763e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.513e-02, tolerance: 6.256e-05\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.601e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.106e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.690e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.431e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.974e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.925e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.319e-04, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.815e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.853e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.727e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.831e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.464e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.157e-02, tolerance: 6.256e-05\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.966e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.264e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.280e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e-02, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.176e-02, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.885e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.937e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.921e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.428e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.075e-03, tolerance: 6.256e-05\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.055e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.398e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.753e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.540e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.947e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.189e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.883e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.000e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.605e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.504e-04, tolerance: 6.256e-05\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.122e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.506e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.996e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.091e-04, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.002e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.219e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.078e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.949e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.070e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.961e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.915e-05, tolerance: 6.256e-05\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.161e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.579e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.191e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.052e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.246e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.137e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.007e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.133e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.461e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.167e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.621e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.337e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.191e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.190e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.136e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.626e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.432e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.240e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.108e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.241e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.965e-03, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.074e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.594e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.475e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.178e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.285e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.153e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.288e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.216e-03, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.556e-02, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.596e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.460e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.326e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.331e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.753e-03, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.036e-03, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.447e-02, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.608e-02, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.365e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.371e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.093e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.648e-04, tolerance: 1.105e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.305e-03, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.180e-03, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.278e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.400e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.267e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.408e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.756e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.576e-04, tolerance: 1.272e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.844e-04, tolerance: 1.181e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.307e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.378e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.434e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.300e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.443e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.561e-02, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.334e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.465e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.330e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.475e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.480e-03, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11702335471516814 {'alpha': 0.0, 'l1_ratio': 0}\n",
      "0.11702335471516814 {'alpha': 0.0, 'l1_ratio': 0.2}\n",
      "0.11702335471516814 {'alpha': 0.0, 'l1_ratio': 0.5}\n",
      "0.11702335471516814 {'alpha': 0.0, 'l1_ratio': 0.8}\n",
      "0.11702335471516814 {'alpha': 0.0, 'l1_ratio': 1}\n",
      "0.110933616085592 {'alpha': 0.01, 'l1_ratio': 0}\n",
      "0.11006204123310026 {'alpha': 0.01, 'l1_ratio': 0.2}\n",
      "0.11807012644247596 {'alpha': 0.01, 'l1_ratio': 0.5}\n",
      "0.12821428012611055 {'alpha': 0.01, 'l1_ratio': 0.8}\n",
      "0.1323320721855181 {'alpha': 0.01, 'l1_ratio': 1}\n",
      "0.11039618398465617 {'alpha': 0.02, 'l1_ratio': 0}\n",
      "0.11767774582459965 {'alpha': 0.02, 'l1_ratio': 0.2}\n",
      "0.13261160613379533 {'alpha': 0.02, 'l1_ratio': 0.5}\n",
      "0.13817815906597844 {'alpha': 0.02, 'l1_ratio': 0.8}\n",
      "0.14141018070594819 {'alpha': 0.02, 'l1_ratio': 1}\n",
      "0.11100105368984274 {'alpha': 0.03, 'l1_ratio': 0}\n",
      "0.12439777327958848 {'alpha': 0.03, 'l1_ratio': 0.2}\n",
      "0.13780938557498212 {'alpha': 0.03, 'l1_ratio': 0.5}\n",
      "0.14482955955101484 {'alpha': 0.03, 'l1_ratio': 0.8}\n",
      "0.14619980824276332 {'alpha': 0.03, 'l1_ratio': 1}\n",
      "0.11196501407773933 {'alpha': 0.04, 'l1_ratio': 0}\n",
      "0.13004132759373213 {'alpha': 0.04, 'l1_ratio': 0.2}\n",
      "0.14179461406782934 {'alpha': 0.04, 'l1_ratio': 0.5}\n",
      "0.1462345369606186 {'alpha': 0.04, 'l1_ratio': 0.8}\n",
      "0.14667987792093887 {'alpha': 0.04, 'l1_ratio': 1}\n",
      "0.11303838254250306 {'alpha': 0.05, 'l1_ratio': 0}\n",
      "0.1336704797999421 {'alpha': 0.05, 'l1_ratio': 0.2}\n",
      "0.14533444878879867 {'alpha': 0.05, 'l1_ratio': 0.5}\n",
      "0.14669035852055323 {'alpha': 0.05, 'l1_ratio': 0.8}\n",
      "0.14779709044419015 {'alpha': 0.05, 'l1_ratio': 1}\n",
      "0.11412242694728301 {'alpha': 0.06, 'l1_ratio': 0}\n",
      "0.13666730412818412 {'alpha': 0.06, 'l1_ratio': 0.2}\n",
      "0.1461883548160529 {'alpha': 0.06, 'l1_ratio': 0.5}\n",
      "0.14754530478687047 {'alpha': 0.06, 'l1_ratio': 0.8}\n",
      "0.14951549800099825 {'alpha': 0.06, 'l1_ratio': 1}\n",
      "0.11517480621078542 {'alpha': 0.07, 'l1_ratio': 0}\n",
      "0.13817458251753081 {'alpha': 0.07, 'l1_ratio': 0.2}\n",
      "0.1463680739358243 {'alpha': 0.07, 'l1_ratio': 0.5}\n",
      "0.14878388068354434 {'alpha': 0.07, 'l1_ratio': 0.8}\n",
      "0.1515090868459997 {'alpha': 0.07, 'l1_ratio': 1}\n",
      "0.11617752186743575 {'alpha': 0.08, 'l1_ratio': 0}\n",
      "0.13959102179571575 {'alpha': 0.08, 'l1_ratio': 0.2}\n",
      "0.14672316581149333 {'alpha': 0.08, 'l1_ratio': 0.5}\n",
      "0.1503933093068212 {'alpha': 0.08, 'l1_ratio': 0.8}\n",
      "0.1531254757127632 {'alpha': 0.08, 'l1_ratio': 1}\n",
      "0.11712397167320958 {'alpha': 0.09, 'l1_ratio': 0}\n",
      "0.14104438086122653 {'alpha': 0.09, 'l1_ratio': 0.2}\n",
      "0.1472306101758105 {'alpha': 0.09, 'l1_ratio': 0.5}\n",
      "0.15185014144568326 {'alpha': 0.09, 'l1_ratio': 0.8}\n",
      "0.15435974738421332 {'alpha': 0.09, 'l1_ratio': 1}\n",
      "0.11801311177512894 {'alpha': 0.1, 'l1_ratio': 0}\n",
      "0.142523277608709 {'alpha': 0.1, 'l1_ratio': 0.2}\n",
      "0.14788606579113728 {'alpha': 0.1, 'l1_ratio': 0.5}\n",
      "0.1531361816604278 {'alpha': 0.1, 'l1_ratio': 0.8}\n",
      "0.15507974688102688 {'alpha': 0.1, 'l1_ratio': 1}\n",
      "0.1188466251938476 {'alpha': 0.11, 'l1_ratio': 0}\n",
      "0.14394501287610553 {'alpha': 0.11, 'l1_ratio': 0.2}\n",
      "0.148685842396587 {'alpha': 0.11, 'l1_ratio': 0.5}\n",
      "0.1542350756357497 {'alpha': 0.11, 'l1_ratio': 0.8}\n",
      "0.15562924643249254 {'alpha': 0.11, 'l1_ratio': 1}\n",
      "0.1196274804977074 {'alpha': 0.12, 'l1_ratio': 0}\n",
      "0.1450236759351607 {'alpha': 0.12, 'l1_ratio': 0.2}\n",
      "0.14962433844136278 {'alpha': 0.12, 'l1_ratio': 0.5}\n",
      "0.15478893237325625 {'alpha': 0.12, 'l1_ratio': 0.8}\n",
      "0.15615424059954208 {'alpha': 0.12, 'l1_ratio': 1}\n",
      "0.12035917644180745 {'alpha': 0.13, 'l1_ratio': 0}\n",
      "0.14582898311674916 {'alpha': 0.13, 'l1_ratio': 0.2}\n",
      "0.15069734237858307 {'alpha': 0.13, 'l1_ratio': 0.5}\n",
      "0.15535175953398409 {'alpha': 0.13, 'l1_ratio': 0.8}\n",
      "0.1565109697856715 {'alpha': 0.13, 'l1_ratio': 1}\n",
      "0.12104534165929029 {'alpha': 0.14, 'l1_ratio': 0}\n",
      "0.14613236178838113 {'alpha': 0.14, 'l1_ratio': 0.2}\n",
      "0.15158279412378145 {'alpha': 0.14, 'l1_ratio': 0.5}\n",
      "0.1557330348901134 {'alpha': 0.14, 'l1_ratio': 0.8}\n",
      "0.15689525378859304 {'alpha': 0.14, 'l1_ratio': 1}\n",
      "0.12168952460899686 {'alpha': 0.15, 'l1_ratio': 0}\n",
      "0.1461788321647421 {'alpha': 0.15, 'l1_ratio': 0.2}\n",
      "0.15240871962198102 {'alpha': 0.15, 'l1_ratio': 0.5}\n",
      "0.15615669539191832 {'alpha': 0.15, 'l1_ratio': 0.8}\n",
      "0.15699509095826747 {'alpha': 0.15, 'l1_ratio': 1}\n",
      "0.1222950878990936 {'alpha': 0.16, 'l1_ratio': 0}\n",
      "0.14625955324543444 {'alpha': 0.16, 'l1_ratio': 0.2}\n",
      "0.15316794717527013 {'alpha': 0.16, 'l1_ratio': 0.5}\n",
      "0.156433630766134 {'alpha': 0.16, 'l1_ratio': 0.8}\n",
      "0.1571020831229356 {'alpha': 0.16, 'l1_ratio': 1}\n",
      "0.12286516061395103 {'alpha': 0.17, 'l1_ratio': 0}\n",
      "0.1463744086473646 {'alpha': 0.17, 'l1_ratio': 0.2}\n",
      "0.15384610823920586 {'alpha': 0.17, 'l1_ratio': 0.5}\n",
      "0.15681896453583172 {'alpha': 0.17, 'l1_ratio': 0.8}\n",
      "0.1571333088025217 {'alpha': 0.17, 'l1_ratio': 1}\n",
      "0.12340262291067722 {'alpha': 0.18, 'l1_ratio': 0}\n",
      "0.14651563363974138 {'alpha': 0.18, 'l1_ratio': 0.2}\n",
      "0.15439142323713356 {'alpha': 0.18, 'l1_ratio': 0.5}\n",
      "0.1569339007584858 {'alpha': 0.18, 'l1_ratio': 0.8}\n",
      "0.15715971497722914 {'alpha': 0.18, 'l1_ratio': 1}\n",
      "0.12391010831512066 {'alpha': 0.19, 'l1_ratio': 0}\n",
      "0.14668142695555825 {'alpha': 0.19, 'l1_ratio': 0.2}\n",
      "0.15473933176911636 {'alpha': 0.19, 'l1_ratio': 0.5}\n",
      "0.15701434389175264 {'alpha': 0.19, 'l1_ratio': 0.8}\n",
      "0.15718894060253635 {'alpha': 0.19, 'l1_ratio': 1}\n",
      "0.12439001535858762 {'alpha': 0.2, 'l1_ratio': 0}\n",
      "0.14687100147403384 {'alpha': 0.2, 'l1_ratio': 0.2}\n",
      "0.15510766051902197 {'alpha': 0.2, 'l1_ratio': 0.5}\n",
      "0.15710210428130375 {'alpha': 0.2, 'l1_ratio': 0.8}\n",
      "0.15722002530897097 {'alpha': 0.2, 'l1_ratio': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.360e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.494e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.359e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.506e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.298e-04, tolerance: 1.234e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.385e-01, tolerance: 1.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.416e-01, tolerance: 6.256e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.522e-01, tolerance: 1.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.386e-01, tolerance: 1.272e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.534e-01, tolerance: 1.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/ccs/proj/csc499/hstellar/rapids/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.764e-01, tolerance: 1.365e-04\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#elastic net\n",
    "\n",
    "\n",
    "for train_index, test_index in sss.split(data.drop(['model'], axis=1), data['code']):\n",
    "    model_type =  pd.get_dummies(data['model'])\n",
    "    data_temp = data.merge(model_type, how='outer',left_index=True, right_index=True)\n",
    "    data_temp = data_temp.drop(['model'], axis=1)\n",
    "    X = np.array(data_temp.drop(['error','code'], axis=1))[train_index]\n",
    "    y = np.array(data_temp['error'])[train_index]\n",
    "\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_scaled = sc.fit_transform(X)\n",
    "    # X_scaled = pd.DataFrame(data = X_scaled, columns = X.columns)\n",
    "    param_grid = [\n",
    "    {'alpha': np.linspace(0, 0.2, 21), 'l1_ratio': [0, 0.2, .5, .8, 1]},]\n",
    "    elastic_net = ElasticNet()\n",
    "    grid_search = GridSearchCV(elastic_net, param_grid, cv=5,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            return_train_score=True)\n",
    "    grid_search.fit(X, y)\n",
    "    cvres = grid_search.cv_results_\n",
    "    for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "        print(np.sqrt(-mean_score), params)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(model, X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    train_errors, val_errors = [], []\n",
    "    for m in range(1, len(X_train)):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = model.predict(X_train[:m])\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        train_errors.append(mean_squared_error(y_train_predict, y_train[:m]))\n",
    "        val_errors.append(mean_squared_error(y_val_predict, y_val))\n",
    "        plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
    "        plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(lasso,X,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(elastic_net,X,y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "rapids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "766cfe2864b800c6196a6f9652521f0de5a64fb97f94472e69f0b3f394df521a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
