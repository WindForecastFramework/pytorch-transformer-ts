{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8104,
     "status": "ok",
     "timestamp": 1654899118892,
     "user": {
      "displayName": "Hena Ghonia",
      "userId": "03246241722682988409"
     },
     "user_tz": 240
    },
    "id": "RdI6LSS_mo7o",
    "outputId": "3050392f-eea6-4257-e149-de5206aa714f"
   },
   "outputs": [],
   "source": [
    "from estimator import HopfieldEstimator\n",
    "\n",
    "from gluonts.torch.distributions import StudentTOutput, NegativeBinomialOutput\n",
    "from datasets import load_dataset\n",
    "from gluonts.dataset.split import split\n",
    "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219,
     "referenced_widgets": [
      "4202b9b16c484f3c98617cd66dbef46e",
      "c01293cf2c0d42eea7ce3afb22ba90aa",
      "310d3fa7ffef4b22abfe695765826e69",
      "9f030ce97316462b810ce3965c6c2108",
      "76df9e8f69d14f369d32c531a06c2a1e",
      "26132e35c8de434f877aa890190e65ef",
      "5e72f23895124631ae15affc09deba6b",
      "8088c2508e7e49398d3a3ff8c3159031",
      "59a543c66b094b4bb1e0b6dd04f83d67",
      "9c3dcbee1bd448d3ae5f60f0b622aa79",
      "44ed849a6fdb4edeb08455302504eb23",
      "f9498060d21e4e628a1398a6bb3de458",
      "1fdfd3c916494f259134e9b98f1a65f8",
      "f5c34333d20349079d613391b3e835a6",
      "69f871dc2bbd485c942ad6f56597e1f4",
      "efb0c3bd80e84f23af6eb06d14db33f5",
      "f7d2f9e600f94617bb7ff2b8af07fea1",
      "244355caea9741aab02846681d3ed3fd",
      "3db61121da9e425a9c49cfcaca302820",
      "878d24c9e2b14822a2e83fb8e3f26ba7",
      "4f1b6913874840b48c26889bc41648fd",
      "95270e2ee70240fc95c0b516dd5ab6fe",
      "12d89789e7c24d0e99df4c91d1a76c05",
      "63ce14a0fe8a4f529e981001ec5328d3",
      "44edcc4dd9f54cee8b16b33303304c3e",
      "edaf300460ba4b18855b3abbef746d8d",
      "539f1b357d404b7a96b672036cd7d812",
      "3aeadccaad874c55b5f0d26a5fd1a117",
      "1fda193ebaf5443db821af4e82a782a5",
      "28e406f331bd45cbab2c578b2a818a2c",
      "a82846a26c84444fb4175422f65b23b4",
      "acc2055be84942cca356ec0f4147f4e2",
      "2d2c16b089af4bfa86f4512a16fafe3b",
      "f969841826274947a1f636f65327110a",
      "3d8a16e789c3494c838f71f8255bfaf8",
      "ccbf1381bfd94b749b37dc17af1bc105",
      "37e47e25e55141bf9f69fdcdd652ab9d",
      "8d73dcbc23a643faa7ec33e734249661",
      "903a2f2f279a4b638472a95cd0e31fd4",
      "a7c21ae75ca44acbb0af43cc8aa95ede",
      "1ac34e29062f4030a709027dfae808ba",
      "e4b56e662fbf4490996b10c337d83cd4",
      "6a9c1144d5c34d91b0061a974f7be1e2",
      "3973f3858e124cc2af097c2596bae40a",
      "38ee9b45725c42f68ebb1b4bbcb7dc13",
      "4a31b985ba3a4b0889af6f2ba65710f5",
      "61b918eb0300418dad3f95bb99c69680",
      "0b248143a7734c0fb79010733aeb19cc",
      "62b721406c6c43ceaf535c24e58fb49d",
      "ddcfca9611804da4863e0c80e79b67fa",
      "97b6006278594ae294a2e78512154b66",
      "f7bea2f634034aa9bfe07413d6c2a7ba",
      "9182dcef2ecf4b66acae7b73d88be966",
      "e1d4dfdffe4e4ffcbed188edbdad1cca",
      "4aaac1ff93ca45c5ab329e8bee185d1e",
      "b1939ae3fc2e4540b458f86f8c06e045",
      "8f1f5c4763f042cb9128d75e0653e4f6",
      "e453fa0401244a1fb3ce7671b431d83f",
      "490c4158b00f4e578e2aa017df586b08",
      "98609c0f31f74f05b888b71ec33746e6",
      "b76ae8f5609e4fa88ff9c4a1b2129b3a",
      "034b69b4270d445c874ebec39289e216",
      "adc171fc222848d5afac1969f74a14c8",
      "f7cd575bfcf44f418a724d63cbb40296",
      "71cda2bda2714328b736e15cb26cad8c",
      "bfdf013e724b4382bdee915c8cf404c0",
      "1fd21029697c40119233fb8e599af5c5",
      "e402633e51444f968bf4f167b9ff4440",
      "6ad1b396787248a2a199b79df3d41df7",
      "a0e2dd1649714377888d33aaf1809b07",
      "386ce6a8e716475d91120f65c05cba32",
      "eac6e66d4e6d491ab6e5c201d32a5b48",
      "91e3e823d9ad4c40a1aa36448771c483",
      "2abf98d168a7434bb49850bfb5880237",
      "6f09a6180b0b48168679ac869429149f",
      "ae421e6f0f134f91a3381fcea8e8f475",
      "8c3a3e73404f4e69b924fd80cb81a52a"
     ]
    },
    "executionInfo": {
     "elapsed": 70487,
     "status": "ok",
     "timestamp": 1654899223453,
     "user": {
      "displayName": "Hena Ghonia",
      "userId": "03246241722682988409"
     },
     "user_tz": 240
    },
    "id": "dkO5OmT-m9dy",
    "outputId": "5cfe9523-4f13-4c86-946a-4654b0dae33a"
   },
   "outputs": [],
   "source": [
    "dta_sets = [\"exchange_rate\", \"solar-energy\", \"electricity_hourly\", \"traffic\", \"taxi_30min\", \"wiki-rolling_nips\"]\n",
    "\n",
    "for dta in dta_sets:\n",
    "    dataset = get_dataset(dta, regenerate=False) \n",
    "    print(f\"{dta}: {int(dataset.metadata.feat_static_cat[0].cardinality)}/{dataset.metadata.freq}/{dataset.metadata.prediction_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ho1PxDM6MeEw"
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cl3JMFsgMS5M"
   },
   "outputs": [],
   "source": [
    "# Parameter Settings\n",
    "params  = {\n",
    "    \n",
    "    # General settings\n",
    "    \"model\": \"hopfield\",\n",
    "    \"context_length_factor\": 2, \n",
    "    \"batch_size\": 32,\n",
    "    \"max_epochs\": 100,\n",
    "    \n",
    "    # Model-specific settings\n",
    "    \"nhead\": 4,\n",
    "    \"num_encoder_layers\": 8,\n",
    "    \"num_decoder_layers\": 8,\n",
    "    \"dim_feedforward\": 32,\n",
    "    \"embedding_dimension\": 4,     \n",
    "}\n",
    "\n",
    "# Number of runs\n",
    "n_runs = 5\n",
    "\n",
    "metrics = []\n",
    "for dta in dta_sets:     \n",
    "    \n",
    "    # Dataset\n",
    "    dataset = get_dataset(dta, regenerate=False) \n",
    "    freq = dataset.metadata.freq\n",
    "    prediction_length = dataset.metadata.prediction_length\n",
    "    cardinality = int(dataset.metadata.feat_static_cat[0].cardinality)\n",
    "    context_length = int(params[\"context_length_factor\"])*prediction_length\n",
    "\n",
    "    # Distribution\n",
    "    dist_mapping = {\n",
    "        \"taxi_30min\": NegativeBinomialOutput(),\n",
    "        \"wiki-rolling_nips\": NegativeBinomialOutput()\n",
    "        }\n",
    "    dist = dist_mapping.get(dta, StudentTOutput())\n",
    "\n",
    "    # Scaling\n",
    "    scaling_mapping = {\n",
    "        \"taxi_30min\": \"mean\",\n",
    "        \"wiki-rolling_nips\": \"mean\"\n",
    "        }\n",
    "    scaling = scaling_mapping.get(dta, \"std\")\n",
    "\n",
    "    for i in range(n_runs):           \n",
    "       \n",
    "        print(f\"\\n\\nEstimation of {params['model'].upper()} on {dta} dataset: {i+1}/{n_runs}\\n\\n\")\n",
    "\n",
    "        # Estimator\n",
    "        start = time.time()\n",
    "        estimator = HopfieldEstimator(\n",
    "            freq=freq,\n",
    "            prediction_length=prediction_length,\n",
    "            context_length=context_length,\n",
    "            num_feat_static_cat=1,\n",
    "            cardinality=[cardinality],\n",
    "            num_batches_per_epoch=100,\n",
    "\n",
    "            distr_output = dist,\n",
    "            scaling = scaling,\n",
    "            nhead=params[\"nhead\"],\n",
    "            num_encoder_layers=params[\"num_encoder_layers\"],\n",
    "            num_decoder_layers=params[\"num_decoder_layers\"],\n",
    "            dim_feedforward=params[\"dim_feedforward\"],            \n",
    "            embedding_dimension=[params[\"embedding_dimension\"]],\n",
    "            batch_size=params[\"batch_size\"],   \n",
    "            trainer_kwargs=dict(max_epochs=params[\"max_epochs\"], accelerator=\"auto\")\n",
    "        )\n",
    "        end = time.time()\n",
    "        runtime = end - start\n",
    "\n",
    "        # Train\n",
    "        predictor = estimator.train(dataset.train, shuffle_buffer_length=1024, cache_data=True)\n",
    "\n",
    "        # Forecast\n",
    "        forecast_it, ts_it = make_evaluation_predictions(dataset=dataset.test, predictor=predictor)\n",
    "        forecasts = list(forecast_it)\n",
    "        tss = list(ts_it)\n",
    "\n",
    "        # Evaluate\n",
    "        evaluator = Evaluator()\n",
    "        agg_metrics, _ = evaluator(tss, forecasts)\n",
    "\n",
    "        # Metrics\n",
    "        items = list(agg_metrics.items())\n",
    "        metrics_df = pd.DataFrame(items).T.iloc[[1]]\n",
    "        metrics_df.columns = list(agg_metrics)\n",
    "        metrics_df[\"dataset\"] = dta\n",
    "        metrics_df[\"model\"] = params[\"model\"]\n",
    "        metrics_df[\"runtime\"] = runtime\n",
    "        metrics_df[\"run\"] = i + 1\n",
    "        metrics.append(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.concat(metrics, axis=0)\n",
    "metrics_df.to_csv(f\"{params['model'].upper()}_experiments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Metrics for Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouped_loss(df, group_by_cols, target_cols, digits=3):\n",
    "    \"\"\"\n",
    "    Computes grouped statistics (mean, min, and max) of the target columns based on the grouping columns.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The data frame to be grouped.\n",
    "    - group_by_cols (list): List of column names to group by.\n",
    "    - target_cols (list): List of target columns for which statistics will be computed.\n",
    "    - digits (int): Number of decimal places to round the statistics. Default is 3.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: A data frame with the mean, min, and max statistics for the target columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Group by the specified columns\n",
    "    grouped = df.groupby(group_by_cols)\n",
    "    \n",
    "    # Compute mean, min, and max for target columns\n",
    "    mean_df = grouped[target_cols].mean()\n",
    "    min_df = grouped[target_cols].min()\n",
    "    max_df = grouped[target_cols].max()\n",
    "    \n",
    "    # Format string for rounding\n",
    "    format_str = '{:.' + str(digits) + 'f}'\n",
    "    \n",
    "    # Iterate through columns and create the desired format\n",
    "    for col in mean_df.columns:\n",
    "        mean_df[col] = mean_df[col].map(format_str.format) + ' (' + min_df[col].map(format_str.format) + ', ' + max_df[col].map(format_str.format) + ')'\n",
    "\n",
    "    return mean_df        \n",
    "\n",
    "\n",
    "metric_cols = [\"mean_wQuantileLoss\",\n",
    "               \"wQuantileLoss[0.5]\",\n",
    "               \"wQuantileLoss[0.9]\",\n",
    "               \"MSIS\",\n",
    "               \"NRMSE\",\n",
    "               \"sMAPE\",\n",
    "               \"MASE\"\n",
    "              ]\n",
    "\n",
    "group_cols =  [\"dataset\", \"model\"]\n",
    "\n",
    "digits=4\n",
    "loss_metrics = grouped_loss(metrics_df, group_cols, metric_cols, digits)\n",
    "loss_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_str = '{:.' + str(digits) + 'f}'\n",
    "loss_metrics.to_latex(index=False, float_format=format_str.format)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPj/PtAPp6M1qtNIyWk53A7",
   "name": "hyperparameter-tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
