Timer unit: 1e-09 s

Total time: 123.664 s
File: /Users/ahenry/Documents/toolboxes/gluonts/src/gluonts/torch/model/estimator.py
Function: train_model at line 149

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   149                                               @profile
   150                                               def train_model(
   151                                                   self,
   152                                                   training_data: Dataset,
   153                                                   validation_data: Optional[Dataset] = None,
   154                                                   from_predictor: Optional[PyTorchPredictor] = None,
   155                                                   shuffle_buffer_length: Optional[int] = None,
   156                                                   cache_data: bool = False,
   157                                                   ckpt_path: Optional[str] = None,
   158                                                   **kwargs,
   159                                               ) -> TrainOutput:
   160         1    1768000.0    2e+06      0.0          transformation = self.create_transformation()
   161                                                    
   162         2    1202000.0 601000.0      0.0          with env._let(max_idle_transforms=max(len(training_data), 100)):
   163         2      43000.0  21500.0      0.0              transformed_training_data: Dataset = transformation.apply(
   164         1          0.0      0.0      0.0                  training_data, is_train=True
   165                                                       )
   166                                                       # x = next(iter(transformed_training_data))
   167                                                        
   168         1          0.0      0.0      0.0              if cache_data:
   169                                                           transformed_training_data = Cached(transformed_training_data)
   170                                           
   171         1        1e+10    1e+10      9.3              training_network = self.create_lightning_module()
   172                                           
   173                                                       
   174         2    1659000.0 829500.0      0.0              training_data_loader = self.create_training_data_loader(
   175         1       4000.0   4000.0      0.0                  transformed_training_data,
   176         1       4000.0   4000.0      0.0                  training_network,
   177         1       3000.0   3000.0      0.0                  shuffle_buffer_length=shuffle_buffer_length,
   178                                                       )
   179                                                       # x = next(iter(training_data_loader))
   180                                                       
   181         1       5000.0   5000.0      0.0          validation_data_loader = None
   182                                           
   183         1       3000.0   3000.0      0.0          if validation_data is not None:
   184                                                       with env._let(max_idle_transforms=max(len(validation_data), 100)):
   185                                                           transformed_validation_data: Dataset = transformation.apply(
   186                                                               validation_data, is_train=True
   187                                                           )
   188                                                           if cache_data:
   189                                                               transformed_validation_data = Cached(
   190                                                                   transformed_validation_data
   191                                                               )
   192                                           
   193                                                           
   194                                                           validation_data_loader = self.create_validation_data_loader(
   195                                                               transformed_validation_data,
   196                                                               training_network,
   197                                                           )
   198                                           
   199         1       3000.0   3000.0      0.0          if from_predictor is not None:
   200                                                       training_network.load_state_dict(
   201                                                           from_predictor.network.state_dict()
   202                                                       )
   203                                           
   204         1       8000.0   8000.0      0.0          monitor = "train_loss" if validation_data is None else "val_loss"
   205         2    3505000.0    2e+06      0.0          checkpoint = pl.callbacks.ModelCheckpoint(
   206         1       3000.0   3000.0      0.0              monitor=monitor, mode="min", verbose=True
   207                                                   )
   208                                           
   209         1       7000.0   7000.0      0.0          custom_callbacks = self.trainer_kwargs.pop("callbacks", [])
   210         2  412378000.0    2e+08      0.3          trainer = pl.Trainer(
   211         2       7000.0   3500.0      0.0              **{
   212                                                           # "accelerator": "auto",
   213         1       4000.0   4000.0      0.0                  "callbacks": [checkpoint] + custom_callbacks,
   214         1       3000.0   3000.0      0.0                  **self.trainer_kwargs,
   215                                                       }
   216                                                   )
   217                                                   
   218         2        1e+11    5e+10     81.3          trainer.fit(
   219         1       2000.0   2000.0      0.0              model=training_network,
   220         1       2000.0   2000.0      0.0              train_dataloaders=training_data_loader,
   221         1       2000.0   2000.0      0.0              val_dataloaders=validation_data_loader,
   222         1       2000.0   2000.0      0.0              ckpt_path=ckpt_path,
   223                                                   )
   224                                           
   225         1       8000.0   8000.0      0.0          if checkpoint.best_model_path != "":
   226         2     129000.0  64500.0      0.0              logger.info(
   227         1       2000.0   2000.0      0.0                  f"Loading best model from {checkpoint.best_model_path}"
   228                                                       )
   229         2        1e+10    6e+09      9.0              best_model = training_network.__class__.load_from_checkpoint(
   230         1       2000.0   2000.0      0.0                  checkpoint.best_model_path
   231                                                       )
   232                                                   else:
   233                                                       best_model = training_network
   234                                           
   235         2      35000.0  17500.0      0.0          return TrainOutput(
   236         1       2000.0   2000.0      0.0              transformation=transformation,
   237         1       3000.0   3000.0      0.0              trained_net=best_model,
   238         1       2000.0   2000.0      0.0              trainer=trainer,
   239         1    2677000.0    3e+06      0.0              predictor=self.create_predictor(transformation, best_model, **kwargs), # CHANGE
   240                                                   )

Total time: 123.665 s
File: /Users/ahenry/Documents/toolboxes/gluonts/src/gluonts/torch/model/estimator.py
Function: train at line 246

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   246                                               @profile
   247                                               def train(
   248                                                   self,
   249                                                   training_data: Dataset,
   250                                                   validation_data: Optional[Dataset] = None,
   251                                                   shuffle_buffer_length: Optional[int] = None,
   252                                                   cache_data: bool = False,
   253                                                   ckpt_path: Optional[str] = None,
   254                                                   **kwargs,
   255                                               ) -> TrainOutput:
   256         4        1e+11    3e+10    100.0          return self.train_model(
   257         1       1000.0   1000.0      0.0              training_data,
   258         1          0.0      0.0      0.0              validation_data,
   259         1       3000.0   3000.0      0.0              shuffle_buffer_length=shuffle_buffer_length,
   260         1       2000.0   2000.0      0.0              cache_data=cache_data,
   261         1          0.0      0.0      0.0              ckpt_path=ckpt_path,
   262         1          0.0      0.0      0.0              **kwargs # CHANGE
   263                                                   ) # CHANGE

123.66 seconds - /Users/ahenry/Documents/toolboxes/gluonts/src/gluonts/torch/model/estimator.py:149 - train_model
123.66 seconds - /Users/ahenry/Documents/toolboxes/gluonts/src/gluonts/torch/model/estimator.py:246 - train
